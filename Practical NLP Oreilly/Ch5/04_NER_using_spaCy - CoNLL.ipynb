{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating an NER model with spaCy on the CoNLL dataset\n",
    "\n",
    "In this notebook, we will take a look at using spaCy commandline to train and evaluate a NER model. We will also compare it with the pretrained NER model in spacy. \n",
    "\n",
    "Note: we will create multiple folders during this experiment:\n",
    "spacyNER_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Converting data to json structures so it can be used by Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘spacyNER_data’: File exists\n",
      "\u001b[38;5;2m✔ Generated output file (1 documents)\u001b[0m\n",
      "spacyNER_data/train.json\n",
      "\u001b[38;5;2m✔ Generated output file (1 documents)\u001b[0m\n",
      "spacyNER_data/test.json\n",
      "\u001b[38;5;2m✔ Generated output file (1 documents)\u001b[0m\n",
      "spacyNER_data/valid.json\n"
     ]
    }
   ],
   "source": [
    "#Read the CONLL data from conll2003 folder, and store the formatted data into a folder spacyNER_data\n",
    "!mkdir spacyNER_data\n",
    "#the above two lines create folders if they don't exist. If they do, the output shows a message that it\n",
    "#already exists and cannot be created again\n",
    "!python3 -m spacy convert \"Data/conll2003/en/train.txt\" spacyNER_data -c ner\n",
    "!python3 -m spacy convert \"Data/conll2003/en/test.txt\" spacyNER_data -c ner\n",
    "!python3 -m spacy convert \"Data/conll2003/en/valid.txt\" spacyNER_data -c ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For example, the data before and after running spacy's convert program looks as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE : (Data/conll2003/en/train.txt)\n",
      "EU NNP B-NP B-ORG\n",
      "rejects VBZ B-VP O\n",
      "German JJ B-NP B-MISC\n",
      "call NN I-NP O\n",
      "to TO B-VP O\n",
      "boycott VB I-VP O\n",
      "British JJ B-NP B-MISC\n",
      "lamb NN I-NP O\n",
      ". . O O\n",
      "\n",
      "AFTER : (Data/conll2003/en/train.json)\n",
      "          {\n",
      "            \"tokens\":[\n",
      "              {\n",
      "                \"orth\":\"EU\",\n",
      "                \"tag\":\"NNP\",\n",
      "                \"ner\":\"U-ORG\"\n",
      "              },\n",
      "              {\n",
      "                \"orth\":\"rejects\",\n",
      "                \"tag\":\"VBZ\",\n",
      "                \"ner\":\"O\"\n",
      "              },\n",
      "              {\n",
      "                \"orth\":\"German\",\n",
      "                \"tag\":\"JJ\",\n",
      "                \"ner\":\"U-MISC\"\n",
      "              },\n",
      "              {\n",
      "                \"orth\":\"call\",\n",
      "                \"tag\":\"NN\",\n",
      "                \"ner\":\"O\"\n",
      "              },\n",
      "              {\n",
      "                \"orth\":\"to\",\n",
      "                \"tag\":\"TO\",\n",
      "                \"ner\":\"O\"\n",
      "              },\n",
      "              {\n",
      "                \"orth\":\"boycott\",\n",
      "                \"tag\":\"VB\",\n",
      "                \"ner\":\"O\"\n",
      "              },\n",
      "              {\n",
      "                \"orth\":\"British\",\n",
      "                \"tag\":\"JJ\",\n",
      "                \"ner\":\"U-MISC\"\n",
      "              },\n",
      "              {\n",
      "                \"orth\":\"lamb\",\n",
      "                \"tag\":\"NN\",\n",
      "                \"ner\":\"O\"\n",
      "              },\n",
      "              {\n",
      "                \"orth\":\".\",\n",
      "                \"tag\":\".\",\n",
      "                \"ner\":\"O\"\n",
      "              }\n",
      "            ]\n",
      "          },\n"
     ]
    }
   ],
   "source": [
    "!echo \"BEFORE : (Data/conll2003/en/train.txt)\"\n",
    "!head \"Data/conll2003/en/train.txt\" -n 11 | tail -n 9\n",
    "!echo \"\\nAFTER : (Data/conll2003/en/train.json)\"\n",
    "!head \"spacyNER_data/train.json\" -n 64 | tail -n 49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the NER model with Spacy (CLI)\n",
    "\n",
    "All the commandline options can be seen at: https://spacy.io/api/cli#train\n",
    "We are training using the train program in spacy, for English (en), and the results are stored in a folder \n",
    "called \"model\" (created while training). Our training file is in \"spacyNER_data/train.json\" and the validation file is at: \"spacyNER_data/valid.json\". \n",
    "\n",
    "-G stands for gpu option.\n",
    "-p stands for pipeline, and it should be followed by a comma separated set of options - in this case, a tagger and an NER are being trained simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pipeline: ['tagger', 'ner']\n",
      "Starting with blank model 'en'\n",
      "Counting training words (limit=0)\n",
      "\n",
      "Itn    Dep Loss    NER Loss      UAS    NER P    NER R    NER F    Tag %  Token %  CPU WPS  GPU WPS\n",
      "---  ----------  ----------  -------  -------  -------  -------  -------  -------  -------  -------\n",
      "  0       0.000   20994.512    0.000   78.404   77.230   77.813   94.075  100.000    15468        0\n",
      "  1       0.000   10338.546    0.000   84.808   84.366   84.586   94.812  100.000    15833        0\n",
      "  2       0.000    7414.531    0.000   86.235   85.931   86.083   95.015  100.000    15839        0\n",
      "  3       0.000    5461.594    0.000   87.020   86.873   86.946   95.106  100.000    15737        0\n",
      "  4       0.000    4101.375    0.000   87.669   87.344   87.506   95.182  100.000    15887        0\n",
      "  5       0.000    3413.915    0.000   87.622   87.327   87.475   95.258  100.000    15919        0\n",
      "  6       0.000    3008.749    0.000   88.024   87.580   87.802   95.322  100.000    18794        0\n",
      "  7       0.000    2704.280    0.000   88.323   87.832   88.077   95.347  100.000    15652        0\n",
      "  8       0.000    2301.952    0.000   88.195   87.883   88.038   95.405  100.000    15935        0\n",
      "  9       0.000    2162.503    0.000   88.227   88.034   88.131   95.428  100.000    15866        0\n",
      " 10       0.000    1954.655    0.000   88.394   88.186   88.290   95.409  100.000    15689        0\n",
      " 11       0.000    1846.583    0.000   88.233   88.085   88.159   95.391  100.000    15812        0\n",
      " 12       0.000    1760.181    0.000   88.682   88.354   88.518   95.452  100.000    15829        0\n",
      " 13       0.000    1670.751    0.000   88.579   88.236   88.407   95.465  100.000    15689        0\n",
      " 14       0.000    1534.231    0.000   88.443   88.219   88.331   95.481  100.000    15662        0\n",
      " 15       0.000    1439.400    0.000   88.782   88.438   88.610   95.510  100.000    15864        0\n",
      " 16       0.000    1407.665    0.000   88.915   88.556   88.735   95.477  100.000    15872        0\n",
      " 17       0.000    1199.285    0.000   88.709   88.455   88.582   95.512  100.000    15826        0\n",
      " 18       0.000    1302.530    0.000   88.709   88.455   88.582   95.512  100.000    15776        0\n",
      " 19       0.000    1147.754    0.000   88.874   88.455   88.664   95.519  100.000    19138        0\n",
      " 20       0.000    1115.887    0.000   88.987   88.388   88.686   95.519  100.000    19035        0\n",
      " 21       0.000    1146.815    0.000   89.006   88.421   88.713   95.531  100.000    15839        0\n",
      " 22       0.000    1143.363    0.000   89.122   88.522   88.821   95.529  100.000    15981        0\n",
      " 23       0.000    1051.906    0.000   89.171   88.556   88.863   95.550  100.000    15931        0\n",
      " 24       0.000     922.404    0.000   89.124   88.674   88.898   95.550  100.000    16115        0\n",
      " 25       0.000    1033.210    0.000   89.013   88.758   88.885   95.527  100.000    15973        0\n",
      " 26       0.000     939.757    0.000   88.962   88.708   88.835   95.539  100.000    15939        0\n",
      " 27       0.000     874.334    0.000   88.808   88.539   88.674   95.521  100.000    15963        0\n",
      " 28       0.000     847.320    0.000   88.870   88.691   88.780   95.541  100.000    15855        0\n",
      " 29       0.000     879.595    0.000   88.763   88.674   88.719   95.564  100.000    15893        0\n",
      "\u001b[38;5;2m✔ Saved model to output directory\u001b[0m\n",
      "model/model-final\n",
      "\u001b[2K\u001b[38;5;2m✔ Created best model\u001b[0m\n",
      "model/model-best\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train en model spacyNER_data/train.json spacyNER_data/valid.json -G -p tagger,ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the performance improves with each iteration!\n",
    "## Evaluating the model with test data set (`spacyNER_data/test.json`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Trained model (`model/model-best`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "Time      3.53 s\n",
      "Words     46666 \n",
      "Words/s   13234 \n",
      "TOK       100.00\n",
      "POS       94.79 \n",
      "UAS       0.00  \n",
      "LAS       0.00  \n",
      "NER P     78.09 \n",
      "NER R     78.75 \n",
      "NER F     78.42 \n",
      "\n",
      "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
      "result\n"
     ]
    }
   ],
   "source": [
    "#create a folder to store the output and visualizations. \n",
    "!mkdir result\n",
    "!python3 -m spacy evaluate model/model-best spacyNER_data/test.json -dp result\n",
    "# !python -m spacy evaluate model/model-final data/test.txt.json -dp result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a Visualization of the entity tagged test data can be seen in result/entities.html folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On spacy's Pretrained NER model (`en`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "Time      6.52 s\n",
      "Words     46666 \n",
      "Words/s   7160  \n",
      "TOK       100.00\n",
      "POS       86.84 \n",
      "UAS       0.00  \n",
      "LAS       0.00  \n",
      "NER P     7.97  \n",
      "NER R     10.68 \n",
      "NER F     9.12  \n",
      "\n",
      "\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n",
      "pretrained_result\n"
     ]
    }
   ],
   "source": [
    "!mkdir pretrained_result\n",
    "!python3 -m spacy evaluate en spacyNER_data/test.json -dp pretrained_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a Visualization of the entity tagged test data can be seen in pretrained_result/entities.html folder. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
