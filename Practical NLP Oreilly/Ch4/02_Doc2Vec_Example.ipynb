{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doc2Vec_Example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LCgVnQopb6TI"
      },
      "source": [
        "# Doc2Vec demonstration \n",
        "\n",
        "In this notebook, let us take a look at how to \"learn\" document embeddings and use them for text classification. We will be using the dataset of \"Sentiment and Emotion in Text\" from [Kaggle](https://www.kaggle.com/c/sa-emotions/data).\n",
        "\n",
        "\"In a variation on the popular task of sentiment analysis, this dataset contains labels for the emotional content (such as happiness, sadness, and anger) of texts. Hundreds to thousands of examples across 13 labels. A subset of this data is used in an experiment we uploaded to Microsoft’s Cortana Intelligence Gallery.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hSB6W1seb6TJ",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lSvnHBYPb6TQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "c5a2fa15-e630-49e9-c43b-f1393c36022d"
      },
      "source": [
        "#Load the dataset and explore.\n",
        "filepath = \"https://github.com/duybluemind1988/Data-science/blob/master/Practical%20NLP%20Oreilly/Ch4/Data/Sentiment%20and%20Emotion%20in%20Text/text_emotion.csv?raw=true\"\n",
        "df = pd.read_csv(filepath)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>empty</td>\n",
              "      <td>xoshayzers</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>wannamama</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>coolfunky</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>czareaquino</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>xkilljoyx</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     tweet_id  ...                                            content\n",
              "0  1956967341  ...  @tiffanylue i know  i was listenin to bad habi...\n",
              "1  1956967666  ...  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2  1956967696  ...                Funeral ceremony...gloomy friday...\n",
              "3  1956967789  ...               wants to hang out with friends SOON!\n",
              "4  1956968416  ...  @dannycastillo We want to trade with someone w...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5JEI6SH7b6TU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "75436bb9-ef39-40ab-a699-fa5630845e6d"
      },
      "source": [
        "df['sentiment'].value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral       8638\n",
              "worry         8459\n",
              "happiness     5209\n",
              "sadness       5165\n",
              "love          3842\n",
              "surprise      2187\n",
              "fun           1776\n",
              "relief        1526\n",
              "hate          1323\n",
              "empty          827\n",
              "enthusiasm     759\n",
              "boredom        179\n",
              "anger          110\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CHajyKpmb6TY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16fe5c2d-3c10-4947-ac5a-f76e566932b6"
      },
      "source": [
        "#Let us take the top 3 categories and leave out the rest.\n",
        "shortlist = ['neutral', \"happiness\", \"worry\"]\n",
        "df_subset = df[df['sentiment'].isin(shortlist)]\n",
        "df_subset.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22306, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m2oiZzU5b6Tf"
      },
      "source": [
        "# Text pre-processing:\n",
        "Tweets are different. Somethings to consider:\n",
        "- Removing @mentions, and urls perhaps?\n",
        "- using NLTK Tweet tokenizer instead of a regular one\n",
        "- stopwords, numbers as usual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtNRgu8Le1GM",
        "colab_type": "text"
      },
      "source": [
        "After loading the dataset and taking a subset of the three most frequent labels, an\n",
        "important step to consider here is pre-processing the data. What’s different here\n",
        "compared to previous examples? Why can’t we just follow the same procedure as\n",
        "before? There are a few things that are different about tweets compared to news\n",
        "articles or other such text, as we briefly discussed in Chapter 2 when we talked\n",
        "about text pre-processing. First, they are very short. Second, our traditional\n",
        "tokenizers may not work well with tweets, splitting smileys, hashtags, Twitter\n",
        "handles, etc., into multiple tokens. Such specialized needs prompted a lot of\n",
        "research into NLP for Twitter in the recent past, which resulted in several preprocessing options for tweets. One such solution is a TweetTokenizer,\n",
        "implemented in the NLTK [21] library in Python. We’ll discuss more on this topic in\n",
        "Chapter 8. For now, let’s see how we can use a TweetTokenizer in the following\n",
        "code snippet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7_nAxwuZ_kK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a17b6137-2ed6-40c0-f5f0-0754c173a73d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rl-FfMdLb6Th",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aace2361-6072-4e57-9685-384476e5ef2e"
      },
      "source": [
        "#strip_handles removes personal information such as twitter handles, which don't\n",
        "#contribute to emotion in the tweet. preserve_case=False converts everything to lowercase.\n",
        "tweeter = TweetTokenizer(strip_handles=True,preserve_case=False)\n",
        "mystopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "#Function to tokenize tweets, remove stopwords and numbers. \n",
        "#Keeping punctuations and emoticon symbols could be relevant for this task!\n",
        "def preprocess_corpus(texts):\n",
        "    def remove_stops_digits(tokens):\n",
        "        #Nested function that removes stopwords and digits from a list of tokens\n",
        "        return [token for token in tokens if token not in mystopwords and not token.isdigit()]\n",
        "    #This return statement below uses the above function to process twitter tokenizer output further. \n",
        "    return [remove_stops_digits(tweeter.tokenize(content)) for content in texts]\n",
        "    #explain return: tach texts thanh tung cau van nho, tung cau van nay se duoc \n",
        "    # token thanh tung tu, sau do se remove stopwords va digit cac tu nay\n",
        "#df_subset contains only the three categories we chose. \n",
        "mydata = preprocess_corpus(df_subset['content'])\n",
        "mycats = df_subset['sentiment']\n",
        "print(len(mydata), len(mycats))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22306 22306\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwzED_gJbpSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f770e1fd-8e3b-452d-b15c-a66a0cf08890"
      },
      "source": [
        "tweeter.tokenize('We want to trade with someone')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['we', 'want', 'to', 'trade', 'with', 'someone']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqQEkYIkZ80M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "912b5dd7-e1ef-4d8c-c04f-eb53cced0687"
      },
      "source": [
        "df_subset['content']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4        @dannycastillo We want to trade with someone w...\n",
              "5        Re-pinging @ghostridah14: why didn't you go to...\n",
              "7                     Hmmm. http://www.djhero.com/ is down\n",
              "10                                        cant fall asleep\n",
              "11                                 Choked on her retainers\n",
              "                               ...                        \n",
              "39992    @jasimmo Ooo showing of your French skills!! l...\n",
              "39993    @sendsome2me haha, yeah. Twitter has many uses...\n",
              "39994                        Succesfully following Tayla!!\n",
              "39995                                     @JohnLloydTaylor\n",
              "39998    @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
              "Name: content, Length: 22306, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAueqy9laFdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8167d570-6388-4c43-d8a5-ece832ee9864"
      },
      "source": [
        "mydata[:5] #after tweeter.tokenize and remove stopword, digit each toeknize"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['want', 'trade', 'someone', 'houston', 'tickets', ',', 'one', '.'],\n",
              " ['re-pinging', ':', 'go', 'prom', '?', 'bc', 'bf', 'like', 'friends'],\n",
              " ['hmmm', '.', 'http://www.djhero.com/'],\n",
              " ['cant', 'fall', 'asleep'],\n",
              " ['choked', 'retainers']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-zsxanfaD7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split data into train and test, following the usual process\n",
        "train_data, test_data, train_cats, test_cats = train_test_split(mydata,mycats,random_state=1234)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U-1crZCcPHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "40511489-cbaf-485c-9d89-7ba2b9339c36"
      },
      "source": [
        "print(len(mydata))\n",
        "print(len(train_data))\n",
        "print(len(test_data))\n",
        "print('split:',len(test_data)/len(mydata))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22306\n",
            "16729\n",
            "5577\n",
            "split: 0.25002241549358917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4F3Oev0cr7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0f355b96-ee36-4b84-d3f8-a242abe7d117"
      },
      "source": [
        "print(train_data[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['good', 'morning', 'plan', 'day', ':', 'church', 'followed', 'f1', '&', 'lunch', 'mum', '&', 'dads', '.', 'dm', 'discussions', 'star', 'trek', '!'], ['happy', 'anniversary', '.', 'know', 'whyyyy', '.', 'three', 'years', 'baby', '!', '!', '!'], ['never', '...'], ['lol', '...', 'maybe', '...', 'still', 'go', 'monday', '.'], ['got', 'home', 'leave']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNBeOrBlir_q",
        "colab_type": "text"
      },
      "source": [
        "The next step in this process is to train a Doc2vec model to learn tweet\n",
        "representations. Ideally, any large dataset of tweets will work for this step. However,\n",
        "since we don’t have such a ready-made corpus, we’ll split our dataset into train-test\n",
        "and use the training data for learning the Doc2vec representations. The first part of\n",
        "this process involves converting the data into a format readable by the Doc2vec\n",
        "implementation, which can be done using the TaggedDocument class. It’s used to\n",
        "represent a document as a list of tokens, followed by a “tag,” which in its simplest\n",
        "form can be just the filename or ID of the document. However, Doc2vec by itself\n",
        "can also be used as a nearest neighbor classifier for both multiclass and multilabel\n",
        "classification problems using . We’ll leave this as an exploratory exercise for the\n",
        "reader. Let’s now see how to train a Doc2vec classifier for tweets through the code\n",
        "snippet below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QWQDhfOcllJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ea057079-84b9-4908-9b2e-5e972d2653b8"
      },
      "source": [
        "#prepare training data in doc2vec format:\n",
        "train_doc2vec = [TaggedDocument((d), tags=[str(i)]) for i, d in enumerate(train_data)]\n",
        "train_doc2vec[:5]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['good', 'morning', 'plan', 'day', ':', 'church', 'followed', 'f1', '&', 'lunch', 'mum', '&', 'dads', '.', 'dm', 'discussions', 'star', 'trek', '!'], tags=['0']),\n",
              " TaggedDocument(words=['happy', 'anniversary', '.', 'know', 'whyyyy', '.', 'three', 'years', 'baby', '!', '!', '!'], tags=['1']),\n",
              " TaggedDocument(words=['never', '...'], tags=['2']),\n",
              " TaggedDocument(words=['lol', '...', 'maybe', '...', 'still', 'go', 'monday', '.'], tags=['3']),\n",
              " TaggedDocument(words=['got', 'home', 'leave'], tags=['4'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rsGwfVebb6Tl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "4693f844-d151-4000-ad1e-045578be1385"
      },
      "source": [
        "#Train a doc2vec model to learn tweet representations. Use only training data!!\n",
        "model = Doc2Vec(vector_size=50, alpha=0.025, min_count=10, dm =1, epochs=100)\n",
        "model.build_vocab(train_doc2vec)\n",
        "model.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "model.save(\"d2v.model\")\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5ox4QaVjfqV",
        "colab_type": "text"
      },
      "source": [
        "Training for Doc2vec involves making several choices regarding parameters, as seen\n",
        "in the model definition in the code snippet above. vector_size refers to the\n",
        "dimensionality of the learned embeddings; alpha is the learning rate; min_count\n",
        "is the minimum frequency of words that remain in vocabulary; dm, which stands for\n",
        "distributed memory, is one of the representation learners implemented in Doc2vec\n",
        "(the other is dbow, or distributed bag of words); and epochs are the number of\n",
        "training iterations. There are a few other parameters that can be customized. While\n",
        "there are some guidelines on choosing optimal parameters for training Doc2vec\n",
        "models [22], these are not exhaustively validated, and we don’t know if the\n",
        "guidelines work for tweets. \n",
        "\n",
        "The best way to address this issue is to explore a range of values for the ones that\n",
        "matter to us (e.g., dm versus dbow, vector sizes, learning rate) and compare\n",
        "multiple models. How do we compare these models, as they only learn the text\n",
        "representation? One way to do it is to start using these learned representations in a downstream task—in this case, text classification. Doc2vec’s infer_vector\n",
        "function can be used to infer the vector representation for a given text using a pretrained model. Since there is some amount of randomness due to the choice of\n",
        "hyperparameters, the inferred vectors differ each time we extract them. For this\n",
        "reason, to get a stable representation, we run it multiple times (called steps) and\n",
        "aggregate the vectors. Let’s use the learned model to infer features for our data and\n",
        "train a logistic regression classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v9C7WsQdB74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b96e6a7a-d66d-48ff-a8ae-7176a5e5c5b1"
      },
      "source": [
        "#Infer the feature representation for training and test data using the trained model\n",
        "model= Doc2Vec.load(\"d2v.model\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XndGXiLldEbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#infer in multiple steps to get a stable representation. \n",
        "train_vectors =  [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in train_data]\n",
        "test_vectors = [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in test_data]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL18Cu79dFqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "6a114f70-4952-491c-febe-bf2b8e645535"
      },
      "source": [
        "print(len(train_vectors))\n",
        "print(len(train_vectors[0]))\n",
        "train_vectors[:2]\n",
        "# train data khoang 16000 cau, do do train vector cung chua 16000 cau nay, tuy nhien\n",
        "# da duoc vector thanh 50 features bang model Doc2Vec (size=50)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16729\n",
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.6529503 , -0.51924896, -0.21210717,  0.14603347,  0.45059487,\n",
              "        -0.11474446, -0.52541053,  1.352756  ,  0.60549915,  0.57136095,\n",
              "         0.07941024, -0.30615112, -0.53190136,  0.31115034,  0.20471233,\n",
              "         0.32783344, -0.3623462 , -0.16501822, -1.110246  , -0.03500773,\n",
              "         0.35840616,  0.5518916 ,  0.6852925 ,  1.0789195 ,  0.36664835,\n",
              "         0.38964126,  0.9523874 ,  0.20698452,  0.42710775,  0.25844195,\n",
              "         1.057438  , -0.63624537,  0.34882364, -1.9149145 , -0.8416676 ,\n",
              "         0.23125714,  0.02937917,  0.19794124, -0.18933612,  0.96149725,\n",
              "         0.23230445,  0.70313305,  0.06039672,  0.22982568, -0.36523342,\n",
              "        -0.346476  ,  0.7458607 , -0.8421915 , -0.33843362,  1.4140338 ],\n",
              "       dtype=float32),\n",
              " array([-0.10650355, -0.22520047,  0.10830083,  0.17515166, -1.2132022 ,\n",
              "         0.06870602,  0.72229046,  0.5370227 , -0.7329244 , -0.2182864 ,\n",
              "        -0.53772664, -0.7481025 , -0.46327096, -0.02487552,  0.51938653,\n",
              "        -0.10405631, -0.82948583,  0.73951143, -0.10000248,  0.45213482,\n",
              "        -0.24404974, -0.3922797 , -0.4357392 , -0.6341866 , -0.36092228,\n",
              "         0.02898073, -0.10862037, -0.38292894,  0.01031657,  0.11843861,\n",
              "         0.14142652,  0.15990129,  0.20437238, -0.6347779 ,  0.1788738 ,\n",
              "         0.38413477,  0.22114843,  0.33797514,  0.5887276 , -0.7023044 ,\n",
              "        -0.69930524, -0.78718346, -0.8026394 , -0.5496059 ,  0.6761916 ,\n",
              "         0.02494031, -0.30303925, -0.3144585 ,  0.8323039 ,  0.00465085],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hTqo26Vsb6Ts",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "29e21caa-629f-43ac-bf07-863412b82843"
      },
      "source": [
        "#Use any regular classifier like logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "myclass = LogisticRegression(class_weight=\"balanced\") #because classes are not balanced. \n",
        "myclass.fit(train_vectors, train_cats)\n",
        "\n",
        "preds = myclass.predict(test_vectors)\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(test_cats, preds))\n",
        "\n",
        "#print(confusion_matrix(test_cats,preds))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   happiness       0.47      0.55      0.51      1331\n",
            "     neutral       0.49      0.55      0.52      2143\n",
            "       worry       0.57      0.43      0.49      2103\n",
            "\n",
            "    accuracy                           0.51      5577\n",
            "   macro avg       0.51      0.51      0.51      5577\n",
            "weighted avg       0.51      0.51      0.51      5577\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhDeIHaHjyTw",
        "colab_type": "text"
      },
      "source": [
        "Now, the performance of this model seems rather poor, achieving an F1 score of\n",
        "0.51 on a reasonably large corpus, with only three classes. There are a couple of\n",
        "interpretations for this poor result. First, unlike full news articles or even wellformed sentences, tweets contain very little data per instance. Further, people write\n",
        "with a wide variety in spelling and syntax when they tweet. There are a lot of\n",
        "emoticons in different forms. Our feature representation should be able to capture\n",
        "such aspects. While tuning the algorithms by searching a large parameter space for\n",
        "the best model may help, an alternative could be to explore problem-specific feature\n",
        "representations, as we discussed in Chapter 3. We’ll see how to do this for tweets in\n",
        "Chapter 8. An important point to keep in mind when using Doc2vec is the same as\n",
        "for fastText: if we have to use Doc2vec for feature representation, we have to store\n",
        "the model that learned the representation. While it’s not typically as bulky as\n",
        "fastText, it’s also not as fast to train. Such trade-offs need to be considered and\n",
        "compared before we make a deployment decision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9leSmbIvGZuJ",
        "colab_type": "text"
      },
      "source": [
        "# Investigate more Doc2Vec train (DNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58oKqEBRJV0k",
        "colab_type": "text"
      },
      "source": [
        "https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAitkhDjICN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import all the dependencies\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jigZzcAJIeNO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4f7e40c0-1e4a-477e-f243-92e3f329dcab"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pytdxc5FIYw1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "933f53d6-e9d0-477c-cc30-a4abc43751a2"
      },
      "source": [
        "data = [\"I love machine learning. Its awesome.\",\n",
        "        \"I love coding in python\",\n",
        "        \"I love building chatbots\",\n",
        "        \"they chat amagingly well\"]\n",
        "\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n",
        "tagged_data"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['i', 'love', 'machine', 'learning', '.', 'its', 'awesome', '.'], tags=['0']),\n",
              " TaggedDocument(words=['i', 'love', 'coding', 'in', 'python'], tags=['1']),\n",
              " TaggedDocument(words=['i', 'love', 'building', 'chatbots'], tags=['2']),\n",
              " TaggedDocument(words=['they', 'chat', 'amagingly', 'well'], tags=['3'])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSA27UF5IZEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epochs = 100\n",
        "vec_size = 20\n",
        "alpha = 0.025\n",
        "\n",
        "model = Doc2Vec(size=vec_size,\n",
        "                alpha=alpha, \n",
        "                min_alpha=0.00025,\n",
        "                min_count=1,\n",
        "                dm =1)\n",
        "  \n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    model.train(tagged_data,\n",
        "                total_examples=model.corpus_count,\n",
        "                epochs=model.iter)\n",
        "    # decrease the learning rate\n",
        "    model.alpha -= 0.0002\n",
        "    # fix the learning rate, no decay\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "model.save(\"d2v.model\")\n",
        "print(\"Model Saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRg8DXHvImqM",
        "colab_type": "text"
      },
      "source": [
        "Note: dm defines the training algorithm. If dm=1 means ‘distributed memory’ (PV-DM) and dm =0 means ‘distributed bag of words’ (PV-DBOW). Distributed Memory model preserves the word order in a document whereas Distributed Bag of words just uses the bag of words approach, which doesn’t preserve any word order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkz28u6zIZHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "fc256267-3459-40df-8aa9-0a64f54d3622"
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec\n",
        "\n",
        "model= Doc2Vec.load(\"d2v.model\")\n",
        "#to find the vector of a document which is not in training data\n",
        "test_data = word_tokenize(\"I love chatbots\".lower())\n",
        "v1 = model.infer_vector(test_data)\n",
        "print(\"V1_infer_len\", len(v1))\n",
        "print(\"V1_infer\", v1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "V1_infer_len 20\n",
            "V1_infer [-0.00878063 -0.00544482  0.01080374 -0.01708308  0.0016778   0.00359283\n",
            "  0.01627675 -0.02149624 -0.03383703  0.0141253   0.01244494  0.02691077\n",
            " -0.01086808 -0.00988033 -0.0126295  -0.00034494 -0.00372593  0.01453551\n",
            " -0.00773452 -0.00319144]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiVjXEZPIZKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "faad01ae-2f9f-4af1-cdbe-9e7125e6cb68"
      },
      "source": [
        "# to find most similar doc using tags\n",
        "similar_doc = model.docvecs.most_similar('1')\n",
        "print(similar_doc)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('2', 0.9919646382331848), ('0', 0.9868806600570679), ('3', 0.9820027351379395)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qTAVqa8IZNF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "255eb494-baae-4730-ab36-4a91e49916ac"
      },
      "source": [
        "# to find vector of doc in training data using tags or in other words, printing the vector of document at index 1 in training data\n",
        "print(model.docvecs['1'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.02395858 -0.09486863  0.2664889   0.30889022  0.02167329  0.11899626\n",
            "  0.15026924  0.05626415 -0.52175915  0.1065143   0.45151034  0.13679758\n",
            " -0.01897911  0.10781869 -0.08501073 -0.09515668  0.26260602  0.15917566\n",
            "  0.1775172   0.36418226]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfYDO-JFdkPR",
        "colab_type": "text"
      },
      "source": [
        "# Multi-Class Text Classification with Doc2Vec & Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg4_30Qydl4r",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/multi-class-text-classification-with-doc2vec-logistic-regression-9da9947b43f4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Brb8ESdnRJ",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/susanli2016/NLP-with-Python/blob/master/Doc2Vec%20Consumer%20Complaint_3.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDhtbkAgI2ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3UH1zYwdoRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}