{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec_Example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sVtvH58nb_Hp"
      },
      "source": [
        "# Word2Vec for Text Classification\n",
        "\n",
        "In this short notebook, we will see an example of how to use a pre-trained Word2vec model for doing feature extraction and performing text classification.\n",
        "\n",
        "We will use the sentiment labelled sentences dataset from UCI repository\n",
        "http://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
        "\n",
        "The dataset consists of 1500 positive, and 1500 negative sentiment sentences from Amazon, Yelp, IMDB. Let us first combine all the three separate data files into one using the following unix command:\n",
        "\n",
        "```cat amazon_cells_labelled.txt imdb_labelled.txt yelp_labelled.txt > sentiment_sentences.txt```\n",
        "\n",
        "For a pre-trained embedding model, we will use the Google News vectors.\n",
        "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
        "\n",
        "Let us get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JQX8DAmBb_Hr",
        "colab": {}
      },
      "source": [
        "#basic imports\n",
        "import os\n",
        "from time import time\n",
        "\n",
        "#pre-processing imports\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "#imports related to modeling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww39Tp4uNHtT",
        "colab_type": "text"
      },
      "source": [
        "#Word2vector by another lib (DNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88-MfyXJNNZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors #To load the model\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') #ignore any generated warnings\n",
        "import numpy as np\n",
        "# load model\n",
        "path='https://github.com/practical-nlp/practical-nlp/blob/master/Ch3/Models/word2vec_cbow.bin?raw=true'\n",
        "model_new = KeyedVectors.load_word2vec_format(path, binary=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHDURxxQNNcD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8685dd2-f037-49f8-92b0-623e0c58ca0b"
      },
      "source": [
        "model_new"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7fa9713a8ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU_H0xfITD_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec295b5c-db02-4ee9-a6e8-11649522af60"
      },
      "source": [
        "# Inspect the model\n",
        "word2vec_vocab_new = model_new.vocab.keys()\n",
        "word2vec_vocab_lower_new = [item.lower() for item in word2vec_vocab_new]\n",
        "print(len(word2vec_vocab_new))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "161018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shmk89KITZRw",
        "colab_type": "text"
      },
      "source": [
        "Model nay chi co 161,000 tu, kem hon nhieu model cua google la 3,000,000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8pxR1N6ND-p",
        "colab_type": "text"
      },
      "source": [
        "# Word2vector by googlenew"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC-Zgd1yLyzc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "0cc65d6d-b673-4806-bb7c-11541746f5a2"
      },
      "source": [
        "#download google new vectors (other tool than word2vector)\n",
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: brew: command not found\n",
            "--2020-08-01 04:02:29--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.129.237\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.129.237|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  32.0MB/s    in 50s     \n",
            "\n",
            "2020-08-01 04:03:20 (31.2 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKb-sf9gKE5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7a6e1fd6-53d4-4d9f-bdb2-9a2e9d2209b0"
      },
      "source": [
        "path_to_model = '/content/GoogleNews-vectors-negative300.bin.gz'\n",
        "#Load W2V model. This will take some time. \n",
        "%time w2v_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
        "print('done loading Word2Vec')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 53s, sys: 4.09 s, total: 1min 57s\n",
            "Wall time: 1min 57s\n",
            "done loading Word2Vec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "COUGXAxcb_H5",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "training_data_path = '/content/drive/My Drive/Data/NLP/sentiment_all.txt'\n",
        "#Read text data, cats.\n",
        "#the file path consists of tab separated sentences and cats.\n",
        "texts = []\n",
        "cats = []\n",
        "fh = open(training_data_path)\n",
        "for line in fh:\n",
        "    text, sentiment = line.split(\"\\t\")\n",
        "    texts.append(text)\n",
        "    cats.append(sentiment)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m-WjFyC6b_IE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1c4f087-3f2a-4b31-cc29-ea90494c36c5"
      },
      "source": [
        "# Inspect the model\n",
        "word2vec_vocab = w2v_model.vocab.keys()\n",
        "word2vec_vocab_lower = [item.lower() for item in word2vec_vocab]\n",
        "print(len(word2vec_vocab))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XEz30Jztb_IP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ffcf2a95-cd9b-4bb4-e0f4-716c8cfd93ba"
      },
      "source": [
        "#Inspect the dataset\n",
        "print(len(cats), len(texts))\n",
        "print(texts[1])\n",
        "print(cats[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000 3000\n",
            "Good case, Excellent value.\n",
            "1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbVvD0V1PyYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6d0d3bec-4bad-4e8c-9f33-e1482cdca28f"
      },
      "source": [
        "#Preprocessing our models vocabulary to make better visualizations\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MFOGaDTwb_Ig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1d991400-d399-4a76-c6e2-3ca6adea020c"
      },
      "source": [
        "#preprocess the text.\n",
        "def preprocess_corpus(texts):\n",
        "    mystopwords = set(stopwords.words(\"english\"))\n",
        "    def remove_stops_digits(tokens):\n",
        "        #Nested function that lowercases, removes stopwords and digits from a list of tokens\n",
        "        return [token.lower() for token in tokens if token not in mystopwords and not token.isdigit()\n",
        "               and token not in punctuation]\n",
        "    #This return statement below uses the above function to process twitter tokenizer output further. \n",
        "    return [remove_stops_digits(word_tokenize(text)) for text in texts]\n",
        "    #Tach rieng tung tu trong cau (word_tokenize) sau do lowercases, bo dau,stopword \n",
        "    #va so ra khoi tung tu\n",
        "\n",
        "texts_processed = preprocess_corpus(texts)\n",
        "print(len(cats), len(texts_processed))\n",
        "print(texts_processed[1])\n",
        "print(cats[1])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000 3000\n",
            "['good', 'case', 'excellent', 'value']\n",
            "1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEXz9twLQ1pL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "95da73c0-94a8-48b4-dce8-bcc1a48b0f8a"
      },
      "source": [
        "texts_processed[:5]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['so', 'way', 'plug', 'us', 'unless', 'i', 'go', 'converter'],\n",
              " ['good', 'case', 'excellent', 'value'],\n",
              " ['great', 'jawbone'],\n",
              " ['tied', 'charger', 'conversations', 'lasting', 'minutes.major', 'problems'],\n",
              " ['the', 'mic', 'great']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fXRiGtY1b_Iq",
        "colab": {}
      },
      "source": [
        "# Creating a feature vector by averaging all embeddings for all sentences\n",
        "def embedding_feats(list_of_lists):\n",
        "    DIMENSION = 300\n",
        "    zero_vector = np.zeros(DIMENSION)\n",
        "    feats = []\n",
        "    for tokens in list_of_lists: # trich tung cau sentiments trong toan van ban\n",
        "        feat_for_this =  np.zeros(DIMENSION)\n",
        "        count_for_this = 0\n",
        "        # tach tung tu trong 1 cau sentiments, chuyen sang vector kich thuoc 300\n",
        "        for token in tokens: #['so', 'way', 'plug', 'us', 'unless', 'i', 'go', 'converter'],\n",
        "            if token in w2v_model: #'so'...\n",
        "                feat_for_this += w2v_model[token] # 300 dimension\n",
        "                count_for_this +=1\n",
        "        feats.append(feat_for_this/count_for_this)    \n",
        "        # cong tat ca token vector cua tung tu trong 1 sentiment va \n",
        "        #chia tong lay trung binh     \n",
        "    return feats # return tung sentiment da duoc vector (300 dim)\n",
        "\n",
        "train_vectors = embedding_feats(texts_processed)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52AdcnYSVKzy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6b27f8c4-ac46-4d19-da09-f120649f65ca"
      },
      "source": [
        "print(len(train_vectors))\n",
        "print(len(train_vectors[0]))\n",
        "# train_vectors chua 3000 tu sentiment da duoc convert sang vector 300 dim"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT002Mn0mAGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "a4b0f79d-d6c7-4f02-bf62-30c34c2df4c3"
      },
      "source": [
        "train_vectors_df=pd.DataFrame(train_vectors)\n",
        "train_vectors_df"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.021805</td>\n",
              "      <td>-0.023468</td>\n",
              "      <td>-0.012323</td>\n",
              "      <td>0.077515</td>\n",
              "      <td>-0.088196</td>\n",
              "      <td>0.070930</td>\n",
              "      <td>-0.010033</td>\n",
              "      <td>-0.075729</td>\n",
              "      <td>0.082336</td>\n",
              "      <td>0.057972</td>\n",
              "      <td>-0.073334</td>\n",
              "      <td>-0.118927</td>\n",
              "      <td>-0.122688</td>\n",
              "      <td>-0.087128</td>\n",
              "      <td>-0.136826</td>\n",
              "      <td>0.062119</td>\n",
              "      <td>0.135101</td>\n",
              "      <td>0.089153</td>\n",
              "      <td>0.032700</td>\n",
              "      <td>-0.051884</td>\n",
              "      <td>0.050720</td>\n",
              "      <td>0.115067</td>\n",
              "      <td>0.087708</td>\n",
              "      <td>0.046097</td>\n",
              "      <td>0.115997</td>\n",
              "      <td>0.074646</td>\n",
              "      <td>-0.053223</td>\n",
              "      <td>0.003174</td>\n",
              "      <td>0.038960</td>\n",
              "      <td>-0.000963</td>\n",
              "      <td>-0.031982</td>\n",
              "      <td>0.090088</td>\n",
              "      <td>-0.081940</td>\n",
              "      <td>-0.036938</td>\n",
              "      <td>-0.041351</td>\n",
              "      <td>-0.024971</td>\n",
              "      <td>0.025858</td>\n",
              "      <td>-0.040695</td>\n",
              "      <td>0.027710</td>\n",
              "      <td>0.074799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000793</td>\n",
              "      <td>0.009430</td>\n",
              "      <td>-0.118835</td>\n",
              "      <td>0.055084</td>\n",
              "      <td>-0.012728</td>\n",
              "      <td>0.103458</td>\n",
              "      <td>0.026917</td>\n",
              "      <td>-0.076813</td>\n",
              "      <td>-0.062988</td>\n",
              "      <td>-0.026306</td>\n",
              "      <td>0.024513</td>\n",
              "      <td>0.041832</td>\n",
              "      <td>0.065262</td>\n",
              "      <td>0.108101</td>\n",
              "      <td>0.064667</td>\n",
              "      <td>-0.117340</td>\n",
              "      <td>-0.060623</td>\n",
              "      <td>-0.188507</td>\n",
              "      <td>-0.071335</td>\n",
              "      <td>-0.021705</td>\n",
              "      <td>-0.055595</td>\n",
              "      <td>-0.043552</td>\n",
              "      <td>0.024734</td>\n",
              "      <td>0.102722</td>\n",
              "      <td>0.052923</td>\n",
              "      <td>-0.022774</td>\n",
              "      <td>-0.005280</td>\n",
              "      <td>-0.163971</td>\n",
              "      <td>0.059113</td>\n",
              "      <td>0.065811</td>\n",
              "      <td>-0.002777</td>\n",
              "      <td>0.200783</td>\n",
              "      <td>-0.159241</td>\n",
              "      <td>0.056152</td>\n",
              "      <td>-0.044449</td>\n",
              "      <td>0.066162</td>\n",
              "      <td>-0.081963</td>\n",
              "      <td>-0.027138</td>\n",
              "      <td>-0.020218</td>\n",
              "      <td>-0.012622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.008728</td>\n",
              "      <td>0.038536</td>\n",
              "      <td>-0.037689</td>\n",
              "      <td>0.037628</td>\n",
              "      <td>0.028809</td>\n",
              "      <td>0.133072</td>\n",
              "      <td>0.104202</td>\n",
              "      <td>0.012512</td>\n",
              "      <td>0.081543</td>\n",
              "      <td>0.196411</td>\n",
              "      <td>-0.115005</td>\n",
              "      <td>-0.107529</td>\n",
              "      <td>0.068542</td>\n",
              "      <td>0.103210</td>\n",
              "      <td>-0.134033</td>\n",
              "      <td>0.164795</td>\n",
              "      <td>0.115723</td>\n",
              "      <td>0.092094</td>\n",
              "      <td>-0.059814</td>\n",
              "      <td>-0.100784</td>\n",
              "      <td>0.021362</td>\n",
              "      <td>-0.035645</td>\n",
              "      <td>-0.050537</td>\n",
              "      <td>0.094482</td>\n",
              "      <td>0.137604</td>\n",
              "      <td>0.041683</td>\n",
              "      <td>-0.105106</td>\n",
              "      <td>0.072327</td>\n",
              "      <td>-0.006805</td>\n",
              "      <td>0.044296</td>\n",
              "      <td>-0.012909</td>\n",
              "      <td>-0.116348</td>\n",
              "      <td>0.121216</td>\n",
              "      <td>-0.000488</td>\n",
              "      <td>0.149689</td>\n",
              "      <td>0.167114</td>\n",
              "      <td>0.041199</td>\n",
              "      <td>-0.017685</td>\n",
              "      <td>-0.041260</td>\n",
              "      <td>-0.036560</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.029236</td>\n",
              "      <td>0.029541</td>\n",
              "      <td>-0.143555</td>\n",
              "      <td>0.021240</td>\n",
              "      <td>0.074188</td>\n",
              "      <td>0.059509</td>\n",
              "      <td>-0.015442</td>\n",
              "      <td>-0.144836</td>\n",
              "      <td>-0.082108</td>\n",
              "      <td>-0.081055</td>\n",
              "      <td>0.032013</td>\n",
              "      <td>0.058167</td>\n",
              "      <td>0.023254</td>\n",
              "      <td>-0.019363</td>\n",
              "      <td>0.031860</td>\n",
              "      <td>0.058075</td>\n",
              "      <td>0.086731</td>\n",
              "      <td>-0.123718</td>\n",
              "      <td>-0.131104</td>\n",
              "      <td>0.055725</td>\n",
              "      <td>0.019104</td>\n",
              "      <td>0.010284</td>\n",
              "      <td>0.087404</td>\n",
              "      <td>0.148438</td>\n",
              "      <td>-0.115295</td>\n",
              "      <td>-0.013916</td>\n",
              "      <td>-0.064751</td>\n",
              "      <td>-0.021637</td>\n",
              "      <td>-0.042667</td>\n",
              "      <td>-0.012558</td>\n",
              "      <td>0.024460</td>\n",
              "      <td>0.058664</td>\n",
              "      <td>-0.113159</td>\n",
              "      <td>-0.009438</td>\n",
              "      <td>0.023499</td>\n",
              "      <td>0.132477</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>-0.120605</td>\n",
              "      <td>-0.032248</td>\n",
              "      <td>-0.031235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.013550</td>\n",
              "      <td>0.137695</td>\n",
              "      <td>-0.085022</td>\n",
              "      <td>0.136475</td>\n",
              "      <td>-0.062500</td>\n",
              "      <td>0.126953</td>\n",
              "      <td>0.119873</td>\n",
              "      <td>0.034424</td>\n",
              "      <td>0.105591</td>\n",
              "      <td>0.085693</td>\n",
              "      <td>0.069214</td>\n",
              "      <td>-0.204102</td>\n",
              "      <td>-0.174805</td>\n",
              "      <td>0.014648</td>\n",
              "      <td>-0.057495</td>\n",
              "      <td>0.013428</td>\n",
              "      <td>-0.018066</td>\n",
              "      <td>0.282227</td>\n",
              "      <td>-0.061157</td>\n",
              "      <td>-0.183105</td>\n",
              "      <td>0.011466</td>\n",
              "      <td>-0.052734</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.144775</td>\n",
              "      <td>-0.082520</td>\n",
              "      <td>-0.003906</td>\n",
              "      <td>-0.175049</td>\n",
              "      <td>-0.037964</td>\n",
              "      <td>0.219604</td>\n",
              "      <td>-0.019043</td>\n",
              "      <td>-0.147217</td>\n",
              "      <td>0.035767</td>\n",
              "      <td>0.112549</td>\n",
              "      <td>-0.046875</td>\n",
              "      <td>0.119873</td>\n",
              "      <td>-0.130463</td>\n",
              "      <td>-0.133789</td>\n",
              "      <td>0.123199</td>\n",
              "      <td>0.097969</td>\n",
              "      <td>0.201660</td>\n",
              "      <td>...</td>\n",
              "      <td>0.190430</td>\n",
              "      <td>-0.050781</td>\n",
              "      <td>-0.310059</td>\n",
              "      <td>0.272278</td>\n",
              "      <td>0.068237</td>\n",
              "      <td>0.250732</td>\n",
              "      <td>-0.063477</td>\n",
              "      <td>-0.370361</td>\n",
              "      <td>0.058411</td>\n",
              "      <td>-0.029327</td>\n",
              "      <td>-0.262695</td>\n",
              "      <td>0.319336</td>\n",
              "      <td>0.083527</td>\n",
              "      <td>-0.032532</td>\n",
              "      <td>0.183350</td>\n",
              "      <td>-0.054932</td>\n",
              "      <td>0.035156</td>\n",
              "      <td>-0.147949</td>\n",
              "      <td>-0.265625</td>\n",
              "      <td>-0.128296</td>\n",
              "      <td>0.155518</td>\n",
              "      <td>-0.079834</td>\n",
              "      <td>-0.041809</td>\n",
              "      <td>-0.029541</td>\n",
              "      <td>-0.166077</td>\n",
              "      <td>0.059265</td>\n",
              "      <td>-0.144531</td>\n",
              "      <td>0.042297</td>\n",
              "      <td>0.101074</td>\n",
              "      <td>-0.115295</td>\n",
              "      <td>0.026001</td>\n",
              "      <td>0.096191</td>\n",
              "      <td>-0.091553</td>\n",
              "      <td>0.105835</td>\n",
              "      <td>-0.081177</td>\n",
              "      <td>0.123535</td>\n",
              "      <td>0.049683</td>\n",
              "      <td>-0.166504</td>\n",
              "      <td>0.034485</td>\n",
              "      <td>-0.098877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.031543</td>\n",
              "      <td>0.064844</td>\n",
              "      <td>-0.028577</td>\n",
              "      <td>0.068555</td>\n",
              "      <td>-0.035107</td>\n",
              "      <td>-0.016791</td>\n",
              "      <td>0.007568</td>\n",
              "      <td>-0.080078</td>\n",
              "      <td>0.246140</td>\n",
              "      <td>0.075586</td>\n",
              "      <td>-0.108691</td>\n",
              "      <td>-0.031006</td>\n",
              "      <td>-0.105176</td>\n",
              "      <td>0.057227</td>\n",
              "      <td>0.104785</td>\n",
              "      <td>0.032568</td>\n",
              "      <td>0.209521</td>\n",
              "      <td>0.152539</td>\n",
              "      <td>0.005859</td>\n",
              "      <td>-0.112531</td>\n",
              "      <td>0.039551</td>\n",
              "      <td>0.065967</td>\n",
              "      <td>-0.044873</td>\n",
              "      <td>0.008838</td>\n",
              "      <td>-0.028918</td>\n",
              "      <td>0.082715</td>\n",
              "      <td>-0.191895</td>\n",
              "      <td>0.098730</td>\n",
              "      <td>0.035083</td>\n",
              "      <td>-0.159668</td>\n",
              "      <td>-0.052832</td>\n",
              "      <td>-0.004248</td>\n",
              "      <td>-0.016187</td>\n",
              "      <td>0.047314</td>\n",
              "      <td>0.062176</td>\n",
              "      <td>-0.066016</td>\n",
              "      <td>0.128503</td>\n",
              "      <td>-0.030957</td>\n",
              "      <td>-0.033203</td>\n",
              "      <td>0.013525</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.010013</td>\n",
              "      <td>0.163110</td>\n",
              "      <td>-0.158057</td>\n",
              "      <td>-0.052100</td>\n",
              "      <td>-0.020117</td>\n",
              "      <td>0.181372</td>\n",
              "      <td>0.044727</td>\n",
              "      <td>-0.089648</td>\n",
              "      <td>-0.139404</td>\n",
              "      <td>0.050195</td>\n",
              "      <td>0.097314</td>\n",
              "      <td>0.038574</td>\n",
              "      <td>0.048340</td>\n",
              "      <td>-0.043213</td>\n",
              "      <td>0.095020</td>\n",
              "      <td>-0.058008</td>\n",
              "      <td>-0.109491</td>\n",
              "      <td>-0.022559</td>\n",
              "      <td>0.015045</td>\n",
              "      <td>-0.093066</td>\n",
              "      <td>0.137183</td>\n",
              "      <td>-0.095215</td>\n",
              "      <td>0.054492</td>\n",
              "      <td>0.057715</td>\n",
              "      <td>-0.061719</td>\n",
              "      <td>-0.134814</td>\n",
              "      <td>0.035596</td>\n",
              "      <td>0.047705</td>\n",
              "      <td>0.024121</td>\n",
              "      <td>-0.021048</td>\n",
              "      <td>0.056494</td>\n",
              "      <td>0.126758</td>\n",
              "      <td>0.044019</td>\n",
              "      <td>-0.022070</td>\n",
              "      <td>-0.120947</td>\n",
              "      <td>0.042334</td>\n",
              "      <td>-0.157031</td>\n",
              "      <td>-0.139941</td>\n",
              "      <td>0.023798</td>\n",
              "      <td>0.066406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.043498</td>\n",
              "      <td>-0.009603</td>\n",
              "      <td>-0.090535</td>\n",
              "      <td>0.072144</td>\n",
              "      <td>0.026489</td>\n",
              "      <td>-0.030762</td>\n",
              "      <td>0.028158</td>\n",
              "      <td>-0.038411</td>\n",
              "      <td>0.039469</td>\n",
              "      <td>0.102498</td>\n",
              "      <td>-0.114746</td>\n",
              "      <td>-0.093424</td>\n",
              "      <td>0.142314</td>\n",
              "      <td>-0.089844</td>\n",
              "      <td>-0.008952</td>\n",
              "      <td>0.062826</td>\n",
              "      <td>0.069316</td>\n",
              "      <td>0.208252</td>\n",
              "      <td>0.016846</td>\n",
              "      <td>-0.202271</td>\n",
              "      <td>0.142613</td>\n",
              "      <td>0.215820</td>\n",
              "      <td>-0.008382</td>\n",
              "      <td>-0.002556</td>\n",
              "      <td>-0.059245</td>\n",
              "      <td>0.049927</td>\n",
              "      <td>-0.074870</td>\n",
              "      <td>0.133708</td>\n",
              "      <td>0.086421</td>\n",
              "      <td>-0.049479</td>\n",
              "      <td>-0.181722</td>\n",
              "      <td>0.123820</td>\n",
              "      <td>-0.024495</td>\n",
              "      <td>0.056773</td>\n",
              "      <td>-0.002035</td>\n",
              "      <td>-0.064087</td>\n",
              "      <td>-0.012044</td>\n",
              "      <td>-0.024394</td>\n",
              "      <td>-0.028437</td>\n",
              "      <td>0.025391</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.122518</td>\n",
              "      <td>-0.065918</td>\n",
              "      <td>-0.095378</td>\n",
              "      <td>-0.011515</td>\n",
              "      <td>-0.035563</td>\n",
              "      <td>0.112630</td>\n",
              "      <td>-0.098928</td>\n",
              "      <td>-0.035238</td>\n",
              "      <td>-0.088664</td>\n",
              "      <td>0.007711</td>\n",
              "      <td>-0.134033</td>\n",
              "      <td>0.058512</td>\n",
              "      <td>-0.069275</td>\n",
              "      <td>-0.005737</td>\n",
              "      <td>0.138265</td>\n",
              "      <td>-0.068970</td>\n",
              "      <td>-0.001709</td>\n",
              "      <td>-0.077393</td>\n",
              "      <td>-0.168945</td>\n",
              "      <td>-0.028768</td>\n",
              "      <td>0.082438</td>\n",
              "      <td>-0.040482</td>\n",
              "      <td>0.040955</td>\n",
              "      <td>0.033366</td>\n",
              "      <td>0.122030</td>\n",
              "      <td>-0.052450</td>\n",
              "      <td>-0.039225</td>\n",
              "      <td>-0.063965</td>\n",
              "      <td>-0.070496</td>\n",
              "      <td>-0.068237</td>\n",
              "      <td>0.059652</td>\n",
              "      <td>0.122762</td>\n",
              "      <td>-0.187927</td>\n",
              "      <td>0.058105</td>\n",
              "      <td>-0.168864</td>\n",
              "      <td>-0.093038</td>\n",
              "      <td>-0.035116</td>\n",
              "      <td>-0.143311</td>\n",
              "      <td>-0.147339</td>\n",
              "      <td>-0.002116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>-0.032674</td>\n",
              "      <td>0.091064</td>\n",
              "      <td>0.015493</td>\n",
              "      <td>0.094808</td>\n",
              "      <td>-0.048747</td>\n",
              "      <td>0.081726</td>\n",
              "      <td>0.122030</td>\n",
              "      <td>-0.169922</td>\n",
              "      <td>-0.091431</td>\n",
              "      <td>0.130778</td>\n",
              "      <td>-0.029541</td>\n",
              "      <td>-0.157694</td>\n",
              "      <td>-0.047526</td>\n",
              "      <td>0.004069</td>\n",
              "      <td>-0.093602</td>\n",
              "      <td>0.149862</td>\n",
              "      <td>0.004845</td>\n",
              "      <td>0.167470</td>\n",
              "      <td>-0.014567</td>\n",
              "      <td>-0.207723</td>\n",
              "      <td>-0.120565</td>\n",
              "      <td>-0.001684</td>\n",
              "      <td>0.166606</td>\n",
              "      <td>0.030195</td>\n",
              "      <td>-0.017293</td>\n",
              "      <td>-0.097760</td>\n",
              "      <td>-0.065063</td>\n",
              "      <td>0.053752</td>\n",
              "      <td>-0.005381</td>\n",
              "      <td>-0.024740</td>\n",
              "      <td>-0.081340</td>\n",
              "      <td>0.057780</td>\n",
              "      <td>0.059814</td>\n",
              "      <td>0.090953</td>\n",
              "      <td>-0.040059</td>\n",
              "      <td>0.006266</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>-0.026815</td>\n",
              "      <td>-0.039693</td>\n",
              "      <td>0.117778</td>\n",
              "      <td>...</td>\n",
              "      <td>0.081278</td>\n",
              "      <td>-0.069427</td>\n",
              "      <td>-0.172567</td>\n",
              "      <td>-0.080404</td>\n",
              "      <td>0.010905</td>\n",
              "      <td>-0.028687</td>\n",
              "      <td>-0.102376</td>\n",
              "      <td>-0.160156</td>\n",
              "      <td>-0.099019</td>\n",
              "      <td>-0.171224</td>\n",
              "      <td>-0.070986</td>\n",
              "      <td>0.038778</td>\n",
              "      <td>0.101156</td>\n",
              "      <td>0.003438</td>\n",
              "      <td>-0.003352</td>\n",
              "      <td>-0.068120</td>\n",
              "      <td>-0.113617</td>\n",
              "      <td>-0.106669</td>\n",
              "      <td>-0.135025</td>\n",
              "      <td>0.020406</td>\n",
              "      <td>-0.034515</td>\n",
              "      <td>-0.068746</td>\n",
              "      <td>0.125854</td>\n",
              "      <td>0.152344</td>\n",
              "      <td>-0.118217</td>\n",
              "      <td>-0.051310</td>\n",
              "      <td>-0.072591</td>\n",
              "      <td>-0.061076</td>\n",
              "      <td>-0.006036</td>\n",
              "      <td>0.127706</td>\n",
              "      <td>-0.161418</td>\n",
              "      <td>0.000244</td>\n",
              "      <td>-0.024841</td>\n",
              "      <td>0.091024</td>\n",
              "      <td>0.013672</td>\n",
              "      <td>-0.054436</td>\n",
              "      <td>0.010050</td>\n",
              "      <td>-0.049377</td>\n",
              "      <td>0.014623</td>\n",
              "      <td>0.028987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>0.072866</td>\n",
              "      <td>0.111328</td>\n",
              "      <td>-0.058431</td>\n",
              "      <td>0.064819</td>\n",
              "      <td>-0.139486</td>\n",
              "      <td>-0.028158</td>\n",
              "      <td>-0.012207</td>\n",
              "      <td>-0.164714</td>\n",
              "      <td>0.034587</td>\n",
              "      <td>0.094320</td>\n",
              "      <td>-0.041829</td>\n",
              "      <td>-0.186523</td>\n",
              "      <td>-0.050802</td>\n",
              "      <td>-0.001561</td>\n",
              "      <td>-0.097860</td>\n",
              "      <td>0.094401</td>\n",
              "      <td>0.203927</td>\n",
              "      <td>0.138672</td>\n",
              "      <td>0.235514</td>\n",
              "      <td>-0.121613</td>\n",
              "      <td>-0.022705</td>\n",
              "      <td>-0.094401</td>\n",
              "      <td>-0.051666</td>\n",
              "      <td>0.161784</td>\n",
              "      <td>0.069233</td>\n",
              "      <td>-0.017375</td>\n",
              "      <td>-0.002370</td>\n",
              "      <td>0.120768</td>\n",
              "      <td>0.140462</td>\n",
              "      <td>0.053548</td>\n",
              "      <td>-0.030680</td>\n",
              "      <td>-0.015096</td>\n",
              "      <td>-0.030273</td>\n",
              "      <td>-0.050903</td>\n",
              "      <td>0.060303</td>\n",
              "      <td>-0.022542</td>\n",
              "      <td>0.076742</td>\n",
              "      <td>-0.064840</td>\n",
              "      <td>0.018717</td>\n",
              "      <td>0.109639</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.158854</td>\n",
              "      <td>-0.120117</td>\n",
              "      <td>-0.104680</td>\n",
              "      <td>0.216146</td>\n",
              "      <td>-0.121745</td>\n",
              "      <td>0.048299</td>\n",
              "      <td>-0.036296</td>\n",
              "      <td>-0.018229</td>\n",
              "      <td>0.178304</td>\n",
              "      <td>0.026652</td>\n",
              "      <td>-0.022827</td>\n",
              "      <td>0.147786</td>\n",
              "      <td>0.035604</td>\n",
              "      <td>0.037191</td>\n",
              "      <td>-0.069295</td>\n",
              "      <td>-0.124471</td>\n",
              "      <td>-0.078735</td>\n",
              "      <td>-0.004313</td>\n",
              "      <td>0.107096</td>\n",
              "      <td>0.024577</td>\n",
              "      <td>0.042460</td>\n",
              "      <td>-0.021057</td>\n",
              "      <td>-0.015544</td>\n",
              "      <td>0.017253</td>\n",
              "      <td>-0.101237</td>\n",
              "      <td>0.019287</td>\n",
              "      <td>-0.053060</td>\n",
              "      <td>0.074219</td>\n",
              "      <td>0.121663</td>\n",
              "      <td>0.252279</td>\n",
              "      <td>-0.133097</td>\n",
              "      <td>-0.002604</td>\n",
              "      <td>0.044393</td>\n",
              "      <td>0.055868</td>\n",
              "      <td>0.085124</td>\n",
              "      <td>-0.071940</td>\n",
              "      <td>0.115723</td>\n",
              "      <td>-0.040446</td>\n",
              "      <td>-0.053019</td>\n",
              "      <td>-0.035767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>-0.029683</td>\n",
              "      <td>0.161743</td>\n",
              "      <td>0.052785</td>\n",
              "      <td>0.078247</td>\n",
              "      <td>-0.005615</td>\n",
              "      <td>-0.014038</td>\n",
              "      <td>0.049154</td>\n",
              "      <td>-0.135071</td>\n",
              "      <td>0.085429</td>\n",
              "      <td>0.131249</td>\n",
              "      <td>-0.053874</td>\n",
              "      <td>-0.138875</td>\n",
              "      <td>-0.023295</td>\n",
              "      <td>-0.021566</td>\n",
              "      <td>-0.027629</td>\n",
              "      <td>-0.000773</td>\n",
              "      <td>0.125468</td>\n",
              "      <td>0.055598</td>\n",
              "      <td>0.012451</td>\n",
              "      <td>-0.017441</td>\n",
              "      <td>-0.101400</td>\n",
              "      <td>0.131439</td>\n",
              "      <td>0.074605</td>\n",
              "      <td>0.071126</td>\n",
              "      <td>0.039769</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>-0.099528</td>\n",
              "      <td>-0.028956</td>\n",
              "      <td>0.007568</td>\n",
              "      <td>-0.000285</td>\n",
              "      <td>0.031677</td>\n",
              "      <td>0.066162</td>\n",
              "      <td>-0.064168</td>\n",
              "      <td>0.032064</td>\n",
              "      <td>0.020182</td>\n",
              "      <td>-0.037842</td>\n",
              "      <td>-0.040556</td>\n",
              "      <td>0.021932</td>\n",
              "      <td>-0.009989</td>\n",
              "      <td>0.106140</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013969</td>\n",
              "      <td>0.022654</td>\n",
              "      <td>-0.083761</td>\n",
              "      <td>0.069906</td>\n",
              "      <td>0.138611</td>\n",
              "      <td>0.107605</td>\n",
              "      <td>-0.001963</td>\n",
              "      <td>-0.010234</td>\n",
              "      <td>0.003621</td>\n",
              "      <td>-0.000997</td>\n",
              "      <td>0.061310</td>\n",
              "      <td>0.065470</td>\n",
              "      <td>0.069051</td>\n",
              "      <td>-0.003459</td>\n",
              "      <td>0.095805</td>\n",
              "      <td>-0.089071</td>\n",
              "      <td>-0.015015</td>\n",
              "      <td>-0.120748</td>\n",
              "      <td>-0.107259</td>\n",
              "      <td>0.057995</td>\n",
              "      <td>0.062795</td>\n",
              "      <td>-0.009440</td>\n",
              "      <td>-0.047831</td>\n",
              "      <td>0.059570</td>\n",
              "      <td>-0.017446</td>\n",
              "      <td>0.013336</td>\n",
              "      <td>-0.011820</td>\n",
              "      <td>0.003998</td>\n",
              "      <td>0.078817</td>\n",
              "      <td>0.014002</td>\n",
              "      <td>-0.084025</td>\n",
              "      <td>0.149831</td>\n",
              "      <td>-0.100749</td>\n",
              "      <td>0.035583</td>\n",
              "      <td>-0.042745</td>\n",
              "      <td>0.013672</td>\n",
              "      <td>0.001959</td>\n",
              "      <td>-0.096578</td>\n",
              "      <td>-0.003118</td>\n",
              "      <td>-0.097036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>0.021790</td>\n",
              "      <td>0.055105</td>\n",
              "      <td>0.045817</td>\n",
              "      <td>0.164118</td>\n",
              "      <td>-0.031738</td>\n",
              "      <td>0.052039</td>\n",
              "      <td>0.032318</td>\n",
              "      <td>-0.097631</td>\n",
              "      <td>0.062892</td>\n",
              "      <td>0.083518</td>\n",
              "      <td>-0.007863</td>\n",
              "      <td>-0.067871</td>\n",
              "      <td>0.012759</td>\n",
              "      <td>-0.066935</td>\n",
              "      <td>-0.119354</td>\n",
              "      <td>0.055571</td>\n",
              "      <td>0.053879</td>\n",
              "      <td>0.104689</td>\n",
              "      <td>0.046305</td>\n",
              "      <td>-0.094668</td>\n",
              "      <td>-0.064423</td>\n",
              "      <td>0.102943</td>\n",
              "      <td>0.034454</td>\n",
              "      <td>0.042696</td>\n",
              "      <td>-0.012319</td>\n",
              "      <td>0.002329</td>\n",
              "      <td>-0.053294</td>\n",
              "      <td>0.024536</td>\n",
              "      <td>-0.008803</td>\n",
              "      <td>0.045024</td>\n",
              "      <td>-0.005946</td>\n",
              "      <td>0.090688</td>\n",
              "      <td>-0.048258</td>\n",
              "      <td>0.029401</td>\n",
              "      <td>-0.004628</td>\n",
              "      <td>-0.003785</td>\n",
              "      <td>-0.001688</td>\n",
              "      <td>-0.023346</td>\n",
              "      <td>0.016836</td>\n",
              "      <td>0.042435</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003633</td>\n",
              "      <td>-0.060033</td>\n",
              "      <td>-0.024953</td>\n",
              "      <td>0.028714</td>\n",
              "      <td>0.018148</td>\n",
              "      <td>0.098602</td>\n",
              "      <td>-0.024061</td>\n",
              "      <td>-0.017090</td>\n",
              "      <td>-0.108046</td>\n",
              "      <td>-0.042187</td>\n",
              "      <td>-0.008971</td>\n",
              "      <td>0.115031</td>\n",
              "      <td>0.115245</td>\n",
              "      <td>0.065824</td>\n",
              "      <td>0.081533</td>\n",
              "      <td>-0.087470</td>\n",
              "      <td>-0.039394</td>\n",
              "      <td>-0.049215</td>\n",
              "      <td>-0.019407</td>\n",
              "      <td>-0.005516</td>\n",
              "      <td>0.031759</td>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.028657</td>\n",
              "      <td>0.094521</td>\n",
              "      <td>-0.041892</td>\n",
              "      <td>0.039187</td>\n",
              "      <td>-0.081970</td>\n",
              "      <td>-0.057200</td>\n",
              "      <td>-0.006297</td>\n",
              "      <td>0.085604</td>\n",
              "      <td>-0.068746</td>\n",
              "      <td>0.088145</td>\n",
              "      <td>-0.081924</td>\n",
              "      <td>0.046851</td>\n",
              "      <td>-0.035449</td>\n",
              "      <td>-0.055354</td>\n",
              "      <td>0.016132</td>\n",
              "      <td>-0.064800</td>\n",
              "      <td>0.006045</td>\n",
              "      <td>-0.019272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>0.006487</td>\n",
              "      <td>0.130338</td>\n",
              "      <td>0.045449</td>\n",
              "      <td>0.042393</td>\n",
              "      <td>-0.049090</td>\n",
              "      <td>0.024024</td>\n",
              "      <td>0.008913</td>\n",
              "      <td>-0.077497</td>\n",
              "      <td>0.019381</td>\n",
              "      <td>0.073996</td>\n",
              "      <td>0.000623</td>\n",
              "      <td>-0.173135</td>\n",
              "      <td>-0.044285</td>\n",
              "      <td>0.049229</td>\n",
              "      <td>-0.066110</td>\n",
              "      <td>0.048522</td>\n",
              "      <td>0.014457</td>\n",
              "      <td>0.097125</td>\n",
              "      <td>0.002093</td>\n",
              "      <td>-0.004671</td>\n",
              "      <td>-0.067309</td>\n",
              "      <td>0.062717</td>\n",
              "      <td>0.045409</td>\n",
              "      <td>0.024264</td>\n",
              "      <td>0.003344</td>\n",
              "      <td>0.003802</td>\n",
              "      <td>-0.088318</td>\n",
              "      <td>0.053205</td>\n",
              "      <td>-0.031023</td>\n",
              "      <td>-0.025478</td>\n",
              "      <td>-0.064994</td>\n",
              "      <td>-0.014997</td>\n",
              "      <td>-0.076678</td>\n",
              "      <td>0.003501</td>\n",
              "      <td>-0.071716</td>\n",
              "      <td>-0.037022</td>\n",
              "      <td>0.094539</td>\n",
              "      <td>-0.016181</td>\n",
              "      <td>0.022343</td>\n",
              "      <td>0.088077</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024083</td>\n",
              "      <td>0.012429</td>\n",
              "      <td>-0.020299</td>\n",
              "      <td>0.069597</td>\n",
              "      <td>-0.009452</td>\n",
              "      <td>0.059065</td>\n",
              "      <td>0.005349</td>\n",
              "      <td>0.038539</td>\n",
              "      <td>-0.033892</td>\n",
              "      <td>-0.057177</td>\n",
              "      <td>0.027213</td>\n",
              "      <td>0.064863</td>\n",
              "      <td>0.057717</td>\n",
              "      <td>0.017831</td>\n",
              "      <td>0.077567</td>\n",
              "      <td>-0.040131</td>\n",
              "      <td>-0.092939</td>\n",
              "      <td>-0.114881</td>\n",
              "      <td>-0.069877</td>\n",
              "      <td>0.099556</td>\n",
              "      <td>0.028695</td>\n",
              "      <td>-0.034664</td>\n",
              "      <td>0.092520</td>\n",
              "      <td>0.068987</td>\n",
              "      <td>-0.028390</td>\n",
              "      <td>0.008508</td>\n",
              "      <td>-0.078482</td>\n",
              "      <td>0.042672</td>\n",
              "      <td>0.040385</td>\n",
              "      <td>0.068874</td>\n",
              "      <td>-0.089861</td>\n",
              "      <td>0.038705</td>\n",
              "      <td>-0.091435</td>\n",
              "      <td>0.114319</td>\n",
              "      <td>-0.037223</td>\n",
              "      <td>-0.011161</td>\n",
              "      <td>0.034840</td>\n",
              "      <td>-0.081893</td>\n",
              "      <td>-0.019932</td>\n",
              "      <td>-0.019605</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2    ...       297       298       299\n",
              "0    -0.021805 -0.023468 -0.012323  ... -0.027138 -0.020218 -0.012622\n",
              "1    -0.008728  0.038536 -0.037689  ... -0.120605 -0.032248 -0.031235\n",
              "2     0.013550  0.137695 -0.085022  ... -0.166504  0.034485 -0.098877\n",
              "3    -0.031543  0.064844 -0.028577  ... -0.139941  0.023798  0.066406\n",
              "4     0.043498 -0.009603 -0.090535  ... -0.143311 -0.147339 -0.002116\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "2995 -0.032674  0.091064  0.015493  ... -0.049377  0.014623  0.028987\n",
              "2996  0.072866  0.111328 -0.058431  ... -0.040446 -0.053019 -0.035767\n",
              "2997 -0.029683  0.161743  0.052785  ... -0.096578 -0.003118 -0.097036\n",
              "2998  0.021790  0.055105  0.045817  ... -0.064800  0.006045 -0.019272\n",
              "2999  0.006487  0.130338  0.045449  ... -0.081893 -0.019932 -0.019605\n",
              "\n",
              "[3000 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJSpX1pzoEpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cats_new=[a.replace('\\n','') for a in cats]\n",
        "cats_df=pd.DataFrame(cats_new)\n",
        "cats_df.head()"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOPbTQ1xmLa1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb37b615-b85d-4f02-f8f4-384a8276fdca"
      },
      "source": [
        "X_train, X_test, y_train, y_test= train_test_split(train_vectors_df, cats_df,\n",
        "                                                                test_size=0.3,random_state=42,\n",
        "                                                                stratify=cats)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2100, 300)\n",
            "(900, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQagd9vTpMAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=X_train.dropna()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D7tbdf5pJFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4f0d7eb6-46e2-48ca-bc75-5703fb0de8d8"
      },
      "source": [
        "y_train.isnull().sum()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGl1gsCVpCN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "70d89123-c113-47a4-d815-54fe23de2de1"
      },
      "source": [
        "X_train.isnull().sum()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "295    0\n",
              "296    0\n",
              "297    0\n",
              "298    0\n",
              "299    0\n",
              "Length: 300, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mr9IaQppb_Ix",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b534a4db-2c13-4dfc-be95-469c7e9e62f8"
      },
      "source": [
        "#Take any classifier (LogisticRegression here, and train/test it like before.\n",
        "classifier = LogisticRegression(random_state=1234)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_preds = classifier.predict(test_data)\n",
        "print(classification_report(y_test, y_preds))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-f87fb5edef35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Take any classifier (LogisticRegression here, and train/test it like before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2098, 2100]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k7wjLB8rb_JB"
      },
      "source": [
        "Not bad. With little efforts we got 81% accuracy. Thats a great starting model to have!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8z3tJJJkb_JB",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}