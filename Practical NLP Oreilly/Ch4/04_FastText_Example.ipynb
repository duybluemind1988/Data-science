{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastText_Example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6FIToZHAhz2O"
      },
      "source": [
        "In this notebook we will demonstrate using the fastText library to perform text classificatoin on the dbpedie data which can we downloaded from [here](https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz). <br>fastText is a library for learning of word embeddings and text classification created by Facebook's AI Research (FAIR) lab. The model allows to create an unsupervised learning or supervised learning algorithm for obtaining vector representations for words. Facebook makes available pretrained models for 294 languages(source: [wiki](https://en.wikipedia.org/wiki/FastText)).<br>\n",
        "**Note**: This notebook uses an older version of fasttext."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efT0YsYpW9cF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "d352e78d-bac9-490c-a232-5a1354aa6491"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (49.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3016703 sha256=7168ce45f9e56adbf64adb4f947699bc4f77b9a2941416c8e75293b267507f92\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YKgZXvTGb61z",
        "colab": {}
      },
      "source": [
        "#necessary imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from fasttext import supervised "
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYzr9S3RYak1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "b57f07f2-af90-459a-94cc-c4167e215139"
      },
      "source": [
        "!wget -c \"https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-01 10:14:33--  https://github.com/le-scientifique/torchDatasets/raw/master/dbpedia_csv.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/srhrshr/torchDatasets/raw/master/dbpedia_csv.tar.gz [following]\n",
            "--2020-08-01 10:14:33--  https://github.com/srhrshr/torchDatasets/raw/master/dbpedia_csv.tar.gz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/srhrshr/torchDatasets/master/dbpedia_csv.tar.gz [following]\n",
            "--2020-08-01 10:14:33--  https://raw.githubusercontent.com/srhrshr/torchDatasets/master/dbpedia_csv.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnWFLuzEgP5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6faa7166-d680-4db7-83c9-852f0d28e5fa"
      },
      "source": [
        "import tarfile\n",
        "tar = tarfile.open(\"/content/dbpedia_csv.tar.gz\")\n",
        "tar.extractall()\n",
        "for member in tar.getmembers():\n",
        "    print(\"Extracting %s\" % member.name)\n",
        "    tar.extract(member, #path='/home/connor/'\n",
        "    )"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting dbpedia_csv\n",
            "Extracting dbpedia_csv/test.csv\n",
            "Extracting dbpedia_csv/classes.txt\n",
            "Extracting dbpedia_csv/train.csv\n",
            "Extracting dbpedia_csv/readme.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lMoRw3oQb62I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "139ca83d-98b5-4288-fc86-0a7147e33497"
      },
      "source": [
        "\n",
        "# Loading train data\n",
        "train_file = '/content/dbpedia_csv/train.csv'\n",
        "df = pd.read_csv(train_file, header=None, names=['class','name','description'])\n",
        "# Loading test data\n",
        "test_file = '/content/dbpedia_csv/test.csv'\n",
        "df_test = pd.read_csv(test_file, header=None, names=['class','name','description'])\n",
        "# Data we have\n",
        "print(\"Train:{} Test:{}\".format(df.shape,df_test.shape))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:(560000, 3) Test:(70000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pxs__IEhpKm",
        "colab_type": "text"
      },
      "source": [
        "The remaining\n",
        "part of this subsection shows how to use the fastText classifier [17] for text\n",
        "classification. We’ll work with the DBpedia dataset [18]. It’s a balanced dataset\n",
        "consisting of 14 classes, with 40,000 training and 5,000 testing examples per class.\n",
        "Thus, the total size of the dataset is 560,000 training and 70,000 testing data points.\n",
        "Clearly, this is a much larger dataset than what we saw before. Can we build a fast\n",
        "training model using fastText? Let’s check it out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfTRacE_hhH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "def274c7-1f11-4148-ec01-8e2a010d06ad"
      },
      "source": [
        "df"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>E. D. Abbott Ltd</td>\n",
              "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Schwan-Stabilo</td>\n",
              "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Q-workshop</td>\n",
              "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Marvell Software Solutions Israel</td>\n",
              "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Bergan Mercy Medical Center</td>\n",
              "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559995</th>\n",
              "      <td>14</td>\n",
              "      <td>Barking in Essex</td>\n",
              "      <td>Barking in Essex is a Black comedy play direc...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559996</th>\n",
              "      <td>14</td>\n",
              "      <td>Science &amp; Spirit</td>\n",
              "      <td>Science &amp; Spirit is a discontinued American b...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559997</th>\n",
              "      <td>14</td>\n",
              "      <td>The Blithedale Romance</td>\n",
              "      <td>The Blithedale Romance (1852) is Nathaniel Ha...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559998</th>\n",
              "      <td>14</td>\n",
              "      <td>Razadarit Ayedawbon</td>\n",
              "      <td>Razadarit Ayedawbon (Burmese: ရာဇာဓိရာဇ် အရေး...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559999</th>\n",
              "      <td>14</td>\n",
              "      <td>The Vinyl Cafe Notebooks</td>\n",
              "      <td>Vinyl Cafe Notebooks: a collection of essays ...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>560000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        class  ...   class_name\n",
              "0           1  ...      Company\n",
              "1           1  ...      Company\n",
              "2           1  ...      Company\n",
              "3           1  ...      Company\n",
              "4           1  ...      Company\n",
              "...       ...  ...          ...\n",
              "559995     14  ...  WrittenWork\n",
              "559996     14  ...  WrittenWork\n",
              "559997     14  ...  WrittenWork\n",
              "559998     14  ...  WrittenWork\n",
              "559999     14  ...  WrittenWork\n",
              "\n",
              "[560000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIA-xHVUhvWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4d9ce647-0114-4f77-df07-be3cc54b6bfb"
      },
      "source": [
        "df['class'].value_counts()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14    40000\n",
              "13    40000\n",
              "12    40000\n",
              "11    40000\n",
              "10    40000\n",
              "9     40000\n",
              "8     40000\n",
              "7     40000\n",
              "6     40000\n",
              "5     40000\n",
              "4     40000\n",
              "3     40000\n",
              "2     40000\n",
              "1     40000\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gaz226vXb62W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dccb0993-7d53-4075-b0d7-a283380cc8f1"
      },
      "source": [
        "# Since we have no clue about the classes lets build one\n",
        "# Mapping from class number to class name\n",
        "class_dict={\n",
        "            1:'Company',\n",
        "            2:'EducationalInstitution',\n",
        "            3:'Artist',\n",
        "            4:'Athlete',\n",
        "            5:'OfficeHolder',\n",
        "            6:'MeanOfTransportation',\n",
        "            7:'Building',\n",
        "            8:'NaturalPlace',\n",
        "            9:'Village',\n",
        "            10:'Animal',\n",
        "            11:'Plant',\n",
        "            12:'Album',\n",
        "            13:'Film',\n",
        "            14:'WrittenWork'\n",
        "        }\n",
        "\n",
        "# Mapping the classes\n",
        "df['class_name'] = df['class'].map(class_dict)\n",
        "df.head()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>E. D. Abbott Ltd</td>\n",
              "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Schwan-Stabilo</td>\n",
              "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Q-workshop</td>\n",
              "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Marvell Software Solutions Israel</td>\n",
              "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Bergan Mercy Medical Center</td>\n",
              "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class  ... class_name\n",
              "0      1  ...    Company\n",
              "1      1  ...    Company\n",
              "2      1  ...    Company\n",
              "3      1  ...    Company\n",
              "4      1  ...    Company\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "si7VC_Rub62a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7d5a3df3-60ed-417f-8377-8282f8fc95b0"
      },
      "source": [
        "df[\"class_name\"].value_counts()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Animal                    40000\n",
              "MeanOfTransportation      40000\n",
              "NaturalPlace              40000\n",
              "Building                  40000\n",
              "Plant                     40000\n",
              "WrittenWork               40000\n",
              "Company                   40000\n",
              "EducationalInstitution    40000\n",
              "Album                     40000\n",
              "Artist                    40000\n",
              "OfficeHolder              40000\n",
              "Film                      40000\n",
              "Village                   40000\n",
              "Athlete                   40000\n",
              "Name: class_name, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sn-3kIqMb62d",
        "colab": {}
      },
      "source": [
        "# Lets do some cleaning of this text\n",
        "def clean_it(text,normalize=True):\n",
        "    # Replacing possible issues with data. We can add or reduce the replacemtent in this chain\n",
        "    s = str(text).replace(',',' ').replace('\"','').replace('\\'',' \\' ').replace('.',' . ').replace('(',' ( ').\\\n",
        "            replace(')',' ) ').replace('!',' ! ').replace('?',' ? ').replace(':',' ').replace(';',' ').lower()\n",
        "    \n",
        "    # normalizing / encoding the text\n",
        "    if normalize:\n",
        "        s = s.normalize('NFKD').str.encode('ascii','ignore').str.decode('utf-8')\n",
        "    \n",
        "    return s\n",
        "\n",
        "# Now lets define a small function where we can use above cleaning on datasets\n",
        "def clean_df(data, cleanit= False, shuffleit=False, encodeit=False, label_prefix='__class__'):\n",
        "    # Defining the new data\n",
        "    df = data[['name','description']].copy(deep=True)\n",
        "    df['class'] = label_prefix + data['class'].astype(str) + ' '\n",
        "    \n",
        "    # cleaning it\n",
        "    if cleanit:\n",
        "        df['name'] = df['name'].apply(lambda x: clean_it(x,encodeit))\n",
        "        df['description'] = df['description'].apply(lambda x: clean_it(x,encodeit))\n",
        "    \n",
        "    # shuffling it\n",
        "    if shuffleit:\n",
        "        df.sample(frac=1).reset_index(drop=True)\n",
        "            \n",
        "    return df"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r_DRvdFcb62m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7fc0aba6-78a0-47e4-b90d-fcc21d961e26"
      },
      "source": [
        "%%time\n",
        "# Transform the datasets using the above clean functions\n",
        "df_train_cleaned = clean_df(df, True, True)\n",
        "df_test_cleaned = clean_df(df_test, True, True)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.04 s, sys: 573 ms, total: 5.61 s\n",
            "Wall time: 5.62 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBHSElRpiZQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e5ff608c-e91d-48ed-f5a1-4c4916f1cf3c"
      },
      "source": [
        "df"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>class_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>E. D. Abbott Ltd</td>\n",
              "      <td>Abbott of Farnham E D Abbott Limited was a Br...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Schwan-Stabilo</td>\n",
              "      <td>Schwan-STABILO is a German maker of pens for ...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Q-workshop</td>\n",
              "      <td>Q-workshop is a Polish company located in Poz...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Marvell Software Solutions Israel</td>\n",
              "      <td>Marvell Software Solutions Israel known as RA...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Bergan Mercy Medical Center</td>\n",
              "      <td>Bergan Mercy Medical Center is a hospital loc...</td>\n",
              "      <td>Company</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559995</th>\n",
              "      <td>14</td>\n",
              "      <td>Barking in Essex</td>\n",
              "      <td>Barking in Essex is a Black comedy play direc...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559996</th>\n",
              "      <td>14</td>\n",
              "      <td>Science &amp; Spirit</td>\n",
              "      <td>Science &amp; Spirit is a discontinued American b...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559997</th>\n",
              "      <td>14</td>\n",
              "      <td>The Blithedale Romance</td>\n",
              "      <td>The Blithedale Romance (1852) is Nathaniel Ha...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559998</th>\n",
              "      <td>14</td>\n",
              "      <td>Razadarit Ayedawbon</td>\n",
              "      <td>Razadarit Ayedawbon (Burmese: ရာဇာဓိရာဇ် အရေး...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559999</th>\n",
              "      <td>14</td>\n",
              "      <td>The Vinyl Cafe Notebooks</td>\n",
              "      <td>Vinyl Cafe Notebooks: a collection of essays ...</td>\n",
              "      <td>WrittenWork</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>560000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        class  ...   class_name\n",
              "0           1  ...      Company\n",
              "1           1  ...      Company\n",
              "2           1  ...      Company\n",
              "3           1  ...      Company\n",
              "4           1  ...      Company\n",
              "...       ...  ...          ...\n",
              "559995     14  ...  WrittenWork\n",
              "559996     14  ...  WrittenWork\n",
              "559997     14  ...  WrittenWork\n",
              "559998     14  ...  WrittenWork\n",
              "559999     14  ...  WrittenWork\n",
              "\n",
              "[560000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6JmiK0iVsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "6d724587-899e-4183-a695-7f6e2fc67232"
      },
      "source": [
        "df_train_cleaned"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>description</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e .  d .  abbott ltd</td>\n",
              "      <td>abbott of farnham e d abbott limited was a br...</td>\n",
              "      <td>__class__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>schwan-stabilo</td>\n",
              "      <td>schwan-stabilo is a german maker of pens for ...</td>\n",
              "      <td>__class__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>q-workshop</td>\n",
              "      <td>q-workshop is a polish company located in poz...</td>\n",
              "      <td>__class__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>marvell software solutions israel</td>\n",
              "      <td>marvell software solutions israel known as ra...</td>\n",
              "      <td>__class__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bergan mercy medical center</td>\n",
              "      <td>bergan mercy medical center is a hospital loc...</td>\n",
              "      <td>__class__1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559995</th>\n",
              "      <td>barking in essex</td>\n",
              "      <td>barking in essex is a black comedy play direc...</td>\n",
              "      <td>__class__14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559996</th>\n",
              "      <td>science &amp; spirit</td>\n",
              "      <td>science &amp; spirit is a discontinued american b...</td>\n",
              "      <td>__class__14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559997</th>\n",
              "      <td>the blithedale romance</td>\n",
              "      <td>the blithedale romance  ( 1852 )  is nathanie...</td>\n",
              "      <td>__class__14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559998</th>\n",
              "      <td>razadarit ayedawbon</td>\n",
              "      <td>razadarit ayedawbon  ( burmese  ရာဇာဓိရာဇ် အရ...</td>\n",
              "      <td>__class__14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559999</th>\n",
              "      <td>the vinyl cafe notebooks</td>\n",
              "      <td>vinyl cafe notebooks  a collection of essays ...</td>\n",
              "      <td>__class__14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>560000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     name  ...         class\n",
              "0                    e .  d .  abbott ltd  ...   __class__1 \n",
              "1                          schwan-stabilo  ...   __class__1 \n",
              "2                              q-workshop  ...   __class__1 \n",
              "3       marvell software solutions israel  ...   __class__1 \n",
              "4             bergan mercy medical center  ...   __class__1 \n",
              "...                                   ...  ...           ...\n",
              "559995                   barking in essex  ...  __class__14 \n",
              "559996                   science & spirit  ...  __class__14 \n",
              "559997             the blithedale romance  ...  __class__14 \n",
              "559998                razadarit ayedawbon  ...  __class__14 \n",
              "559999           the vinyl cafe notebooks  ...  __class__14 \n",
              "\n",
              "[560000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "imMZ9-Bkb62t",
        "colab": {}
      },
      "source": [
        "# Write files to disk as fastText classifier API reads files from disk.\n",
        "train_file = 'dbpedia_train_clean.csv'\n",
        "df_train_cleaned.to_csv(train_file, header=None, \n",
        "                        index=False, columns=['class','name','description'] )\n",
        "\n",
        "test_file ='dbpedia_test_clean.csv'\n",
        "df_test_cleaned.to_csv(test_file, header=None, \n",
        "                       index=False, columns=['class','name','description'] )\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GglNrZlkjGCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "5ce7447d-5cff-4a4d-e474-b294c59f94be"
      },
      "source": [
        "pd.read_csv('dbpedia_train_clean.csv').head()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>__class__1</th>\n",
              "      <th>e .  d .  abbott ltd</th>\n",
              "      <th>abbott of farnham e d abbott limited was a british coachbuilding business based in farnham surrey trading under that name from 1929 .  a major part of their output was under sub-contract to motor vehicle manufacturers .  their business closed in 1972 .</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>__class__1</td>\n",
              "      <td>schwan-stabilo</td>\n",
              "      <td>schwan-stabilo is a german maker of pens for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>__class__1</td>\n",
              "      <td>q-workshop</td>\n",
              "      <td>q-workshop is a polish company located in poz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>__class__1</td>\n",
              "      <td>marvell software solutions israel</td>\n",
              "      <td>marvell software solutions israel known as ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>__class__1</td>\n",
              "      <td>bergan mercy medical center</td>\n",
              "      <td>bergan mercy medical center is a hospital loc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>__class__1</td>\n",
              "      <td>the unsigned guide</td>\n",
              "      <td>the unsigned guide is an online contacts dire...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   __class__1   ...  abbott of farnham e d abbott limited was a british coachbuilding business based in farnham surrey trading under that name from 1929 .  a major part of their output was under sub-contract to motor vehicle manufacturers .  their business closed in 1972 . \n",
              "0  __class__1   ...   schwan-stabilo is a german maker of pens for ...                                                                                                                                                                                                            \n",
              "1  __class__1   ...   q-workshop is a polish company located in poz...                                                                                                                                                                                                            \n",
              "2  __class__1   ...   marvell software solutions israel known as ra...                                                                                                                                                                                                            \n",
              "3  __class__1   ...   bergan mercy medical center is a hospital loc...                                                                                                                                                                                                            \n",
              "4  __class__1   ...   the unsigned guide is an online contacts dire...                                                                                                                                                                                                            \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bWZTSzd9b62x"
      },
      "source": [
        "Now that we have the train and test files written into disk in a format fastText wants, we are ready to use it for text classification!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nKqQv0RlgGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "023a10b1-c510-4297-a7e8-bce9d2a0994c"
      },
      "source": [
        "import fasttext\n",
        "%time model = fasttext.train_supervised(input='dbpedia_train_clean.csv',label_prefix=\"__class__\")\n",
        "results=model.test('dbpedia_test_clean.csv')\n",
        "results\n",
        " # run with no header"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 6s, sys: 452 ms, total: 1min 6s\n",
            "Wall time: 1min 6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 0.07142857142857142, 0.07142857142857142)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "excX8cVo8y6t",
        "colab_type": "text"
      },
      "source": [
        "(70000, 0.07142857142857142, 0.07142857142857142)\n",
        "\n",
        "Do chinh xac ban dau: 0.07%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z00Z8HNnCYe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "babedb87-ffb9-4fac-9084-6f75f2bfadb1"
      },
      "source": [
        "model.predict(\"schwan-stabilo is a german maker of pens for \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__class__14',), array([0.96447182]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uUOcmso6SuC",
        "colab_type": "text"
      },
      "source": [
        "Imporve performance: add learning rate and epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpv5xxWw6LqB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "076f392c-01ac-41e2-da5b-b7ede56a1868"
      },
      "source": [
        "%time model = fasttext.train_supervised(input='dbpedia_train_clean.csv',\\\n",
        "                                  lr=1.0, epoch=25,label_prefix=\"__class__\")\n",
        "results=model.test('dbpedia_test_clean.csv')\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 38s, sys: 2.06 s, total: 5min 40s\n",
            "Wall time: 5min 40s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 0.2650142857142857, 0.2650142857142857)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_-5E-Zi8azt",
        "colab_type": "text"
      },
      "source": [
        "Tang do chinh xac tu 1% len 26%, thoi gian training tang len nhieu lan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6wjYUGx6c5a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e31f4e1c-0fca-4234-d1d5-7eee7088b9c2"
      },
      "source": [
        "%time model = fasttext.train_supervised(input='dbpedia_train_clean.csv',\\\n",
        "                                  lr=1.0, epoch=25,wordNgrams=2,\\\n",
        "                                  label_prefix=\"__class__\")\n",
        "results=model.test('dbpedia_test_clean.csv')\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11min 57s, sys: 3.25 s, total: 12min\n",
            "Wall time: 12min 1s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 0.4786285714285714, 0.4786285714285714)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiZ5OH6a-nXN",
        "colab_type": "text"
      },
      "source": [
        "Do chinh xac tang tu 26% len 47%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW-tVMSNA9oF",
        "colab_type": "text"
      },
      "source": [
        "Tim cach cai thien toc do train bang ham softmax (loss= 'hs')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgDuBa_gAQ1n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "688e836a-473d-429d-e3f0-13d884c32ee0"
      },
      "source": [
        "%time model = fasttext.train_supervised(input='dbpedia_train_clean.csv',\\\n",
        "                                        lr=1.0, epoch=25,wordNgrams=2,\\\n",
        "                                        bucket=200000, dim=50, loss='hs',\\\n",
        "                                        label_prefix=\"__class__\")\n",
        "results=model.test('dbpedia_test_clean.csv')\n",
        "results\n",
        " # run with no header"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 54s, sys: 2.42 s, total: 5min 57s\n",
            "Wall time: 5min 57s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 0.41482857142857144, 0.41482857142857144)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FhdavHhGyPJ",
        "colab_type": "text"
      },
      "source": [
        "Toc do nhanh hon gap doi, tu 12 phut xuong 6 phut, do chinh xac giam 4%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYP8FGVaSk23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = fasttext.load_model(\"temp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a-H1wouCb62x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "5ec6f453-68ac-45cd-8f2d-d25147b06f55"
      },
      "source": [
        "## Using fastText for feature extraction and training\n",
        "from fasttext import supervised \n",
        "\"\"\"fastText expects and training file (csv), a model name as input arguments.\n",
        "label_prefix refers to the prefix before label string in the dataset.\n",
        "default is __label__. In our dataset, it is __class__. \n",
        "There are several other parameters which can be seen in: \n",
        "https://pypi.org/project/fasttext/\n",
        "\"\"\"\n",
        "%time model = supervised(train_file, 'temp', label_prefix=\"__class__\")\n",
        "results = model.test(test_file)\n",
        "print(results.nexamples, results.precision, results.recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 11s, sys: 908 ms, total: 1min 12s\n",
            "Wall time: 1min 12s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ab3bb5e6ba3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time model = train_supervised(\\'dbpedia_train_clean.csv\\', label_prefix=\"__class__\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dbpedia_test_clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'nexamples'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIXaESAjRrsv",
        "colab_type": "text"
      },
      "source": [
        "Model 'temp' cho do chinh xac la 97% voi chi vai giay training, hien tai khong co o day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAbN8AeFz6b_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "CPU times: user 56.5 s, sys: 1.51 s, total: 58 s\n",
        "\n",
        "Wall time: 12.6 s\n",
        "\n",
        "70000 | 0.9710571428571428 | 0.9710571428571428"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nrxSYRs3b621"
      },
      "source": [
        "Try training a classifier on this dataset with, say, LogisticRegression to realize how fast fastText is! 97% Precision and Recall are hard numbers to beat, too!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7-mSBpo2sr4",
        "colab_type": "text"
      },
      "source": [
        "# Fast text example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73FYmZt32v3a",
        "colab_type": "text"
      },
      "source": [
        "https://fasttext.cc/docs/en/supervised-tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmHm8CTQ2uwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "2a53ac68-5228-4c07-ed59-0aa5b15bc960"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz && tar xvzf cooking.stackexchange.tar.gz\n",
        "!head cooking.stackexchange.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-01 11:50:41--  https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 457609 (447K) [application/x-tar]\n",
            "Saving to: ‘cooking.stackexchange.tar.gz’\n",
            "\n",
            "cooking.stackexchan 100%[===================>] 446.88K  1.21MB/s    in 0.4s    \n",
            "\n",
            "2020-08-01 11:50:42 (1.21 MB/s) - ‘cooking.stackexchange.tar.gz’ saved [457609/457609]\n",
            "\n",
            "cooking.stackexchange.id\n",
            "cooking.stackexchange.txt\n",
            "readme.txt\n",
            "__label__sauce __label__cheese How much does potato starch affect a cheese sauce recipe?\n",
            "__label__food-safety __label__acidity Dangerous pathogens capable of growing in acidic environments\n",
            "__label__cast-iron __label__stove How do I cover up the white spots on my cast iron stove?\n",
            "__label__restaurant Michelin Three Star Restaurant; but if the chef is not there\n",
            "__label__knife-skills __label__dicing Without knife skills, how can I quickly and accurately dice vegetables?\n",
            "__label__storage-method __label__equipment __label__bread What's the purpose of a bread box?\n",
            "__label__baking __label__food-safety __label__substitutions __label__peanuts how to seperate peanut oil from roasted peanuts at home?\n",
            "__label__chocolate American equivalent for British chocolate terms\n",
            "__label__baking __label__oven __label__convection Fan bake vs bake\n",
            "__label__sauce __label__storage-lifetime __label__acidity __label__mayonnaise Regulation and balancing of readymade packed mayonnaise and other sauces\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAyN8zNF3Nva",
        "colab_type": "text"
      },
      "source": [
        "Before training our first classifier, we need to split the data into train and validation. We will use the validation set to evaluate how good the learned classifier is on new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md528uy62uyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed886908-066a-43f3-e9f6-77a71431fdee"
      },
      "source": [
        "!wc cooking.stackexchange.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  15404  169582 1401900 cooking.stackexchange.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqqszslb3ZeC",
        "colab_type": "text"
      },
      "source": [
        "Our full dataset contains 15404 examples. Let's split it into a training set of 12404 examples and a validation set of 3000 examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f69aYZ0X2u1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n 12404 cooking.stackexchange.txt > cooking.train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWPP6yf93UNQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tail -n 3000 cooking.stackexchange.txt > cooking.valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymEF9o-g3nps",
        "colab_type": "text"
      },
      "source": [
        "## Our first classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQwfVhAt3YoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fasttext\n",
        "model = fasttext.train_supervised(input=\"cooking.train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWcIpYsd3sFv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc8681bb-2854-468d-dae9-23b336a69896"
      },
      "source": [
        "model.predict(\"Which baking dish is best to bake a banana bread ?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__baking',), array([0.07257967]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvbsbvOh3xzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "016b5f65-7fd7-492c-80af-63d811385d64"
      },
      "source": [
        "model.predict(\"Why not put knives in the dishwasher?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__food-safety',), array([0.07451777]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q24tnBFP3zEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6765176-e722-4e79-eea6-0b1094d8f5e8"
      },
      "source": [
        "model.test(\"cooking.valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.135, 0.05838258613233386)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nctcuuod35KB",
        "colab_type": "text"
      },
      "source": [
        "The output are the number of samples (here 3000), the precision at one (0.124) and the recall at one (0.0541).\n",
        "\n",
        "We can also compute the precision at five and recall at five with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEFVmKTH30xe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c0e08d9-a691-4bc3-d09f-b35b327e02a2"
      },
      "source": [
        "model.test(\"cooking.valid\", k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.06606666666666666, 0.14285714285714285)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9aggpHa37p-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "34360260-b4c3-42c2-8716-ba376384d531"
      },
      "source": [
        "model.predict(\"Why not put knives in the dishwasher?\", k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__food-safety',\n",
              "  '__label__baking',\n",
              "  '__label__bread',\n",
              "  '__label__substitutions',\n",
              "  '__label__equipment'),\n",
              " array([0.07451777, 0.07366108, 0.04390582, 0.0373    , 0.03408055]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QczITMA44Mps",
        "colab_type": "text"
      },
      "source": [
        "## Making the model better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ud__JIy4OIp",
        "colab_type": "text"
      },
      "source": [
        "preprocessing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezbu8RCU4B5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat cooking.stackexchange.txt | sed -e \"s/\\([.\\!?,'/()]\\)/ \\1 /g\" | tr \"[:upper:]\" \"[:lower:]\" > cooking.preprocessed.txt\n",
        "!head -n 12404 cooking.preprocessed.txt > cooking.train\n",
        "!tail -n 3000 cooking.preprocessed.txt > cooking.valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYf0GRgv4c9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fasttext\n",
        "model = fasttext.train_supervised(input=\"cooking.train\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGpD4xFN4frp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67943b59-c078-4711-f683-d2b147b5e3c8"
      },
      "source": [
        "model.test(\"cooking.valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.16433333333333333, 0.07106818509442121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB2VtaB_4oy4",
        "colab_type": "text"
      },
      "source": [
        "We observe that thanks to the pre-processing, the vocabulary is smaller (from 14k words to 9k). The precision is also starting to go up by 4%!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLdx_d-d4rIo",
        "colab_type": "text"
      },
      "source": [
        "##more epochs and larger learning rate\n",
        "\n",
        "By default, fastText sees each training example only five times during training, which is pretty small, given that our training set only have 12k training examples. The number of times each examples is seen (also known as the number of epochs), can be increased using the -epoch option:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZroZ1wLQ4ls7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fasttext\n",
        "model = fasttext.train_supervised(input=\"cooking.train\", epoch=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqJDFBIv4wxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea7996a8-0899-4c64-f14d-713ac412ce2f"
      },
      "source": [
        "model.test(\"cooking.valid\") # precision increase 35%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.52, 0.22488107250973044)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwkuAmRK42_E",
        "colab_type": "text"
      },
      "source": [
        "This is much better! Another way to change the learning speed of our model is to increase (or decrease) the learning rate of the algorithm. This corresponds to how much the model changes after processing each example. A learning rate of 0 would mean that the model does not change at all, and thus, does not learn anything. Good values of the learning rate are in the range 0.1 - 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu6gqDp44yJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1faefc82-fd33-4293-b8ff-523d29fa8e23"
      },
      "source": [
        "model = fasttext.train_supervised(input=\"cooking.train\", lr=1.0)\n",
        "model.test(\"cooking.valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.5693333333333334, 0.2462159434914228)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0ogzZ6a4_rl",
        "colab_type": "text"
      },
      "source": [
        "Even better! Let's try both together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlTz-ncc4_3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "747e863b-3482-4e2b-89a1-63b6fb8cf927"
      },
      "source": [
        "model = fasttext.train_supervised(input=\"cooking.train\", lr=1.0, epoch=25)\n",
        "model.test(\"cooking.valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.5843333333333334, 0.25270289750612657)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8J9Kt7r5QHv",
        "colab_type": "text"
      },
      "source": [
        "Let us now add a few more features to improve even further our performance!\n",
        "\n",
        "## word n-grams\n",
        "\n",
        "Finally, we can improve the performance of a model by using word bigrams, instead of just unigrams. This is especially important for classification problems where word order is important, such as sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmOsmux_5EGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95909cf5-d11a-4361-b420-19a172429d08"
      },
      "source": [
        "model = fasttext.train_supervised(input=\"cooking.train\", lr=1.0, epoch=25, wordNgrams=2)\n",
        "model.test(\"cooking.valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.5996666666666667, 0.2593340060544904)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVFqTHuv5dmi",
        "colab_type": "text"
      },
      "source": [
        "With a few steps, we were able to go from a precision at one of 12.4% to 59.9%. Important steps included:\n",
        "\n",
        "- preprocessing the data ;\n",
        "- changing the number of epochs (using the option -epoch, standard range [5 - 50]) ;\n",
        "- changing the learning rate (using the option -lr, standard range [0.1 - 1.0]) ;\n",
        "- using word n-grams (using the option -wordNgrams, standard range [1 - 5])."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJk5Kw64-07I",
        "colab_type": "text"
      },
      "source": [
        "## Advanced readers: What is a Bigram?\n",
        "\n",
        "A 'unigram' refers to a single undividing unit, or token, usually used as an input to a model. For example a unigram can be a word or a letter depending on the model. In fastText, we work at the word level and thus unigrams are words.\n",
        "\n",
        "Similarly we denote by 'bigram' the concatenation of 2 consecutive tokens or words. Similarly we often talk about n-gram to refer to the concatenation any n consecutive tokens.\n",
        "\n",
        "For example, in the sentence, 'Last donut of the night', the unigrams are 'last', 'donut', 'of', 'the' and 'night'. The bigrams are: 'Last donut', 'donut of', 'of the' and 'the night'.\n",
        "\n",
        "Bigrams are particularly interesting because, for most sentences, you can reconstruct the order of the words just by looking at a bag of n-grams.\n",
        "\n",
        "Let us illustrate this by a simple exercise, given the following bigrams, try to reconstruct the original sentence: 'all out', 'I am', 'of bubblegum', 'out of' and 'am all'. It is common to refer to a word as a unigram.\n",
        "\n",
        "## Scaling things up\n",
        "\n",
        "Since we are training our model on a few thousands of examples, the training only takes a few seconds. But training models on larger datasets, with more labels can start to be too slow. A potential solution to make the training faster is to use the hierarchical softmax, instead of the regular softmax. This can be done with the option -loss hs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB76_Hqk5Ugd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bed8e43c-ef89-41e3-bdc9-b56a57e4acec"
      },
      "source": [
        "model = fasttext.train_supervised(input=\"cooking.train\", lr=1.0, epoch=25, \n",
        "                                  wordNgrams=2, bucket=200000, dim=50, loss='hs')\n",
        "model.test(\"cooking.valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.5806666666666667, 0.25111719763586565)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAOVbwXyPBMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1256ad5-73d8-4bea-c310-8dbef96c4b55"
      },
      "source": [
        "model.predict(\"Which baking dish is best to bake a banana bread ?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__baking',), array([0.41760537]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhmRFYRHOjfn",
        "colab_type": "text"
      },
      "source": [
        "##Multi-label classification\n",
        "When we want to assign a document to multiple labels, we can still use the softmax loss and play with the parameters for prediction, namely the number of labels to predict and the threshold for the predicted probability. However playing with these arguments can be tricky and unintuitive since the probabilities must sum to 1.\n",
        "\n",
        "A convenient way to handle multiple labels is to use independent binary classifiers for each label. This can be done with -loss one-vs-all or -loss ova."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wn4eF2--78l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bcd3d31-aec1-4c87-81c5-e6462f06c60b"
      },
      "source": [
        "model = fasttext.train_supervised(input=\"cooking.train\", lr=0.5, epoch=25, wordNgrams=2, \n",
        "                                  bucket=200000, dim=50, loss='ova')\n",
        "model.test(\"cooking.valid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 0.604, 0.2612080149920715)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-84j7bZWO8f2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d619d1e6-0554-4f1f-e0ae-3328b3b3c3fc"
      },
      "source": [
        "model.predict(\"Which baking dish is best to bake a banana bread ?\", k=-1, threshold=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__baking',\n",
              "  '__label__equipment',\n",
              "  '__label__bread',\n",
              "  '__label__bananas'),\n",
              " array([1.00001001, 0.97967768, 0.97632056, 0.8872146 ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgbErXWbOsc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}