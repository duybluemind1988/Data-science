{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movies_review_sentiment.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/duybluemind1988/Data-science/blob/master/NLP/Kaggle_movie_sentiment/Movies_review_sentiment2.ipynb",
      "authorship_tag": "ABX9TyOGIYv10t4z7Yk4FVWwaN7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duybluemind1988/Data-science/blob/master/NLP/Kaggle_movie_sentiment/Movies_review_sentiment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqma_rg6Vlzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Jul 31 20:05:23 2017\n",
        "@author: DIP\n",
        "@Copyright: Dipanjan Sarkar\n",
        "\"\"\"\n",
        "\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import clone\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_curve, auc \n",
        "\n",
        "\n",
        "def get_metrics(true_labels, predicted_labels):\n",
        "    \n",
        "    print('Accuracy:', np.round(\n",
        "                        metrics.accuracy_score(true_labels, \n",
        "                                               predicted_labels),\n",
        "                        4))\n",
        "    print('Precision:', np.round(\n",
        "                        metrics.precision_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n",
        "    print('Recall:', np.round(\n",
        "                        metrics.recall_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n",
        "    print('F1 Score:', np.round(\n",
        "                        metrics.f1_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        4))\n",
        "                        \n",
        "\n",
        "def train_predict_model(classifier, \n",
        "                        train_features, train_labels, \n",
        "                        test_features, test_labels):\n",
        "    # build model    \n",
        "    classifier.fit(train_features, train_labels)\n",
        "    # predict using model\n",
        "    predictions = classifier.predict(test_features) \n",
        "    return predictions    \n",
        "\n",
        "\n",
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
        "    \n",
        "    total_classes = len(classes)\n",
        "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
        "\n",
        "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n",
        "                                  labels=classes)\n",
        "    cm_frame = pd.DataFrame(data=cm, \n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
        "                                                  labels=level_labels), \n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
        "                                                labels=level_labels)) \n",
        "    print(cm_frame) \n",
        "\n",
        "\n",
        "def display_confusion_matrix_pretty(true_labels, predicted_labels, classes=[1,0]):\n",
        "    \n",
        "    total_classes = len(classes)\n",
        "    level_labels = [total_classes*[0], list(range(total_classes))]\n",
        "\n",
        "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \n",
        "                                  labels=classes)\n",
        "    cm_frame = pd.DataFrame(data=cm, \n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
        "                                                  labels=level_labels), \n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
        "                                                labels=level_labels)) \n",
        "    return cm_frame\n",
        "    \n",
        "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\n",
        "\n",
        "    report = metrics.classification_report(y_true=true_labels, \n",
        "                                           y_pred=predicted_labels, \n",
        "                                           labels=classes) \n",
        "    print(report)\n",
        "    \n",
        "    \n",
        "    \n",
        "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\n",
        "    print('Model Performance metrics:')\n",
        "    print('-'*30)\n",
        "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\n",
        "    print('\\nModel Classification report:')\n",
        "    print('-'*30)\n",
        "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \n",
        "                                  classes=classes)\n",
        "    print('\\nPrediction Confusion Matrix:')\n",
        "    print('-'*30)\n",
        "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \n",
        "                             classes=classes)\n",
        "\n",
        "\n",
        "def plot_model_decision_surface(clf, train_features, train_labels,\n",
        "                                plot_step=0.02, cmap=plt.cm.RdYlBu,\n",
        "                                markers=None, alphas=None, colors=None):\n",
        "    \n",
        "    if train_features.shape[1] != 2:\n",
        "        raise ValueError(\"X_train should have exactly 2 columnns!\")\n",
        "    \n",
        "    x_min, x_max = train_features[:, 0].min() - plot_step, train_features[:, 0].max() + plot_step\n",
        "    y_min, y_max = train_features[:, 1].min() - plot_step, train_features[:, 1].max() + plot_step\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                         np.arange(y_min, y_max, plot_step))\n",
        "\n",
        "    clf_est = clone(clf)\n",
        "    clf_est.fit(train_features,train_labels)\n",
        "    if hasattr(clf_est, 'predict_proba'):\n",
        "        Z = clf_est.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:,1]\n",
        "    else:\n",
        "        Z = clf_est.predict(np.c_[xx.ravel(), yy.ravel()])    \n",
        "    Z = Z.reshape(xx.shape)\n",
        "    cs = plt.contourf(xx, yy, Z, cmap=cmap)\n",
        "    \n",
        "    le = LabelEncoder()\n",
        "    y_enc = le.fit_transform(train_labels)\n",
        "    n_classes = len(le.classes_)\n",
        "    plot_colors = ''.join(colors) if colors else [None] * n_classes\n",
        "    label_names = le.classes_\n",
        "    markers = markers if markers else [None] * n_classes\n",
        "    alphas = alphas if alphas else [None] * n_classes\n",
        "    for i, color in zip(range(n_classes), plot_colors):\n",
        "        idx = np.where(y_enc == i)\n",
        "        plt.scatter(train_features[idx, 0], train_features[idx, 1], c=color,\n",
        "                    label=label_names[i], cmap=cmap, edgecolors='black', \n",
        "                    marker=markers[i], alpha=alphas[i])\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_model_roc_curve(clf, features, true_labels, label_encoder=None, class_names=None):\n",
        "    \n",
        "    ## Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    if hasattr(clf, 'classes_'):\n",
        "        class_labels = clf.classes_\n",
        "    elif label_encoder:\n",
        "        class_labels = label_encoder.classes_\n",
        "    elif class_names:\n",
        "        class_labels = class_names\n",
        "    else:\n",
        "        raise ValueError('Unable to derive prediction classes, please specify class_names!')\n",
        "    n_classes = len(class_labels)\n",
        "    y_test = label_binarize(true_labels, classes=class_labels)\n",
        "    if n_classes == 2:\n",
        "        if hasattr(clf, 'predict_proba'):\n",
        "            prob = clf.predict_proba(features)\n",
        "            y_score = prob[:, prob.shape[1]-1] \n",
        "        elif hasattr(clf, 'decision_function'):\n",
        "            prob = clf.decision_function(features)\n",
        "            y_score = prob[:, prob.shape[1]-1]\n",
        "        else:\n",
        "            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
        "        \n",
        "        fpr, tpr, _ = roc_curve(y_test, y_score)      \n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
        "                                 ''.format(roc_auc),\n",
        "                 linewidth=2.5)\n",
        "        \n",
        "    elif n_classes > 2:\n",
        "        if hasattr(clf, 'predict_proba'):\n",
        "            y_score = clf.predict_proba(features)\n",
        "        elif hasattr(clf, 'decision_function'):\n",
        "            y_score = clf.decision_function(features)\n",
        "        else:\n",
        "            raise AttributeError(\"Estimator doesn't have a probability or confidence scoring system!\")\n",
        "\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        ## Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        ## Compute macro-average ROC curve and ROC area\n",
        "        # First aggregate all false positive rates\n",
        "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "        # Then interpolate all ROC curves at this points\n",
        "        mean_tpr = np.zeros_like(all_fpr)\n",
        "        for i in range(n_classes):\n",
        "            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "        # Finally average it and compute AUC\n",
        "        mean_tpr /= n_classes\n",
        "        fpr[\"macro\"] = all_fpr\n",
        "        tpr[\"macro\"] = mean_tpr\n",
        "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "        ## Plot ROC curves\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"micro\"]), linewidth=3)\n",
        "\n",
        "        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "                 label='macro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"macro\"]), linewidth=3)\n",
        "\n",
        "        for i, label in enumerate(class_labels):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(label, roc_auc[i]), \n",
        "                     linewidth=2, linestyle=':')\n",
        "    else:\n",
        "        raise ValueError('Number of classes should be atleast 2 or more')\n",
        "        \n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xORWZxYZWnzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path='/content/drive/My Drive/Data/NLP/Kaggle_movie_review_sentiment/train.tsv'\n",
        "test_path='/content/drive/My Drive/Data/NLP/Kaggle_movie_review_sentiment/test.tsv'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIPnIGzIXSl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install text_normalizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1LtJ8a-WuP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import text_normalizer as tn\n",
        "#import model_evaluation_utils as meu\n",
        "import nltk\n",
        "import textblob\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_9x2xcHXO8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bc7e665c-3506-4938-d320-611c79dcccd2"
      },
      "source": [
        "train_df=pd.read_csv(train_path,sep='\\t')\n",
        "print(train_df.shape)\n",
        "train_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(156060, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AV4Gg7XX_vT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "83ddfb59-8f4a-4831-d385-5769041c8d05"
      },
      "source": [
        "train_df['Sentiment'].value_counts()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hiw_EN5lZjVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train_df['Phrase']\n",
        "y=train_df['Sentiment']"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRxn1HsUaFvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "512be525-66fc-47ce-f707-658f78a7ee31"
      },
      "source": [
        "X"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         A series of escapades demonstrating the adage ...\n",
              "1         A series of escapades demonstrating the adage ...\n",
              "2                                                  A series\n",
              "3                                                         A\n",
              "4                                                    series\n",
              "                                ...                        \n",
              "156055                                            Hearst 's\n",
              "156056                            forced avuncular chortles\n",
              "156057                                   avuncular chortles\n",
              "156058                                            avuncular\n",
              "156059                                             chortles\n",
              "Name: Phrase, Length: 156060, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaT8XZqRaCCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e6b3a9f4-6e3b-4019-d1e5-468d377e7161"
      },
      "source": [
        "y"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1\n",
              "1         2\n",
              "2         2\n",
              "3         2\n",
              "4         2\n",
              "         ..\n",
              "156055    2\n",
              "156056    1\n",
              "156057    3\n",
              "156058    2\n",
              "156059    2\n",
              "Name: Sentiment, Length: 156060, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4196zxaXZ3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8c7cbab8-347f-4453-d618-e4f4adebb711"
      },
      "source": [
        "test_df=pd.read_csv(test_path,sep='\\t')\n",
        "print(test_df.shape)\n",
        "test_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66292, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase\n",
              "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2    156063        8545                                                 An\n",
              "3    156064        8545  intermittently pleasing but mostly routine effort\n",
              "4    156065        8545         intermittently pleasing but mostly routine"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWcoTIoTZCvT",
        "colab_type": "text"
      },
      "source": [
        "Text have no label, so we split training set to train and text set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsRjqjw3YJsc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMJZjXxOZXlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,\n",
        "                                               stratify=y,random_state=42)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4CHcYlYZqu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7052459b-b677-491c-e22b-fe90ba083253"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(109242,)\n",
            "(109242,)\n",
            "(46818,)\n",
            "(46818,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDf2PKyGZyCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fbec5c5b-8d62-45df-a0f6-6f68beaeac3d"
      },
      "source": [
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    0.509950\n",
              "3    0.210990\n",
              "1    0.174759\n",
              "4    0.058988\n",
              "0    0.045312\n",
              "Name: Sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK9lRF3zZ8MB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0d63f978-046f-44d5-94e0-ac4212b38257"
      },
      "source": [
        "y_test.value_counts(normalize=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    0.509932\n",
              "3    0.210987\n",
              "1    0.174762\n",
              "4    0.058994\n",
              "0    0.045324\n",
              "Name: Sentiment, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-6db3nzaN1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}