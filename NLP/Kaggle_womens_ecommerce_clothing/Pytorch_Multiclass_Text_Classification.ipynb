{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_Multiclass Text Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyML7LqJ/44MeXCL1hcog7cW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duybluemind1988/Data-science/blob/master/NLP/Kaggle_womens_ecommerce_clothing/Pytorch_Multiclass_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZSS1_MxGbDD",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews/notebooks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWxXnW-vF1fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#library imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import spacy\n",
        "#import jovian\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import string\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXFaih5bF8BF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "adec7301-c541-42ec-bef1-1b82d7cb57a7"
      },
      "source": [
        "#loading the data\n",
        "reviews = pd.read_csv(\"https://raw.githubusercontent.com/NadimKawwa/WomeneCommerce/master/Womens%20Clothing%20E-Commerce%20Reviews.csv\")\n",
        "print(reviews.shape)\n",
        "reviews.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23486, 11)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Clothing ID  Age  ...   Division Name Department Name  Class Name\n",
              "0           0          767   33  ...       Initmates        Intimate   Intimates\n",
              "1           1         1080   34  ...         General         Dresses     Dresses\n",
              "2           2         1077   60  ...         General         Dresses     Dresses\n",
              "3           3         1049   50  ...  General Petite         Bottoms       Pants\n",
              "4           4          847   47  ...         General            Tops     Blouses\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siuipof-GVH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Combine reviews title and review text\n",
        "reviews['Title'] = reviews['Title'].fillna('')\n",
        "reviews['Review Text'] = reviews['Review Text'].fillna('')\n",
        "reviews['review'] = reviews['Title'] + ' ' + reviews['Review Text']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yIq-b2jHB6t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "a66273c4-9eba-4d3d-88c0-bf025df7c7f2"
      },
      "source": [
        "reviews.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Some major design flaws I had such high hopes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "      <td>Flattering shirt This shirt is very flattering...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                             review\n",
              "0           0  ...   Absolutely wonderful - silky and sexy and com...\n",
              "1           1  ...   Love this dress!  it's sooo pretty.  i happen...\n",
              "2           2  ...  Some major design flaws I had such high hopes ...\n",
              "3           3  ...  My favorite buy! I love, love, love this jumps...\n",
              "4           4  ...  Flattering shirt This shirt is very flattering...\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKoUWJKfUtRe",
        "colab_type": "text"
      },
      "source": [
        "Metric\n",
        "\n",
        "We usually take accuracy as our metric for most classification problems, however, ratings are ordered. If the actual value is 5 but the model predicts a 4, it is not considered as bad as predicting a 1. Hence, instead of going with accuracy, we choose RMSE — root mean squared error as our North Star metric. Also, rating prediction is a pretty hard problem, even for humans, so a prediction of being off by just 1 point or lesser is considered pretty good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruMwumCPHCss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "5ba462b9-1e07-4b6d-f84f-7f30b1c15d77"
      },
      "source": [
        "#keeping only relevant columns and calculating sentence lengths\n",
        "reviews = reviews[['review', 'Rating']]\n",
        "reviews.columns = ['review', 'rating']\n",
        "reviews['review_length'] = reviews['review'].apply(lambda x: len(x.split()))\n",
        "reviews.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>review_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and com...</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happen...</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Some major design flaws I had such high hopes ...</td>\n",
              "      <td>3</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
              "      <td>5</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flattering shirt This shirt is very flattering...</td>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  rating  review_length\n",
              "0   Absolutely wonderful - silky and sexy and com...       4              8\n",
              "1   Love this dress!  it's sooo pretty.  i happen...       5             62\n",
              "2  Some major design flaws I had such high hopes ...       3            102\n",
              "3  My favorite buy! I love, love, love this jumps...       5             25\n",
              "4  Flattering shirt This shirt is very flattering...       5             38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8W5lyX2HT9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "93b27fa2-b2da-4b6b-8786-a3a2c0f61431"
      },
      "source": [
        "#changing ratings to 0-numbering\n",
        "zero_numbering = {1:0, 2:1, 3:2, 4:3, 5:4}\n",
        "reviews['rating'] = reviews['rating'].apply(lambda x: zero_numbering[x])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwWKpmR_HXd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "94af9af1-c01b-4089-e6e9-6e8b3e87e06d"
      },
      "source": [
        "reviews.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>review_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and com...</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happen...</td>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Some major design flaws I had such high hopes ...</td>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flattering shirt This shirt is very flattering...</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  rating  review_length\n",
              "0   Absolutely wonderful - silky and sexy and com...       3              8\n",
              "1   Love this dress!  it's sooo pretty.  i happen...       4             62\n",
              "2  Some major design flaws I had such high hopes ...       2            102\n",
              "3  My favorite buy! I love, love, love this jumps...       4             25\n",
              "4  Flattering shirt This shirt is very flattering...       4             38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF2NonPsPwp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b864fd1b-5872-47b8-ae69-faa3032b7ae7"
      },
      "source": [
        "#mean sentence length\n",
        "np.mean(reviews['review_length'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60.832921740611425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mAqtgGUUzvA",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "As mentioned earlier, we need to convert our text into a numerical form that can be fed to our model as input. I’ve used spacy for tokenization after removing punctuation, special characters, and lower casing the text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwdcxfLrPzP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenization\n",
        "tok = spacy.load('en')\n",
        "def tokenize (text):\n",
        "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
        "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]') # remove punctuation and numbers\n",
        "    nopunct = regex.sub(\" \", text.lower())\n",
        "    return [token.text for token in tok.tokenizer(nopunct)]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUZVsrlwVdk7",
        "colab_type": "text"
      },
      "source": [
        "We count the number of occurrences of each token in our corpus and get rid of the ones that don’t occur too frequently:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ESMbH1P3Qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#count number of occurences of each word\n",
        "counts = Counter()\n",
        "for index, row in reviews.iterrows():\n",
        "    counts.update(tokenize(row['review']))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoKZJRbrVsZo",
        "colab_type": "text"
      },
      "source": [
        "Counter({' ': 142615,\n",
        "         'absolutely': 865,\n",
        "         'wonderful': 354,\n",
        "         '  ': 17445,\n",
        "         'silky': 132,\n",
        "         'and': 50853,\n",
        "         'sexy': 269,\n",
        "         'comfortable': 3533,\n",
        "         'love': 10819,\n",
        "         'this': 26693,\n",
        "         'dress': 12221,\n",
        "         'it': 50036,\n",
        "         's': 9191,\n",
        "         'sooo': 57,\n",
        "         'pretty': 2866,\n",
        "         'i': 67652,\n",
        "         'happened': 72,\n",
        "         'to': 25159,\n",
        "         'find': 983,\n",
        "         'in': 21343,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu6coaQPQC2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e4547d2d-5d8f-4a3a-cda8-5c8a548a1662"
      },
      "source": [
        "#deleting infrequent words\n",
        "print(\"num_words before:\",len(counts.keys()))\n",
        "for word in list(counts):\n",
        "    if counts[word] < 2:\n",
        "        del counts[word]\n",
        "print(\"num_words after:\",len(counts.keys()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_words before: 14138\n",
            "num_words after: 8263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4t6Zq9WVvNr",
        "colab_type": "text"
      },
      "source": [
        "We lost about 6000 words! This is expected because our corpus is quite small, less than 25k reviews, the chance of having repeated words is quite small.\n",
        "\n",
        "We then create a vocabulary to index mapping and encode our review text using this mapping. I’ve chosen the maximum length of any review to be 70 words because the average length of reviews was around 60.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMeBVxcQPt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating vocabulary\n",
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in counts:\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X_FrSI_R4nG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dd235fb6-ac8a-4827-c5e3-2405980e2d70"
      },
      "source": [
        "print(len(words))\n",
        "print(len(vocab2index))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8265\n",
            "8265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1ZWBpS1QTpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab2index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3TuaVVcQX4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_sentence(text, vocab2index, N=70):\n",
        "    tokenized = tokenize(text)\n",
        "    encoded = np.zeros(N, dtype=int)\n",
        "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
        "    length = min(N, len(enc1))\n",
        "    encoded[:length] = enc1[:length]\n",
        "    return encoded, length"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaeAWa4bQmjG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "7778edb0-b6fa-4167-91ed-ab3259b4dfe7"
      },
      "source": [
        "reviews['encoded'] = reviews['review'].apply(lambda x: np.array(encode_sentence(x,vocab2index )))\n",
        "reviews.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>review_length</th>\n",
              "      <th>encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and com...</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>[[2, 3, 4, 5, 6, 7, 8, 7, 9, 0, 0, 0, 0, 0, 0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happen...</td>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "      <td>[[2, 10, 11, 12, 5, 13, 14, 15, 16, 5, 17, 18,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Some major design flaws I had such high hopes ...</td>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "      <td>[[54, 55, 56, 57, 17, 58, 59, 60, 61, 62, 11, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>[[68, 109, 110, 2, 17, 10, 2, 10, 2, 10, 11, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Flattering shirt This shirt is very flattering...</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>[[122, 123, 11, 123, 52, 92, 122, 19, 124, 125...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                            encoded\n",
              "0   Absolutely wonderful - silky and sexy and com...  ...  [[2, 3, 4, 5, 6, 7, 8, 7, 9, 0, 0, 0, 0, 0, 0,...\n",
              "1   Love this dress!  it's sooo pretty.  i happen...  ...  [[2, 10, 11, 12, 5, 13, 14, 15, 16, 5, 17, 18,...\n",
              "2  Some major design flaws I had such high hopes ...  ...  [[54, 55, 56, 57, 17, 58, 59, 60, 61, 62, 11, ...\n",
              "3  My favorite buy! I love, love, love this jumps...  ...  [[68, 109, 110, 2, 17, 10, 2, 10, 2, 10, 11, 1...\n",
              "4  Flattering shirt This shirt is very flattering...  ...  [[122, 123, 11, 123, 52, 92, 122, 19, 124, 125...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w-d0JZMQojV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc9b36fa-9f03-4441-b0ea-30e0c13a4283"
      },
      "source": [
        "#check how balanced the dataset is\n",
        "Counter(reviews['rating'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 842, 1: 1565, 2: 2871, 3: 5077, 4: 13131})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xno4u4dHQs0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = list(reviews['encoded'])\n",
        "y = list(reviews['rating'])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAlYatrrQwP1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7267d792-dce8-4b16-8af2-db0cd791d75d"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_train[0][0]))\n",
        "print(len(X_train[1][0]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18788\n",
            "70\n",
            "70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMkx0VIDQw-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e20f9aa6-005c-4749-db11-b187266af1db"
      },
      "source": [
        "X_train[0][0]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  74,   10,    2,   74,  426,    2,   17,  503,  368, 1502,   21,\n",
              "         37,   23,   11,  512,    7,  367,   22, 1648,    5,  300,  328,\n",
              "        223,  175,  426,    7,   17,  460,  300,  373,  223,   47,  426,\n",
              "         39,    2,  182,   37,   43,  896,  545, 1196,    5,   71,   17,\n",
              "         84,   74,  424,    2,  444,  300,  179,   39,  619,    2,   17,\n",
              "        367,   22,  408,  256,  108,    2,   17, 1265,   22,  326,  639,\n",
              "        136,   62,   22, 1879])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUtCdZtPQ-ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2b1ae61-d03d-4fd0-e551-71e86ceae40a"
      },
      "source": [
        "X_train[0][1]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1GneHOpREYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "203270a4-afbe-4e79-a8de-71fcb51d46a5"
      },
      "source": [
        "print(len(y_train))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59kKnRfRRSVz",
        "colab_type": "text"
      },
      "source": [
        "# Pytorch Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8XrPf03V0Hj",
        "colab_type": "text"
      },
      "source": [
        "The dataset is quite straightforward because we’ve already stored our encodings in the input dataframe. We also output the length of the input sequence in each case, because we can have LSTMs that take variable-length sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez2e3Ah9RHcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nORhlkJZRUr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = ReviewsDataset(X_train, y_train)\n",
        "valid_ds = ReviewsDataset(X_valid, y_valid)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiIfKYEdRXeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, epochs=10, lr=0.001):\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        for x, y, l in train_dl:\n",
        "            x = x.long()\n",
        "            y = y.long()\n",
        "            y_pred = model(x, l)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.cross_entropy(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
        "        if i % 5 == 1:\n",
        "            print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
        "\n",
        "def validation_metrics (model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    sum_rmse = 0.0\n",
        "    for x, y, l in valid_dl:\n",
        "        x = x.long()\n",
        "        y = y.long()\n",
        "        y_hat = model(x, l)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = torch.max(y_hat, 1)[1]\n",
        "        correct += (pred == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
        "    return sum_loss/total, correct/total, sum_rmse/total"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4slYK65RRlql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce4f1c16-40a4-4213-f147-669aaa30adb9"
      },
      "source": [
        "batch_size = 5000\n",
        "vocab_size = len(words)\n",
        "print(vocab_size)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjEHfCfJSM4G",
        "colab_type": "text"
      },
      "source": [
        "# LSTM with fixed length input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsKfyQ5HUEy7",
        "colab_type": "text"
      },
      "source": [
        "This pretty much has the same structure as the basic LSTM we saw earlier, with the addition of a dropout layer to prevent overfitting. Since we have a classification problem, we have a final linear layer with 5 outputs. This implementation actually works the best among the classification LSTMs, with an accuracy of about 64% and a root-mean-squared-error of only 0.817"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kizQy5mXSKwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_fixed_len(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 5)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x, l):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmYKNOGVSORv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fixed =  LSTM_fixed_len(vocab_size, 50, 50)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsgIZ9kVSRwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d30f1796-d2ef-4e8d-9956-3ac2fbd31e32"
      },
      "source": [
        "train_model(model_fixed, epochs=30, lr=0.01)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train loss 1.257, val loss 1.212, val accuracy 0.566, and val rmse 1.357\n",
            "train loss 1.193, val loss 1.198, val accuracy 0.565, and val rmse 1.355\n",
            "train loss 1.125, val loss 1.134, val accuracy 0.557, and val rmse 1.101\n",
            "train loss 1.012, val loss 1.092, val accuracy 0.541, and val rmse 1.040\n",
            "train loss 1.040, val loss 1.168, val accuracy 0.498, and val rmse 1.092\n",
            "train loss 1.019, val loss 1.097, val accuracy 0.546, and val rmse 1.054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuVWQdcNUIah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_model(model_fixed, epochs=30, lr=0.01)\n",
        "#train_model(model_fixed, epochs=30, lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AxyixbvUUQj",
        "colab_type": "text"
      },
      "source": [
        "# 2. LSTM with variable input size:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6_HVEjPUVxm",
        "colab_type": "text"
      },
      "source": [
        "We can modify our model a bit to make it accept variable-length inputs. This ends up increasing the training time though, because of the pack_padded_sequence function call which returns a padded batch of variable-length sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP4PpBe8UKxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_variable_input(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 5)\n",
        "        \n",
        "    def forward(self, x, s):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        x_pack = pack_padded_sequence(x, s, batch_first=True, enforce_sorted=False)\n",
        "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
        "        out = self.linear(ht[-1])\n",
        "        return out"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWAl4L9jSUhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(model, epochs=30, lr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIyDA7FcUZDJ",
        "colab_type": "text"
      },
      "source": [
        "# 3. LSTM with fixed input size and fixed pre-trained Glove word-vectors:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2T0T-0BUbI5",
        "colab_type": "text"
      },
      "source": [
        "Instead of training our own word embeddings, we can use pre-trained Glove word vectors that have been trained on a massive corpus and probably have better context captured. For our problem, however, this doesn’t seem to help much."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f70_3iEMUaHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_glove_vectors(glove_file=\"./data/glove.6B/glove.6B.50d.txt\"):\n",
        "    \"\"\"Load the glove word vectors\"\"\"\n",
        "    word_vectors = {}\n",
        "    with open(glove_file) as f:\n",
        "        for line in f:\n",
        "            split = line.split()\n",
        "            word_vectors[split[0]] = np.array([float(x) for x in split[1:]])\n",
        "    return word_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXcTkdhwUdku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_emb_matrix(pretrained, word_counts, emb_size = 50):\n",
        "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
        "    vocab_size = len(word_counts) + 2\n",
        "    vocab_to_idx = {}\n",
        "    vocab = [\"\", \"UNK\"]\n",
        "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
        "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
        "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
        "    vocab_to_idx[\"UNK\"] = 1\n",
        "    i = 2\n",
        "    for word in word_counts:\n",
        "        if word in word_vecs:\n",
        "            W[i] = word_vecs[word]\n",
        "        else:\n",
        "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
        "        vocab_to_idx[word] = i\n",
        "        vocab.append(word)\n",
        "        i += 1   \n",
        "    return W, np.array(vocab), vocab_to_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFQT3A47UdsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_vecs = load_glove_vectors()\n",
        "pretrained_weights, vocab, vocab2index = get_emb_matrix(word_vecs, counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8AidkQSUdvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_glove_vecs(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
        "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 5)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x, l):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwiqLQZ_UdqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model(model, epochs=30, lr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leLhXXQyUhix",
        "colab_type": "text"
      },
      "source": [
        "# Predicting ratings using regression instead of classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgc3Aen-Ujy8",
        "colab_type": "text"
      },
      "source": [
        "Since ratings have an order, and a prediction of 3.6 might be better than rounding off to 4 in many cases, it is helpful to explore this as a regression problem. Not surprisingly, this approach gives us the lowest error of just 0.799 because we don’t have just integer predictions anymore.\n",
        "The only change to our model is that instead of the final layer having 5 outputs, we have just one. The training loop changes a bit too, we use MSE loss and we don’t need to take the argmax anymore to get the final prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4mrQAlWUdn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_regr(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "    def forward(self, x, l):\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        lstm_out, (ht, ct) = self.lstm(x)\n",
        "        return self.linear(ht[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzsoNtJqUl_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model_regr(model, epochs=30, lr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSmDYMm6Unod",
        "colab_type": "text"
      },
      "source": [
        "Conclusion:\n",
        "LSTM appears to be theoretically involved, but its Pytorch implementation is pretty straightforward. Also, while looking at any problem, it is very important to choose the right metric, in our case if we’d gone for accuracy, the model seems to be doing a very bad job, but the RMSE shows that it is off by less than 1 rating point, which is comparable to human performance!"
      ]
    }
  ]
}