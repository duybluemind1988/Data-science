{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_Amazone_review_sentiments.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAJddn9lp0Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import bz2\n",
        "import gc\n",
        "import chardet\n",
        "import re\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVC4bZHGrTnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = bz2.BZ2File('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train.ft.txt.bz2')\n",
        "test_file = bz2.BZ2File('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test.ft.txt.bz2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkELqPpYz5EV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d768abc-4346-46ae-a7cf-7a52ff513e88"
      },
      "source": [
        "train_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bz2.BZ2File at 0x7fb4b8afbc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXbztI3WyMHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_lines = train_file.readlines()\n",
        "test_file_lines = test_file.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMkf0ynOrj6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
        "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6G7l3p_0DVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "86b49516-6b50-4e4e-c679-34287e420761"
      },
      "source": [
        "train_file_lines[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n',\n",
              " \"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
              " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n',\n",
              " \"__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\\n\",\n",
              " \"__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROw81W0BrkDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file_lines]\n",
        "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file_lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXyJYGoVrkGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "029cbff0-2ec0-4e77-f53d-1d9b511131d4"
      },
      "source": [
        "train_labels[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9VCj3ze0K3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op-m_QDL0OHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_sentences)):\n",
        "    train_sentences[i] = re.sub('\\d','0',train_sentences[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCrNx4I0XRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa9nxicQ0kKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1482e490-34aa-4f55-b16f-eaed38489953"
      },
      "source": [
        "print(len(train_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3600000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9oE82Ih0gZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file_lines]\n",
        "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file_lines]\n",
        "\n",
        "for i in range(len(test_sentences)):\n",
        "    test_sentences[i] = re.sub('\\d','0',test_sentences[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62-5qitp0rHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44c33299-7715-4d31-8a23-3fdafa7c6247"
      },
      "source": [
        "print(len(test_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPf8LC5x0svY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_sentences)):\n",
        "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
        "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n",
        "        \n",
        "for i in range(len(test_sentences)):\n",
        "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
        "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLtxAAwq0z_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_file_lines, test_file_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVAsL5oT05ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b16dfc74-48e9-44fa-84b6-33c91c14944c"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIYScaNu1Sfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences\n",
        "train_labels\n",
        "test_sentences\n",
        "test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU9Is0Kh4xBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1212d493-94dd-4295-b98b-ac00782157ba"
      },
      "source": [
        "train_set=pd.concat([pd.DataFrame(train_sentences),pd.DataFrame(train_labels)],axis=1)\n",
        "train_set.columns=['review','label']\n",
        "train_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stuning even for the non-gamer: this sound tra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the best soundtrack ever to anything.: i'm rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazing!: this soundtrack is my favorite music...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>excellent soundtrack: i truly like this soundt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>remember, pull your jaw off the floor after he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  stuning even for the non-gamer: this sound tra...      1\n",
              "1  the best soundtrack ever to anything.: i'm rea...      1\n",
              "2  amazing!: this soundtrack is my favorite music...      1\n",
              "3  excellent soundtrack: i truly like this soundt...      1\n",
              "4  remember, pull your jaw off the floor after he...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "facG0nYb5gir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5118316e-3f35-42c8-fa38-32e86c726923"
      },
      "source": [
        "test_set=pd.concat([pd.DataFrame(test_sentences),pd.DataFrame(test_labels)],axis=1)\n",
        "test_set.columns=['review','label']\n",
        "test_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>great cd: my lovely pat has one of the great v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>one of the best game music soundtracks - for a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>batteries died within a year ...: i bought thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>works fine, but maha energy is better: check o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great for the non-audiophile: reviewed quite a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  great cd: my lovely pat has one of the great v...      1\n",
              "1  one of the best game music soundtracks - for a...      1\n",
              "2  batteries died within a year ...: i bought thi...      0\n",
              "3  works fine, but maha energy is better: check o...      1\n",
              "4  great for the non-audiophile: reviewed quite a...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmhAij4D5myT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set.to_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv')\n",
        "test_set.to_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test_set.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny_ZASKb6PWP",
        "colab_type": "text"
      },
      "source": [
        "# Code for re-process text data from Text_analytic Apress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-tCZjzJ6VFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Aug 01 01:11:02 2016\n",
        "@author: DIP\n",
        "\"\"\"\n",
        "\n",
        "CONTRACTION_MAP = {\n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODHmdls06WNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7cc18082-88c1-44b3-efec-5c400c85c96d"
      },
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import unicodedata\n",
        "#from contractions import CONTRACTION_MAP\n",
        "import re\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('stopwords')\n",
        "import collections\n",
        "#from textblob import Word\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "nlp = spacy.load('en', parse=True, tag=True, entity=True)\n",
        "# nlp_vec = spacy.load('en_vectors_web_lg', parse=True, tag=True, entity=True)\n",
        "\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    if bool(soup.find()):\n",
        "        [s.extract() for s in soup(['iframe', 'script'])]\n",
        "        stripped_text = soup.get_text()\n",
        "        stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "    else:\n",
        "        stripped_text = text\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "#def correct_spellings_textblob(tokens):\n",
        "#\treturn [Word(token).correct() for token in tokens]  \n",
        "\n",
        "\n",
        "def simple_porter_stemming(text):\n",
        "    ps = nltk.porter.PorterStemmer()\n",
        "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_repeated_characters(tokens):\n",
        "    repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
        "    match_substitution = r'\\1\\2\\3'\n",
        "    def replace(old_word):\n",
        "        if wordnet.synsets(old_word):\n",
        "            return old_word\n",
        "        new_word = repeat_pattern.sub(match_substitution, old_word)\n",
        "        return replace(new_word) if new_word != old_word else new_word\n",
        "            \n",
        "    correct_tokens = [replace(word) for word in tokens]\n",
        "    return correct_tokens\n",
        "\n",
        "\n",
        "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
        "    \n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
        "                                      flags=re.IGNORECASE|re.DOTALL)\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match)\\\n",
        "                                if contraction_mapping.get(match)\\\n",
        "                                else contraction_mapping.get(match.lower())                       \n",
        "        expanded_contraction = first_char+expanded_contraction[1:]\n",
        "        return expanded_contraction\n",
        "        \n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text\n",
        "\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^a-zA-Z0-9\\s]|\\[|\\]' if not remove_digits else r'[^a-zA-Z\\s]|\\[|\\]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_stopwords(text, is_lower_case=False, stopwords=stopword_list):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "\n",
        "\n",
        "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
        "                     accented_char_removal=True, text_lower_case=True, \n",
        "                     text_stemming=False, text_lemmatization=True, \n",
        "                     special_char_removal=True, remove_digits=True,\n",
        "                     stopword_removal=True, stopwords=stopword_list):\n",
        "    \n",
        "    normalized_corpus = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "\n",
        "        # strip HTML\n",
        "        if html_stripping:\n",
        "            doc = strip_html_tags(doc)\n",
        "\n",
        "        # remove extra newlines\n",
        "        doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "\n",
        "        # remove accented characters\n",
        "        if accented_char_removal:\n",
        "            doc = remove_accented_chars(doc)\n",
        "\n",
        "        # expand contractions    \n",
        "        if contraction_expansion:\n",
        "            doc = expand_contractions(doc)\n",
        "\n",
        "        # lemmatize text\n",
        "        if text_lemmatization:\n",
        "            doc = lemmatize_text(doc)\n",
        "\n",
        "        # stem text\n",
        "        if text_stemming and not text_lemmatization:\n",
        "        \tdoc = simple_porter_stemming(doc)\n",
        "\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
        "\n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "\n",
        "         # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "\n",
        "        # remove stopwords\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc, is_lower_case=text_lower_case, stopwords=stopwords)\n",
        "\n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        doc = doc.strip()\n",
        "            \n",
        "        normalized_corpus.append(doc)\n",
        "        \n",
        "    return normalized_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4itx8LE1OC7",
        "colab_type": "text"
      },
      "source": [
        "# Ch09a - Sentiment Analysis - Unsupervised Lexical.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF3Q4cAxtRod",
        "colab_type": "text"
      },
      "source": [
        "No need to re-process data before training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCH_xUOS6GMY",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis with textblob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMwRJ05y6Clx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import text_normalizer as tn # specific ebook library\n",
        "#import model_evaluation_utils as meu # specific ebook library\n",
        "import nltk\n",
        "import textblob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfk5j-aI07TF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv')\n",
        "test_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test_set.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsuRJU6E59Nm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d686988-63ce-4283-d12e-746aae9dbbc4"
      },
      "source": [
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3600000, 3)\n",
            "(400000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9s4SsF-6ubT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5c08c9c0-7182-476a-8de8-938b025d3a1f"
      },
      "source": [
        "test_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>great cd: my lovely pat has one of the great v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>one of the best game music soundtracks - for a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>batteries died within a year ...: i bought thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>works fine, but maha energy is better: check o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>great for the non-audiophile: reviewed quite a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             review  label\n",
              "0           0  great cd: my lovely pat has one of the great v...      1\n",
              "1           1  one of the best game music soundtracks - for a...      1\n",
              "2           2  batteries died within a year ...: i bought thi...      0\n",
              "3           3  works fine, but maha energy is better: check o...      1\n",
              "4           4  great for the non-audiophile: reviewed quite a...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUt_F1q96qeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = np.array(test_set['review'])\n",
        "sentiments = np.array(test_set['label'])\n",
        "split_ratio=0.7\n",
        "split=int(test_set.shape[0]*0.7)\n",
        "test_reviews = reviews[split:]\n",
        "test_sentiments = sentiments[split:]\n",
        "sample_review_ids = [0, 200, 500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bexjv1pK60tQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b46bff1d-05a5-4624-e83d-2f0074e97c1c"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    print('Predicted Sentiment polarity:', textblob.TextBlob(review).sentiment.polarity)\n",
        "    print('-'*60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: amazing compositions, performances and recording quality!: having purchased and enjoyed the other 0 star disc of this group i had to see what \"closer\" was like.this disc is even better in many respects.the compositions are so clever, the arrangements perfect and the recording/mixing are stunning.would love to see a live concert here in new zealand!\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment polarity: 0.40984848484848485\n",
            "------------------------------------------------------------\n",
            "REVIEW: i liked it: great story, no violence, nudity, profanity, a movie everyone can watch and enjoy. i would recommend this movie to anyone\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment polarity: 0.6\n",
            "------------------------------------------------------------\n",
            "REVIEW: poor bob, victim of himself!: awful. i mean, really awful...and i liked \"self portrait\" because you knew dylan was just trying to have some fun with his image. this album is just a disaster. the lyrics are ok on most songs (i've seen worse by dylan), but the music is unexciting, not very creative, and downright embarrassing on some tracks. why, oh, why did you have to make an album like this, bob? such talented people at your disposal for these sessions, and you threw it away on garbage arrangements. shameful. really sad.\n",
            "Actual Sentiment: 0\n",
            "Predicted Sentiment polarity: -0.007039835164835172\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTiG2btK7NcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f51f1c76-45d9-489c-ae23-82e04c50113c"
      },
      "source": [
        "sentiment_polarity = [textblob.TextBlob(review).sentiment.polarity for review in test_reviews]\n",
        "predicted_sentiments = [1 if score >= 0.1 else 0 for score in sentiment_polarity]\n",
        "print(classification_report(test_sentiments,predicted_sentiments))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.65      0.73     60301\n",
            "           1       0.71      0.87      0.78     59699\n",
            "\n",
            "    accuracy                           0.76    120000\n",
            "   macro avg       0.77      0.76      0.76    120000\n",
            "weighted avg       0.77      0.76      0.76    120000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhvBk9kC7eh8",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis with AFINN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZvs_jTW7Xyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "16e1b948-245d-4f32-9fea-800e5ee8106a"
      },
      "source": [
        "!pip install afinn\n",
        "from afinn import Afinn\n",
        "afn = Afinn(emoticons=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting afinn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-cp36-none-any.whl size=53452 sha256=001d03417353dd2aadb3386448da728e155d6b6bf9a505f507cd1799791be206\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8WVtTAz7hsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "97110629-b292-4ade-a856-687b83a8e02b"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    print('Predicted Sentiment polarity:', afn.score(review))\n",
        "    print('-'*60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: amazing compositions, performances and recording quality!: having purchased and enjoyed the other 0 star disc of this group i had to see what \"closer\" was like.this disc is even better in many respects.the compositions are so clever, the arrangements perfect and the recording/mixing are stunning.would love to see a live concert here in new zealand!\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment polarity: 26.0\n",
            "------------------------------------------------------------\n",
            "REVIEW: i liked it: great story, no violence, nudity, profanity, a movie everyone can watch and enjoy. i would recommend this movie to anyone\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment polarity: 5.0\n",
            "------------------------------------------------------------\n",
            "REVIEW: poor bob, victim of himself!: awful. i mean, really awful...and i liked \"self portrait\" because you knew dylan was just trying to have some fun with his image. this album is just a disaster. the lyrics are ok on most songs (i've seen worse by dylan), but the music is unexciting, not very creative, and downright embarrassing on some tracks. why, oh, why did you have to make an album like this, bob? such talented people at your disposal for these sessions, and you threw it away on garbage arrangements. shameful. really sad.\n",
            "Actual Sentiment: 0\n",
            "Predicted Sentiment polarity: -13.0\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBLIgknu7hxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cbfdad77-0674-419f-967e-304941015c58"
      },
      "source": [
        "sentiment_polarity = [afn.score(review) for review in test_reviews]\n",
        "predicted_sentiments = [1 if score >= 1.0 else 0 for score in sentiment_polarity]\n",
        "print(classification_report(test_sentiments,predicted_sentiments))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.50      0.63     60301\n",
            "           1       0.64      0.92      0.76     59699\n",
            "\n",
            "    accuracy                           0.71    120000\n",
            "   macro avg       0.75      0.71      0.69    120000\n",
            "weighted avg       0.75      0.71      0.69    120000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgT_8STq7yxE",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis with SentiWordNet (VERY LONG, not stable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoCe0OTT7h01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "975de5fe-e7ae-4a90-9462-91628bec9392"
      },
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "import nltk\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "awesome = list(swn.senti_synsets('awesome', 'a'))[0]\n",
        "print('Positive Polarity Score:', awesome.pos_score())\n",
        "print('Negative Polarity Score:', awesome.neg_score())\n",
        "print('Objective Score:', awesome.obj_score())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Positive Polarity Score: 0.875\n",
            "Negative Polarity Score: 0.125\n",
            "Objective Score: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsJeGIF071P_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_sentiment_sentiwordnet_lexicon(review,\n",
        "                                           verbose=False):\n",
        "\n",
        "    # tokenize and POS tag text tokens\n",
        "    tagged_text = [(token.text, token.tag_) for token in nlp(review)] # from text_normalizer.py\n",
        "    pos_score = neg_score = token_count = obj_score = 0\n",
        "    # get wordnet synsets based on POS tags\n",
        "    # get sentiment scores if synsets are found\n",
        "    for word, tag in tagged_text:\n",
        "        ss_set = None\n",
        "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
        "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
        "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
        "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
        "        # if senti-synset is found        \n",
        "        if ss_set:\n",
        "            # add scores for all found synsets\n",
        "            pos_score += ss_set.pos_score()\n",
        "            neg_score += ss_set.neg_score()\n",
        "            obj_score += ss_set.obj_score()\n",
        "            token_count += 1\n",
        "    \n",
        "    # aggregate final scores\n",
        "    final_score = pos_score - neg_score\n",
        "    norm_final_score = round(float(final_score) / token_count, 2)\n",
        "    final_sentiment = 1 if norm_final_score >= 0 else 0\n",
        "    if verbose:\n",
        "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
        "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
        "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
        "        # to display results in a nice table\n",
        "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
        "                                         norm_neg_score, norm_final_score]],\n",
        "                                       columns = ['Predicted Sentiment', 'Objectivity',\n",
        "                                                     'Positive', 'Negative', 'Overall']\n",
        "                                       #columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
        "                                       #                      ['Predicted Sentiment', 'Objectivity',\n",
        "                                        #                      'Positive', 'Negative', 'Overall']], \n",
        "                                       #                      labels=[[0,0,0,0,0],[0,1,2,3,4]])\n",
        "                                       )\n",
        "        print(sentiment_frame)\n",
        "        \n",
        "    return final_sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ-hndov74hd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "a143c89c-a232-4ef4-ed2f-cf3ff568bc3b"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    pred = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)    \n",
        "    print('-'*60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: amazing compositions, performances and recording quality!: having purchased and enjoyed the other 0 star disc of this group i had to see what \"closer\" was like.this disc is even better in many respects.the compositions are so clever, the arrangements perfect and the recording/mixing are stunning.would love to see a live concert here in new zealand!\n",
            "Actual Sentiment: 1\n",
            "   Predicted Sentiment  Objectivity  Positive  Negative  Overall\n",
            "0                    1         0.81      0.15      0.04     0.11\n",
            "------------------------------------------------------------\n",
            "REVIEW: i liked it: great story, no violence, nudity, profanity, a movie everyone can watch and enjoy. i would recommend this movie to anyone\n",
            "Actual Sentiment: 1\n",
            "   Predicted Sentiment  Objectivity  Positive  Negative  Overall\n",
            "0                    1         0.88      0.07      0.06     0.01\n",
            "------------------------------------------------------------\n",
            "REVIEW: poor bob, victim of himself!: awful. i mean, really awful...and i liked \"self portrait\" because you knew dylan was just trying to have some fun with his image. this album is just a disaster. the lyrics are ok on most songs (i've seen worse by dylan), but the music is unexciting, not very creative, and downright embarrassing on some tracks. why, oh, why did you have to make an album like this, bob? such talented people at your disposal for these sessions, and you threw it away on garbage arrangements. shameful. really sad.\n",
            "Actual Sentiment: 0\n",
            "   Predicted Sentiment  Objectivity  Positive  Negative  Overall\n",
            "0                    0         0.77       0.1      0.13    -0.03\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aDN5YCL7hvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "3bd3c163-69a7-497d-8c49-2e90df8556ae"
      },
      "source": [
        "#norm_test_reviews = normalize_corpus(test_reviews)\n",
        "#predicted_sentiments = [analyze_sentiment_sentiwordnet_lexicon(review, verbose=False) for review in norm_test_reviews]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-17a9bd005996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnorm_test_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_sentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyze_sentiment_sentiwordnet_lexicon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnorm_test_reviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-17a9bd005996>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnorm_test_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_sentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyze_sentiment_sentiwordnet_lexicon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnorm_test_reviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-abc0c0544880>\u001b[0m in \u001b[0;36manalyze_sentiment_sentiwordnet_lexicon\u001b[0;34m(review, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# aggregate final scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mnorm_final_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtoken_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mfinal_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnorm_final_score\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4nnNfTV8CSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(test_sentiments,predicted_sentiments))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj-V4Ayk8Xi3",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis with VADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcAloXxG8WPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6b1d9b4e-3dba-4abd-d75f-acdfc816aad9"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1vUtH5h8ZN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_sentiment_vader_lexicon(review, \n",
        "                                    threshold=0.1,\n",
        "                                    verbose=False):\n",
        "    # pre-process text\n",
        "    review = strip_html_tags(review)\n",
        "    review = remove_accented_chars(review)\n",
        "    review = expand_contractions(review)\n",
        "    \n",
        "    # analyze the sentiment for review\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(review)\n",
        "    # get aggregate scores and final sentiment\n",
        "    agg_score = scores['compound']\n",
        "    final_sentiment = 1 if agg_score >= threshold else 0\n",
        "    #1: positive, o: negative\n",
        "    if verbose:\n",
        "        # display detailed sentiment statistics\n",
        "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
        "        final = round(agg_score, 2)\n",
        "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
        "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
        "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
        "                                        negative, neutral]],\n",
        "                                       columns = ['Predicted Sentiment', 'Polarity Score',\n",
        "                                                     'Positive', 'Negative', 'Overall']\n",
        "                                        #columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
        "                                        #                              ['Predicted Sentiment', 'Polarity Score',\n",
        "                                         #                              'Positive', 'Negative', 'Neutral']], \n",
        "                                          #                    labels=[[0,0,0,0,0],[0,1,2,3,4]])\n",
        "                                        )\n",
        "        print(sentiment_frame)\n",
        "    \n",
        "    return final_sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxUL2W0t8aNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "286631c7-8f24-417e-c4fd-eff280b85b08"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    pred = analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=True)    \n",
        "    print('-'*60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: amazing compositions, performances and recording quality!: having purchased and enjoyed the other 0 star disc of this group i had to see what \"closer\" was like.this disc is even better in many respects.the compositions are so clever, the arrangements perfect and the recording/mixing are stunning.would love to see a live concert here in new zealand!\n",
            "Actual Sentiment: 1\n",
            "   Predicted Sentiment  Polarity Score Positive Negative Overall\n",
            "0                    1            0.97    33.0%     0.0%   67.0%\n",
            "------------------------------------------------------------\n",
            "REVIEW: i liked it: great story, no violence, nudity, profanity, a movie everyone can watch and enjoy. i would recommend this movie to anyone\n",
            "Actual Sentiment: 1\n",
            "   Predicted Sentiment  Polarity Score Positive Negative Overall\n",
            "0                    1            0.74    38.0%    19.0%   43.0%\n",
            "------------------------------------------------------------\n",
            "REVIEW: poor bob, victim of himself!: awful. i mean, really awful...and i liked \"self portrait\" because you knew dylan was just trying to have some fun with his image. this album is just a disaster. the lyrics are ok on most songs (i've seen worse by dylan), but the music is unexciting, not very creative, and downright embarrassing on some tracks. why, oh, why did you have to make an album like this, bob? such talented people at your disposal for these sessions, and you threw it away on garbage arrangements. shameful. really sad.\n",
            "Actual Sentiment: 0\n",
            "   Predicted Sentiment  Polarity Score Positive Negative Overall\n",
            "0                    0           -0.91    12.0%    23.0%   66.0%\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6E40Pso8epc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "391c4451-fd4d-4d16-e15e-367015ff1716"
      },
      "source": [
        "predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=False) for review in test_reviews]\n",
        "print(classification_report(test_sentiments,predicted_sentiments))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.63      0.72     60301\n",
            "           1       0.70      0.88      0.78     59699\n",
            "\n",
            "    accuracy                           0.76    120000\n",
            "   macro avg       0.77      0.76      0.75    120000\n",
            "weighted avg       0.77      0.76      0.75    120000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJd2_hz7slBm",
        "colab_type": "text"
      },
      "source": [
        "# Ch09b - Sentiment Analysis - Supervised.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjGfdzWl8ij7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import text_normalizer as tn\n",
        "#import model_evaluation_utils as meu\n",
        "import nltk\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkwil7HHsqFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1714ef0c-cb28-4cf8-f9c6-e2de4dfd3a13"
      },
      "source": [
        "train_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv')\n",
        "test_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test_set.csv')\n",
        "print(train_set.shape)\n",
        "print(test_set.shape)\n",
        "test_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3600000, 3)\n",
            "(400000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>great cd: my lovely pat has one of the great v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>one of the best game music soundtracks - for a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>batteries died within a year ...: i bought thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>works fine, but maha energy is better: check o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>great for the non-audiophile: reviewed quite a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             review  label\n",
              "0           0  great cd: my lovely pat has one of the great v...      1\n",
              "1           1  one of the best game music soundtracks - for a...      1\n",
              "2           2  batteries died within a year ...: i bought thi...      0\n",
              "3           3  works fine, but maha energy is better: check o...      1\n",
              "4           4  great for the non-audiophile: reviewed quite a...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgKr8Pn4tY-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = np.array(train_set['review'])\n",
        "sentiments = np.array(train_set['label'])\n",
        "# build train and test datasets\n",
        "train_reviews = reviews[:35000]\n",
        "train_sentiments = sentiments[:35000]\n",
        "test_reviews = reviews[35000:50000]\n",
        "test_sentiments = sentiments[35000:50000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjUuDbHF96cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize datasets\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "stop_words.remove('no')\n",
        "stop_words.remove('but')\n",
        "stop_words.remove('not')\n",
        "\n",
        "norm_train_reviews = normalize_corpus(train_reviews, stopwords=stop_words)\n",
        "norm_test_reviews = normalize_corpus(test_reviews, stopwords=stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI-KE3JmC_RV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(norm_train_reviews).to_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/norm_train_reviews.csv')\n",
        "pd.DataFrame(norm_test_reviews).to_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/norm_test_reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J6mNwaY-Dtp",
        "colab_type": "text"
      },
      "source": [
        "## Traditional Supervised Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4QpRLxS-JS0",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering (LOAD FILE AFTER PRE PROCESS BENGIN HERE)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bBG4tHIDSTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_train_reviews=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/norm_train_reviews.csv')\n",
        "norm_test_reviews=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/norm_test_reviews.csv')\n",
        "norm_train_reviews=norm_train_reviews['0']\n",
        "norm_test_reviews=norm_test_reviews['0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSIo_cDv9_Ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# build BOW features on train reviews\n",
        "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
        "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
        "# build TFIDF features on train reviews\n",
        "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
        "                     sublinear_tf=True)\n",
        "tv_train_features = tv.fit_transform(norm_train_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHmiDfU8-Tdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform test reviews into features\n",
        "cv_test_features = cv.transform(norm_test_reviews)\n",
        "tv_test_features = tv.transform(norm_test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBPaGSEm-WC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb932536-4de2-4ad4-af38-68a9938659e6"
      },
      "source": [
        "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
        "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW model:> Train features shape: (35000, 816540)  Test features shape: (15000, 816540)\n",
            "TFIDF model:> Train features shape: (35000, 816540)  Test features shape: (15000, 816540)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HcRkTV2-0Bc",
        "colab_type": "text"
      },
      "source": [
        "### Model Training, Prediction and Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90q4bJOj-WM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
        "svm = SGDClassifier(loss='hinge', max_iter=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MODny1dGBuIG",
        "colab_type": "text"
      },
      "source": [
        "model on BOW features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LgkCzZ8-WKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "a2a29169-8903-49bd-b08b-1d06f8f9f6fc"
      },
      "source": [
        "lr.fit(cv_train_features, train_sentiments)\n",
        "y_pred = lr.predict(cv_test_features)\n",
        "print(classification_report(test_sentiments,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89      7143\n",
            "           1       0.89      0.90      0.90      7857\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJujB9PH-WGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "29e3650b-96ff-4baf-b31b-f34a78e93edf"
      },
      "source": [
        "svm.fit(cv_train_features, train_sentiments)\n",
        "y_pred = svm.predict(cv_test_features)\n",
        "print(classification_report(test_sentiments,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89      7143\n",
            "           1       0.90      0.89      0.90      7857\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kup-NVJxBq8Q",
        "colab_type": "text"
      },
      "source": [
        "model on TF-IDF features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJO_QN_S-WIB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5fa53617-6088-470d-8522-99e451934ace"
      },
      "source": [
        "lr.fit(tv_train_features, train_sentiments)\n",
        "y_pred = lr.predict(tv_test_features)\n",
        "print(classification_report(test_sentiments,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88      7143\n",
            "           1       0.89      0.89      0.89      7857\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZDszGWmANjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "fe0d41ee-1bc3-4d62-ab2d-146c19caebae"
      },
      "source": [
        "svm.fit(tv_train_features, train_sentiments)\n",
        "y_pred = svm.predict(tv_test_features)\n",
        "print(classification_report(test_sentiments,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89      7143\n",
            "           1       0.90      0.89      0.89      7857\n",
            "\n",
            "    accuracy                           0.89     15000\n",
            "   macro avg       0.89      0.89      0.89     15000\n",
            "weighted avg       0.89      0.89      0.89     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v_AsiblD4UX",
        "colab_type": "text"
      },
      "source": [
        "## Newer Supervised Deep Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YcOsejtD0Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Activation, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pRv_SDLEDV8",
        "colab_type": "text"
      },
      "source": [
        "### Prediction class label encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Cy3gvyNNm5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#norm_train_reviews\n",
        "#norm_test_reviews\n",
        "#train_sentiments\n",
        "#test_sentiments"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4NJ53SNN6Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize train reviews & encode train labels\n",
        "tokenized_train = [tokenizer.tokenize(text)\n",
        "                   for text in norm_train_reviews]\n",
        "# tokenize test reviews & encode test labels\n",
        "tokenized_test = [tokenizer.tokenize(text)\n",
        "                   for text in norm_test_reviews]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjzlrtAAOlWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "70d726a0-d899-4184-b794-719f991f2542"
      },
      "source": [
        "print(tokenized_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['stun', 'even', 'non', 'gamer', 'sound', 'track', 'beautiful', 'paint', 'senery', 'mind', 'well', 'would', 'recomend', 'even', 'people', 'hate', 'vid', 'game', 'music', 'play', 'game', 'chrono', 'cross', 'but', 'game', 'ever', 'play', 'good', 'music', 'back', 'away', 'crude', 'keyboarding', 'take', 'fresher', 'step', 'grate', 'guitar', 'soulful', 'orchestra', 'would', 'impress', 'anyone', 'care', 'listen']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "591GZgYeOgBQ",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering with word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vul4U2uS26C",
        "colab_type": "text"
      },
      "source": [
        "feature engineering with word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyXyC5pQN9z3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8318fabc-5033-46da-aaff-5e5f3a48dbfe"
      },
      "source": [
        "%%time\n",
        "# build word2vec model\n",
        "w2v_num_features = 512\n",
        "w2v_model = gensim.models.Word2Vec(tokenized_train, size=w2v_num_features, window=150,\n",
        "                                   min_count=10, sample=1e-3, workers=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 27s, sys: 231 ms, total: 1min 27s\n",
            "Wall time: 45.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25RJBmk2N95A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    \n",
        "    def average_word_vectors(words, model, vocabulary, num_features):\n",
        "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "        nwords = 0.\n",
        "        \n",
        "        for word in words:\n",
        "            if word in vocabulary: \n",
        "                nwords = nwords + 1.\n",
        "                feature_vector = np.add(feature_vector, model.wv[word])\n",
        "        if nwords:\n",
        "            feature_vector = np.divide(feature_vector, nwords)\n",
        "\n",
        "        return feature_vector\n",
        "\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCuaNorBN92j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate averaged word vector features from word2vec model\n",
        "avg_wv_train_features = averaged_word2vec_vectorizer(corpus=tokenized_train, model=w2v_model,\n",
        "                                                     num_features=w2v_num_features)\n",
        "avg_wv_test_features = averaged_word2vec_vectorizer(corpus=tokenized_test, model=w2v_model,\n",
        "                                                    num_features=w2v_num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggYUvI68PVIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74adcea3-cc52-4c58-89cc-ae3ab07a8bd5"
      },
      "source": [
        "print(avg_wv_train_features.shape)\n",
        "print(avg_wv_test_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 512)\n",
            "(15000, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLZQgsnvPeYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1b3cffae-9c4c-4936-c4fb-5f41515c62a6"
      },
      "source": [
        "avg_wv_test_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.09,  0.1 , -0.25, ..., -0.28,  0.37, -0.39],\n",
              "       [-0.16,  0.02, -0.11, ..., -0.39,  0.35, -0.46],\n",
              "       [-0.06, -0.05,  0.22, ...,  0.06,  0.08,  0.16],\n",
              "       ...,\n",
              "       [ 0.41,  0.37, -0.44, ..., -0.  ,  0.16, -0.19],\n",
              "       [ 0.46,  0.69, -0.52, ..., -0.03,  0.08, -0.22],\n",
              "       [-0.04,  0.05,  0.2 , ...,  0.02,  0.03, -0.12]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mPER2Y8QQNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python -m spacy download en_vectors_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF8AzqwEV7Ul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f746c912-4dfc-4272-f144-972e168cfc94"
      },
      "source": [
        "!python -m spacy link en_vectors_web_lg en_vectors_web_lg_link"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_vectors_web_lg -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en_vectors_web_lg_link\n",
            "You can now load the model via spacy.load('en_vectors_web_lg_link')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfJrizt4P7OD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_vec = spacy.load('en_vectors_web_lg_link', parse=True, tag=True, entity=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE-sRzCNS0Up",
        "colab_type": "text"
      },
      "source": [
        "feature engineering with GloVe model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ud4iK0SjEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature engineering with GloVe model\n",
        "train_nlp = [nlp_vec(item) for item in norm_train_reviews]\n",
        "train_glove_features = np.array([item.vector for item in train_nlp])\n",
        "\n",
        "test_nlp = [nlp_vec(item) for item in norm_test_reviews]\n",
        "test_glove_features = np.array([item.vector for item in test_nlp])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7AosxYeN6Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature engineering with GloVe model\n",
        "#Replace nlp_vec = nlp (space.load('en') instead of 'en_vectors_web_lg')\n",
        "#train_nlp = [nlp(item) for item in norm_train_reviews]\n",
        "#train_glove_features = np.array([item.vector for item in train_nlp])\n",
        "\n",
        "#test_nlp = [nlp(item) for item in norm_test_reviews]\n",
        "#test_glove_features = np.array([item.vector for item in test_nlp])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS1vq5LccMPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "738601cb-d857-4b5c-bdb3-9c04d6cdec17"
      },
      "source": [
        "train_glove_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02,  0.16, -0.15, ..., -0.02,  0.01,  0.18],\n",
              "       [-0.16,  0.2 , -0.08, ..., -0.11,  0.12,  0.05],\n",
              "       [-0.04,  0.2 , -0.11, ..., -0.07,  0.04,  0.13],\n",
              "       ...,\n",
              "       [-0.07,  0.02, -0.12, ..., -0.15,  0.1 ,  0.03],\n",
              "       [-0.17,  0.06, -0.15, ..., -0.12,  0.07, -0.03],\n",
              "       [-0.21,  0.05, -0.16, ..., -0.2 ,  0.17,  0.03]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOaN1jBCN6U-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65af5244-f062-4308-dabc-88c619b466e4"
      },
      "source": [
        "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape, ' Test features shape:', avg_wv_test_features.shape)\n",
        "print('GloVe model:> Train features shape:', train_glove_features.shape, ' Test features shape:', test_glove_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec model:> Train features shape: (35000, 512)  Test features shape: (15000, 512)\n",
            "GloVe model:> Train features shape: (35000, 300)  Test features shape: (15000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmGOXqRjWXiE",
        "colab_type": "text"
      },
      "source": [
        "### Modeling with deep neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZSCCO4AN6YJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def construct_deepnn_architecture(num_input_features):\n",
        "    dnn_model = Sequential()\n",
        "    dnn_model.add(Dense(512, input_shape=(num_input_features,), kernel_initializer='glorot_uniform'))\n",
        "    dnn_model.add(BatchNormalization())\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(512, kernel_initializer='glorot_uniform'))\n",
        "    dnn_model.add(BatchNormalization())\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(512, kernel_initializer='glorot_uniform'))\n",
        "    dnn_model.add(BatchNormalization())\n",
        "    dnn_model.add(Activation('relu'))\n",
        "    dnn_model.add(Dropout(0.2))\n",
        "    \n",
        "    dnn_model.add(Dense(1))\n",
        "    dnn_model.add(Activation('softmax'))\n",
        "\n",
        "    dnn_model.compile(loss='binary_crossentropy', optimizer='adam',                 \n",
        "                      metrics=['accuracy'])\n",
        "    return dnn_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5QhjVG-c8Ud",
        "colab_type": "text"
      },
      "source": [
        "Deep learning for w2v"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8epgZTYbn_N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c7d74ad-22fa-474f-a0f6-88138be549bd"
      },
      "source": [
        "w2v_num_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4iYlQaIN6b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2v_dnn = construct_deepnn_architecture(num_input_features=w2v_num_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vs8jkIFbq1z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "29f04347-66b5-4729-b327-aff4222f0b16"
      },
      "source": [
        "batch_size = 100\n",
        "w2v_dnn.fit(avg_wv_train_features, train_sentiments, epochs=10, batch_size=batch_size, \n",
        "            shuffle=True, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "315/315 [==============================] - 7s 23ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 2/10\n",
            "315/315 [==============================] - 7s 22ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 3/10\n",
            "315/315 [==============================] - 7s 22ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 4/10\n",
            "315/315 [==============================] - 7s 21ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 5/10\n",
            "315/315 [==============================] - 7s 22ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 6/10\n",
            "315/315 [==============================] - 7s 22ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 7/10\n",
            "315/315 [==============================] - 7s 22ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 8/10\n",
            "315/315 [==============================] - 7s 22ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 9/10\n",
            "315/315 [==============================] - 7s 21ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 10/10\n",
            "315/315 [==============================] - 7s 21ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff108239fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "howB_KDWcNaz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "4ce6cd73-46c7-4322-bea2-d6167e60c2bc"
      },
      "source": [
        "y_pred = w2v_dnn.predict_classes(avg_wv_test_features)\n",
        "print(classification_report(test_sentiments,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-89-0f4c1c2b0e5c>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      7143\n",
            "           1       0.52      1.00      0.69      7857\n",
            "\n",
            "    accuracy                           0.52     15000\n",
            "   macro avg       0.26      0.50      0.34     15000\n",
            "weighted avg       0.27      0.52      0.36     15000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doOWwRduc3o7",
        "colab_type": "text"
      },
      "source": [
        "Deep learning for glove_features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRviJToMcjW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "dd229c3b-c61d-4fbe-c888-87d3181106b4"
      },
      "source": [
        "glove_dnn = construct_deepnn_architecture(num_input_features=300)\n",
        "batch_size = 100\n",
        "glove_dnn.fit(train_glove_features, train_sentiments, epochs=10, batch_size=batch_size, \n",
        "              shuffle=True, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "315/315 [==============================] - 7s 21ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 2/10\n",
            "315/315 [==============================] - 6s 21ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 3/10\n",
            "315/315 [==============================] - 6s 20ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 4/10\n",
            "315/315 [==============================] - 6s 20ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 5/10\n",
            "315/315 [==============================] - 6s 20ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 6/10\n",
            "315/315 [==============================] - 6s 20ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 7/10\n",
            "315/315 [==============================] - 6s 20ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 8/10\n",
            "315/315 [==============================] - 6s 20ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 9/10\n",
            "315/315 [==============================] - 6s 20ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n",
            "Epoch 10/10\n",
            "315/315 [==============================] - 6s 20ms/step - loss: 7.4610 - accuracy: 0.5107 - val_loss: 8.4481 - val_accuracy: 0.4460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1037ab710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG9N_vkkcq6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "e2123c47-732c-4a20-8b9b-75089677407f"
      },
      "source": [
        "y_pred = glove_dnn.predict_classes(test_glove_features)\n",
        "print(classification_report(test_sentiments,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      7143\n",
            "           1       0.52      1.00      0.69      7857\n",
            "\n",
            "    accuracy                           0.52     15000\n",
            "   macro avg       0.26      0.50      0.34     15000\n",
            "weighted avg       0.27      0.52      0.36     15000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv5asQkQdV37",
        "colab_type": "text"
      },
      "source": [
        "# Ch09c - Sentiment Analysis - Advanced Deep Learning.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKCLYSmjTjXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm_train_reviews=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/norm_train_reviews.csv')\n",
        "norm_test_reviews=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/norm_test_reviews.csv')\n",
        "norm_train_reviews=norm_train_reviews['0']\n",
        "norm_test_reviews=norm_test_reviews['0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfzWRMX0Ts7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "408e25b0-ad53-40fd-f1db-eafaea95d9a4"
      },
      "source": [
        "print(len(norm_train_reviews))\n",
        "print(len(norm_test_reviews))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35000\n",
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1CmhIePbBE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4af63a1f-44d6-4de3-f524-8ef82dea5da3"
      },
      "source": [
        "train_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv')\n",
        "print(train_set.shape)\n",
        "reviews = np.array(train_set['review'])\n",
        "sentiments = np.array(train_set['label'])\n",
        "train_sentiments = sentiments[:35000]\n",
        "test_sentiments = sentiments[35000:50000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3600000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28lrW9a7dwoh",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize train & test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5KLqyILduUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from text_normalizer.py\n",
        "tokenized_train = [tokenizer.tokenize(text) for text in norm_train_reviews]\n",
        "tokenized_test = [tokenizer.tokenize(text) for text in norm_test_reviews]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjNnUTUBT0pV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "29f67503-6259-46df-eaa4-9c8aff478c4a"
      },
      "source": [
        "print(len(tokenized_train))\n",
        "print(tokenized_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35000\n",
            "['stun', 'even', 'non', 'gamer', 'sound', 'track', 'beautiful', 'paint', 'senery', 'mind', 'well', 'would', 'recomend', 'even', 'people', 'hate', 'vid', 'game', 'music', 'play', 'game', 'chrono', 'cross', 'but', 'game', 'ever', 'play', 'good', 'music', 'back', 'away', 'crude', 'keyboarding', 'take', 'fresher', 'step', 'grate', 'guitar', 'soulful', 'orchestra', 'would', 'impress', 'anyone', 'care', 'listen']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PfMIOtkSLxE",
        "colab_type": "text"
      },
      "source": [
        "## Build Vocabulary Mapping (word to index)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZbEZPrKU3nG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2856ddf3-2c11-4489-839f-5958932f7645"
      },
      "source": [
        "from collections import Counter\n",
        "from itertools import islice\n",
        "\n",
        "# build word to index vocabulary\n",
        "token_counter = Counter([token for review in tokenized_train for token in review])\n",
        "print(len(token_counter))\n",
        "# see inside token_counter\n",
        "lengths = Counter()\n",
        "lengths.update(dict(islice(token_counter.items(), 5)))\n",
        "print(lengths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53312\n",
            "Counter({'even': 5123, 'sound': 2542, 'non': 527, 'gamer': 12, 'stun': 7})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaRx7iyRWgQc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "db336c30-7874-4501-e57e-223715e24a4c"
      },
      "source": [
        "vocab_map = {item[0]: index+1 for index, item in enumerate(dict(token_counter).items())}\n",
        "print(len(vocab_map))\n",
        "# see inside token_counter\n",
        "lengths = Counter()\n",
        "lengths.update(dict(islice(vocab_map.items(), 5)))\n",
        "print(lengths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53312\n",
            "Counter({'sound': 5, 'gamer': 4, 'non': 3, 'even': 2, 'stun': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YLnEHdxXOa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77110304-ec39-4f2b-b557-da79036b710f"
      },
      "source": [
        "max_index = np.max(list(vocab_map.values()))\n",
        "max_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_vXDNz0XcvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a389723e-b6ce-4c0a-b309-112acb4cc794"
      },
      "source": [
        "vocab_map['PAD_INDEX'] = 0\n",
        "vocab_map['NOT_FOUND_INDEX'] = max_index+1\n",
        "vocab_size = len(vocab_map)\n",
        "# view vocabulary size and part of the vocabulary map\n",
        "print('Vocabulary Size:', vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 53314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK1RreFNSQ2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42f3134b-57c0-4257-98a2-d01252c7f169"
      },
      "source": [
        "# see inside token_counter\n",
        "lengths = Counter()\n",
        "lengths.update(dict(islice(vocab_map.items(), 5)))\n",
        "print(lengths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'sound': 5, 'gamer': 4, 'non': 3, 'even': 2, 'stun': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zXHZ6d3Zggy",
        "colab_type": "text"
      },
      "source": [
        "## Encode and Pad datasets & Encode prediction class labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2lUv4GWbgN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "223beff1-e0d2-47f5-c675-7633ae46f0b4"
      },
      "source": [
        "from keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# get max length of train corpus and initialize label encoder\n",
        "le = LabelEncoder()\n",
        "num_classes=2 # positive -> 1, negative -> 0\n",
        "max_len = np.max([len(review) for review in tokenized_train])\n",
        "print(max_len) # So tu nhieu nhat trong 1 cau"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxF_oZXEUKei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e1139c29-2715-4643-a47a-b055d47a0ffa"
      },
      "source": [
        "## Train reviews data corpus\n",
        "# Convert tokenized text reviews to numeric vectors\n",
        "train_X = [[vocab_map[token] for token in tokenized_review] for tokenized_review in tokenized_train]\n",
        "train_X = sequence.pad_sequences(train_X, maxlen=max_len) # pad \n",
        "## Train prediction class labels\n",
        "# Convert text sentiment labels (negative\\positive) to binary encodings (0/1)\n",
        "train_y = le.fit_transform(train_sentiments)\n",
        "\n",
        "## Test reviews data corpus\n",
        "# Convert tokenized text reviews to numeric vectors\n",
        "test_X = [[vocab_map[token] if vocab_map.get(token) else vocab_map['NOT_FOUND_INDEX'] \n",
        "           for token in tokenized_review] \n",
        "              for tokenized_review in tokenized_test]\n",
        "test_X = sequence.pad_sequences(test_X, maxlen=max_len)\n",
        "## Test prediction class labels\n",
        "# Convert text sentiment labels (negative\\positive) to binary encodings (0/1)\n",
        "test_y = le.transform(test_sentiments)\n",
        "\n",
        "# view vector shapes\n",
        "print('Max length of train review vectors:', max_len)\n",
        "print('Train review vectors shape:', train_X.shape, ' Test review vectors shape:', test_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of train review vectors: 146\n",
            "Train review vectors shape: (35000, 146)  Test review vectors shape: (15000, 146)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VVwPGu6bQqv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "43e139c1-5fd9-4d01-b335-ded9c3d18613"
      },
      "source": [
        "train_X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,    37,    38,    39],\n",
              "       [    0,     0,     0, ...,    73,    74,    75],\n",
              "       [    0,     0,     0, ...,   117,   118,    90],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,   248,   110,  1883],\n",
              "       [    0,     0,     0, ..., 30344,  3014,   418],\n",
              "       [    0,     0,     0, ...,   110,   985,    42]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18O2kqM1c_MP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5780b74d-c715-4b40-b541-d237febce6b4"
      },
      "source": [
        "train_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZJ9WfGTdLkh",
        "colab_type": "text"
      },
      "source": [
        "## Build the LSTM Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vrk4KacdBUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "38807f63-2772-4f37-c247-b9a119d21413"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Dropout, SpatialDropout1D\n",
        "from keras.layers import LSTM\n",
        "\n",
        "EMBEDDING_DIM = 128 # dimension for dense embeddings for each token\n",
        "LSTM_DIM = 64 # total LSTM units\n",
        "vocab_size # max vocal in transet 53314\n",
        "max_len # max sequence length 146\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_len))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(LSTM_DIM, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 146, 128)          6824192   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 146, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 6,873,665\n",
            "Trainable params: 6,873,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UJ2WWNIdhhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "10ec0afa-f1aa-48b3-eaf7-c81f093409ca"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAIECAYAAACXCW0bAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzde1zUVf4/8Ncgl2EQBlBAhEABRREVTX8JocaarpcU1AzUtrX9Vl4XSDMVNMWCtHaVhxdqK5bdNhVQekCm1D7SWKXykooYtQaYVxJUFJAZZIDz+8PHzDYODNdhBng9H4/5g/M5n/N5fz7DMG/O53zOkQghBIiIiIgat9/M2BEQERGRaWOyQERERHoxWSAiIiK9mCwQERGRXubGDqC95s2bZ+wQiIiImhQYGIiVK1caO4x26fI9CwcOHMD169eNHQYRdZITJ07gxIkTxg6jS7l+/ToOHDhg7DB6pBMnTuC7774zdhjt1uV7FgDg1VdfxXPPPWfsMIioE6h7E/fv32/kSLqO9PR0hIeH85oZQXfp/e7yPQtERERkWEwWiIiISC8mC0RERKQXkwUiIiLSi8kCERER6cVkgYh6pMOHD0Mul+PgwYPGDsUkLVmyBBKJRPN6/vnndep89dVXWLduHRoaGjB79mx4eHhAKpXCzc0NoaGhyM/Pb/PxGxoasH37dgQFBbWofk1NDYYMGYL169frbFOpVEhISICPjw8sLS1hb28Pf39/XL58GQDw2WefYevWraivr9faLzMzU+sa9O3bt83n09UxWSCiHokL7jbP0dER2dnZuHjxIpKTk7W2bdy4ETt27EBMTAwaGhpw/Phx7N27F+Xl5cjNzYVSqcSECRNQUlLS6uMWFhZiwoQJWLlyJRQKRYv2iY2NxcWLFxvdFh4ejo8//hh79uyBQqHATz/9BG9vb9y/fx8AMGvWLEilUkyaNAn37t3T7BcaGorr16/j2LFjmD59eqvPozthskBEPdKMGTNQUVGBmTNnGjsUKJXKFv8H3Zmsra0xdepUDB48GFZWVpryLVu2IDU1Fenp6bC1tQXwcJbC4OBgyGQyDBw4EPHx8aioqMA//vGPVh3z/PnzWLt2LZYuXYqAgIAW7fPtt9/ihx9+aHRbamoqMjMzsX//fjzxxBMwNzeHq6srsrKy4O/vr6kXFRWFkSNHYvr06airqwMASCQSuLm5Yfz48Rg0aFCrzqO7YbJARGRkycnJKCsrM3YYLVJUVIQNGzYgLi4OUqkUAGBubq5zO8fLywsAUFxc3Kr2R44ciYyMDCxcuFArQWmKUqnE6tWrkZiY2Oj29957D6NHj8bw4cObbWvTpk3Iy8trsq2ejMkCEfU4ubm58PDwgEQiwa5duwAASUlJsLGxgUwmQ1ZWFqZNmwY7Ozu4u7tj3759mn137NgBqVQKZ2dnLFmyBK6urpBKpQgKCsLJkyc19SIjI2FpaYl+/fppypYvXw4bGxtIJBLcvn0bABAdHY1Vq1ahuLgYEokEPj4+AIAvvvgCdnZ2iI+P74xL0mI7duyAEAKzZs3SW0+pVAIA7OzsDBpPbGwsli9fDicnJ51ttbW1OHHiRIt7KBwcHDBx4kQkJibyNtUjmCwQUY8THByMb7/9Vqts2bJlePXVV6FUKmFra4u0tDQUFxfDy8sLL7/8MlQqFYCHScCiRYugUCgQFRWFy5cv4+zZs6irq8PkyZNx7do1AA+/VB+dhn737t2Ii4vTKktMTMTMmTPh7e0NIQSKiooAQDPYrqGhwSDXoK0OHToEX19fyGQyvfVOnToF4OG1NpRvvvkGxcXFWLBgQaPbS0pKUFtbizNnziAkJEST2A0dOhS7d+9uNCEYNWoUbty4gfPnzxss7q6IyQIR0SOCgoJgZ2cHJycnREREoLq6GlevXtWqY25ujqFDh8LKygp+fn5ISkpCVVUVUlJSOiSGGTNmoLKyEhs2bOiQ9jpCdXU1fvnlF3h7ezdZp7S0FKmpqYiKikJgYGCzPRBtpVQqER0djaSkpCbrqAcwOjk5IT4+HgUFBSgtLUVYWBhWrFiBvXv36uyjHptw4cIFg8TdVTFZICLSw9LSEgA0PQtNGTNmDGQyGf773/92RlhGUVZWBiGE3l6FwMBAREVFISwsDNnZ2bCwsDBILDExMXjllVfg5ubWZB31mIdhw4YhKCgIjo6OkMvliIuLg1wuxwcffKCzj/rcSktLDRJ3V9UtVp0kIjIFVlZWuHXrlrHDMJiamhoA0Dvw0NnZGcnJyRg2bJjB4sjNzcWFCxewbds2vfVcXV0BQDM+RM3S0hKenp6NDr60trYG8L9zpYfYs0BE1AFUKhXu3bsHd3d3Y4diMOov0kcnL/otJycn2NvbGzSO5ORkHDlyBGZmZpoJk9QDHOPj4yGRSPD999+jd+/eGDRoEH788UedNurq6iCXy3XKa2trAfzvXOkhJgtERB0gJycHQgiMGzdOU2Zubt7s7YuuxNnZGRKJBBUVFU3WOXjwoN5bAx0hJSUFQgitl7pHJzY2FkIIjBkzBsDDCZnOnTuHS5cuafZXKBS4cuVKo49Tqs/NxcXFoOfQ1TBZICJqg4aGBty9exd1dXXIz89HdHQ0PDw8sGjRIk0dHx8flJeXIzMzEyqVCrdu3cKVK1d02nJ0dERJSQkuX76MqqoqqFQqZGdnm9yjkzKZDF5eXrh+/Xqj24uKiuDi4oLw8HCdbREREXBxccHZs2cNHaaWlStXwtPTE4sWLcLVq1dx584drFmzBkqlEmvXrtWprz63lszL0JMwWSCiHmfXrl0YO3YsAGDNmjUIDQ1FUlIStm/fDgAYMWIELl26hA8//BCrVq0CAEydOhWFhYWaNmpqajB8+HBYW1tj/PjxGDx4ML7++mut+/nLli1DSEgI5s+fD19fX7z55pua7u3AwEDNY5ZLly6Fs7Mz/Pz8MH36dJSXl3fKdWiLGTNmoKCgQDOPwm/pm5ugtrYWZWVlyMrK0tv+iRMnEBwcjP79++PkyZM4f/48XF1d8eSTT+LYsWOtjtfBwQHHjx+Hu7s7AgIC4ObmhlOnTuHQoUONzr9w+vRpuLm5YcSIEa0+VnfGAY5E1OOsWLECK1as0ClftmyZ1s/qORYaY2tr2+R/2GqOjo44evSoTvk777yj9fOoUaM0ixqpTZs2DZWVlXrbN4Y///nPSEpKQkZGhs7iUoMGDWryKYIDBw7gqaeegqenp972x40bh9zc3FbH1bdv3yaTFXd390Yfk3zUnTt3cOTIEbz11luQSCStjqE7Y88CEVEb6Bvk110olUp8+eWXKCws1Az88/HxwebNm7F582bNPAbNqa+vR2ZmJqqqqhAREWHIkNtl06ZNCAgIQGRkJICHPSUlJSXIzc3VTJbVUzFZICKiRpWXl2sWkvrTn/6kKV+3bh3mzZuHiIgIvYMd1XJycpCRkYHs7OxmZ340lm3btiEvLw+HDx/WzA2RlZWlWUjq0KFDRo7QuJgsdJCxY8eiV69eLZ6DvDVeeukl2NraQiKRIC8vr9X1Dh8+DLlcrrPQizGYUixtdeLECQwdOlTz2JaLiwveeustY4elJSMjA15eXprHyvr166fTZUxtExMTg5SUFFRUVGDgwIE4cOCAsUMyiPfff1/raYNPPvlEa3t8fDwiIyPx9ttvN9vWpEmTsGfPHq11MkxJVlYWHjx4gJycHDg4OGjKw8LCtK7Bo/M19CQcs9BBTp8+jaefftogv0wfffQRnn76acyfP79N9UxpQRRTiqWtxo0bh59++glTp07Fl19+iYsXLxr8ufLWmjt3LubOnQsfHx/cvn0bN2/eNHZI3UZCQgISEhKMHYZJmDJlCqZMmWLsMNotNDQUoaGhxg7DpDFZ6GCmOChmxowZLeoq7AymFItSqcSkSZN0FhTqirrTuRCR6eFtiA5mqHnQW5qEdEayIoTA/v37G51XvStJTk5GWVmZscPoEN3pXIjI9PS4ZKG+vh5vvPEGPDw8YG1tjREjRiAtLQ3Aw6VibWxsYGZmhscffxwuLi6wsLCAjY0NRo8ejfHjx+Oxxx6DVCqFvb09Xn/9dZ32i4qKMGTIENjY2Giev370MSB9MQAPv4zfffdd+Pr6wsrKCnK5HKtXr9Y5Vkvq5ebmwsPDAxKJBLt27QIAJCUlwcbGBjKZDFlZWZg2bRrs7Ozg7u6Offv26cSakJAAX19fWFtbo2/fvhg4cCASEhJ0lt9tTnti2bFjB6RSKZydnbFkyRLNUrNBQUE4efKkpl5kZCQsLS217o0uX74cNjY2kEgkmttE0dHRWLVqFYqLiyGRSODj4wMA+OKLL9o8EY6pnUtrHT9+HH5+fpDL5ZBKpRg+fDi+/PJLAA/Hw6jHP3h7e+PcuXMAgBdffBEymQxyuRyfffYZAP2/3++88w5kMhlsbW1RVlaGVatWwc3NDRcvXmxTzETUSUQXB0CkpaW1uP5rr70mrKysxIEDB8Tdu3dFTEyMMDMzE6dPnxZCCLFx40YBQJw8eVJUV1eL27dvi6lTpwoA4tChQ+LWrVuiurpaREZGCgAiLy9P0/akSZOEl5eX+OWXX4RKpRI//PCDeOKJJ4RUKhU///xzi2OIjY0VEolE/PWvfxV3794VCoVC7N69WwAQ586d07TT0nrXrl0TAMTOnTu19gUgjhw5IioqKkRZWZkYP368sLGxEbW1tZp68fHxolevXiIrK0soFApx5swZ4eLiIp566qlWvEv/055YFi9eLGxsbMSPP/4oampqREFBgRg7dqywtbUVV69e1dRbuHChcHFx0Truu+++KwCIW7duacrmzp0rvL29tep9/vnnwtbWVmzevLnZc/n9738vAIi7d++a5LkIIYS3t7eQy+XNnosQQuzfv19s2rRJlJeXizt37ohx48aJPn36aB2jV69e4saNG1r7LViwQHz22Wean1vy+w1AREVFiZ07d4o5c+aIn376qUUxCiHEs88+K5599tkW1ych0tLSRDf4c98ldZPf1/Qe1bNQU1ODpKQkzJ49G3PnzoW9vT3Wr18PCwsLnTXo/fz8IJPJ0KdPH82AQQ8PD/Tt2xcymUwzsvzR5WhtbW0xYMAAmJubY9iwYfjwww9RU1Oj6bJvLgalUont27fj6aefxsqVK2Fvbw9ra2s4OjpqHael9ZoTFBQEOzs7ODk5ISIiAtXV1bh69apme2ZmJh5//HHMmjUL1tbWGD16NEJDQ3Hs2DHNc9cdpblYgIdz7Q8dOhRWVlbw8/NDUlISqqqqdN6/tpoxYwYqKyuxYcOGdrVjCufSWs8++yw2btwIBwcHODo6YtasWbhz545mzv2lS5eivr5eK77KykqcPn0a06dPB9C6z9iWLVuwYsUKZGRkYMiQIZ13okTUaj1qgOPFixehUCjg7++vKbO2tka/fv30rkGvXs++rq5OU6Yem9DcIjHDhw+HXC5Hfn5+i2IoKiqCQqHApEmT9Lbb0nqtoT7P355TTU0NpFKpVr36+npYWFigV69eHXbslsTSmDFjxkAmk+l9/4ytq56L+ndcPfnQ7373OwwePBh///vfERMTA4lEgtTUVERERGh+F9r6GWutAwcOmORgYlPHa2Yczz77rLFDaLcelSxUV1cDANavX4/169drbVOve24IFhYWmi+K5mJQTx+rXm61KS2t117Tp0/Hu+++i6ysLEyZMgUFBQXIzMzEM888Y9BkoTWsrKw0//12dcY8l0OHDuHdd99FQUEBKisrdZIbiUSCJUuWYOXKlThy5AiefvppfPzxx9izZ4+mTmd9xsaNG4dXX321w9rr7r777jskJiZqjY2izqFeb6Sr61HJgvqLdfv27YiOju6UY9bV1aG8vBweHh4tiuHrr78GADx48EBvu+r/9pur116bNm3CmTNnsGjRIty/fx+urq547rnnTGYlPJVKhXv37sHd3d3YobRbZ5/LsWPHcObMGbz66qu4evUqZs+ejTlz5uDvf/87+vfvj507d+oM4l20aBFiYmLw0Ucf4bHHHoOdnZ3WXP+d9Rlzd3dv9QDbni4xMZHXzAj2799v7BA6RI9KFtRPMuibBbGjff3112hoaMDo0aNbFIO/vz/MzMzwn//8B0uXLm2y3ZbWa6+CggIUFxfj1q1bMDc3vV+XnJwcCCEwbtw4TZm5uXmzXf6mqLPP5cyZM7CxsQEAXLhwASqVCsuWLYOXlxeAxrusHRwcEB4ejtTUVNja2uossmSMzxgRGV6PGuAolUrx4osvYt++fUhKSkJlZSXq6+tx/fp1/Prrrx1yjNraWlRUVKCurg5nz55FZGSkZi31lsTg5OSEuXPn4sCBA0hOTkZlZSXy8/N15jRoab32WrFiBTw8PFq8YIyhNTQ04O7du6irq0N+fj6io6Ph4eGhub7Aw4VuysvLkZmZCZVKhVu3buHKlSs6bTk6OqKkpASXL19GVVUVVCoVsrOz2/zopKmdS1NUKhVKS0uRk5OjSRbUPV9fffUVampqUFhYqPUY528tXboUDx48wOeff46ZM2dqbeuMzxgRGYGxn8doL7Ty0ckHDx6INWvWCA8PD2Fubi6cnJzE3LlzRUFBgUhMTBQymUwAEAMGDBDHjx8XW7ZsEXK5XAAQLi4uYs+ePSI1NVW4uLgIAMLBwUHs27dPCCFESkqKCAkJEc7OzsLc3Fz06dNHzJ8/X1y5cqXFMQghRFVVlXjppZdEnz59RO/evUVwcLB44403BADh7u4uzp8/3+J6O3fuFP369RMAhEwmE7NmzRK7d+/WnOegQYNEcXGx+OCDD4SdnZ0AIDw9PTWPeh49elT06dNHANC8LCwsxNChQ0VGRkar3qv2xrJ48WJhYWEh3NzchLm5ubCzsxNhYWGiuLhY6zh37twRISEhQiqVioEDB4o///nPYvXq1QKA8PHx0TyaePbsWeHp6Smsra1FcHCwuHnzpjh8+LCwtbUVb731VpPnceLECTFs2DBhZmYmAIh+/fqJ+Ph4kzqX9957T3h7e2u9b429Pv30U82x1qxZIxwdHYW9vb2YN2+e2LVrlwAgvL29tR7nFEKIUaNGiXXr1jV6ffT9fm/dulVYW1sLAOKxxx4T//rXv1ryq6OlmzyK1qn46KTxdJPf13SJEF17sn6JRIK0tDTeizOQpKQkFBYWag3Sqa2txdq1a5GUlIS7d+/C2tq6U2JZsmQJ9u/fjzt37nTK8Qypq5/LjBkzsGvXLgwcOLDTjz1v3jwA3edecGdIT09HeHh4t1ibpavpJr+v+03vJjSZjJs3byIyMlLn/rOlpSU8PDygUqmgUqk6LVkA/vcYX3fQlc5FpVJpHqXMz8+HVCo1SqJARMbRo8YsUOtYW1vDwsICycnJKC0thUqlQklJCT766CO88cYbiIiIQElJiWYaYH2viIgIY58OtcOaNWtQWFiIn3/+GS+++CLefPNNY4dEBrZkyRKtz3BjS5x/9dVXWLduHRoaGjB79mx4eHhAKpXCzc0NoaGhmvll2qKhoQHbt29HUFBQi+rX1NRgyJAhOo/sAg+T3YSEBPj4+MDS0hL29vbw9/fH5cuXAQCfffYZtm7dqpPAZ2Zmal2Dvn37tvl8ujomC9QkuVyOf//73/jhhx8wePBgWFtbw8/PDykpKdiyZQv++c9/YsiQIVrrvTf1Sk1NbVcsMTExSElJQUVFBQYOHIgDBw500Fl2vq54LjKZDEOGDMHTTz+NTZs2wc/Pz9ghUSdwdHREdnY2Ll68iOTkZK1tGzduxI4dOxATE4OGhgYcP34ce/fuRXl5OXJzc6FUKjFhwgSUlJS0+riFhYWYMGECVq5cCYVC0aJ9YmNjm1xjJDw8XDMniEKhwE8//QRvb2/NwO1Zs2ZBKpVi0qRJuHfvnma/0NBQXL9+HceOHdPMUtpjGWesRMdBKwc4ElHXZgoDxhQKhQgMDOwyx2jLAMfFixcLNze3Rre9/fbbYvDgwUKpVAohhFCpVOKZZ57RqnPq1CkBQMTHx7fquHl5eWLOnDnik08+EQEBAWLkyJHN7vPNN9+IKVOmCAAiNjZWa9u+ffuERCIR+fn5zbYTGRkpAgMDhUql0tkWFRWltVZKS5nC72sH6FlrQxARdYTOWBLcVJcdLyoqwoYNGxAXF6eZHM7c3BwHDx7Uqqeer6O4uLhV7Y8cORIZGRlYuHAhrKysmq2vVCqxevVqJCYmNrr9vffew+jRozF8+PBm29q0aRPy8vKabKsnY7JARN2eEALbtm3TLNzl4OCAsLAwrfUq2rMkeFdYQr2j7NixA0IIzJo1S289pVIJALCzszNoPLGxsVi+fHmjU9/X1tbixIkTCAgIaFFbDg4OmDhxIhITE/nkyCOYLBBRt7dp0yasW7cOsbGxKCsrw7Fjx3Dt2jWMHz8epaWlAB5+CT76CPbu3bsRFxenVZaYmIiZM2fC29sbQggUFRUhMjISixYtgkKhQFRUFC5fvoyzZ8+irq4OkydPxrVr19p9DOB/T9A0NDR03MVppUOHDsHX1xcymUxvvVOnTgEAgoODDRbLN998g+LiYixYsKDR7SUlJaitrcWZM2cQEhKiSeKGDh2K3bt3N5oQjBo1Cjdu3MD58+cNFndXxGSBiLo1pVKJbdu2Yc6cOXj++echl8sxfPhwvP/++7h9+3aHznraVZZQb6vq6mr88ssv8Pb2brJOaWkpUlNTERUVhcDAwGZ7INpKqVQiOjoaSUlJTdZRD2B0cnJCfHw8CgoKUFpairCwMKxYsQJ79+7V2WfQoEEAHk6BTv/DZIGIurWCggLcv38fY8aM0SofO3YsLC0tm5zWuiOY2rLj7VVWVgYhhN5ehcDAQERFRSEsLAzZ2dma+Tk6WkxMDF555RW4ubk1WUc95mHYsGEICgqCo6Mj5HI54uLiIJfLG00U1eem7nGihzgpExF1a+pH4Xr37q2zzd7eHlVVVQY9fndaQr2mpgYA9A48dHZ2RnJyMoYNG2awOHJzc3HhwgVs27ZNbz31sujqsSBqlpaW8PT0bHTwpXqSOfW50kPsWSCibs3e3h4AGk0KDL0keHdaQh343xepvtlHnZycNNfcUJKTk3HkyBGYmZlpJkxSD3CMj4+HRCLB999/j969e2PQoEH48ccfddqoq6uDXC7XKa+trQWATp2ZtitgskBE3Zq/vz969+6N77//Xqv85MmTqK2txeOPP64p6+glwbvTEurAw14DiUSCioqKJuscPHhQ762BjpCSkqIz8Zu69yY2NhZCCM1tp/DwcJw7dw6XLl3S7K9QKHDlypVGH6dUn5uLi4tBz6GrYbJARN2aVCrFqlWr8Omnn+KTTz5BZWUlLly4gKVLl8LV1RWLFy/W1G3vkuDdaQn1xshkMnh5eeH69euNbi8qKoKLiwvCw8N1tkVERMDFxQVnz541dJhaVq5cCU9PTyxatAhXr17FnTt3sGbNGiiVSqxdu1anvvrcWjIvQ0/CZIGIur2NGzciISEBmzdvRt++fTFx4kQMGDAAOTk5sLGx0dRbtmwZQkJCMH/+fPj6+uLNN9/UdEcHBgZqHoFcunQpnJ2d4efnh+nTp6O8vBzAw/vcw4cPh7W1NcaPH4/Bgwfj66+/1rrH395jGNuMGTNQUFCgmUfht/TNTVBbW4uysjJkZWXpbf/EiRMIDg5G//79cfLkSZw/fx6urq548skncezYsVbH6+DggOPHj8Pd3R0BAQFwc3PDqVOncOjQoUbnXzh9+jTc3NwwYsSIVh+rO+MARyLq9iQSCV577TW89tpreus5Ojri6NGjOuXvvPOO1s+jRo3SLEL0W7a2tk3+190Rx5g2bRoqKyv1tm9of/7zn5GUlISMjAydxaUGDRrU5FMEBw4cwFNPPQVPT0+97Y8bNw65ubmtjqtv375NJivu7u6NPib5qDt37uDIkSN46623IJFIWh1Dd8aeBSKiDtKVlh1vCaVSiS+//BKFhYWagX8+Pj7YvHkzNm/erJnHoDn19fXIzMxEVVWVSa9Au2nTJgQEBCAyMhLAw56SkpIS5ObmaibG6qmYLBARUaPKy8sxdepUDB48GH/605805evWrcO8efMQERGhd7CjWk5ODjIyMpCdnd3szI/Gsm3bNuTl5eHw4cOauSGysrLg5uaG8ePH49ChQ0aO0LiYLBARtVNXXHa8Oe+//77W0waffPKJ1vb4+HhERkbi7bffbratSZMmYc+ePVprYpiSrKwsPHjwADk5OXBwcNCUh4WFaV2DR+dr6Ek4ZoGIqJ0SEhKQkJBg7DA63ZQpUzBlyhRjh9FuoaGhCA0NNXYYJo09C0RERKQXkwUiIiLSi8kCERER6cVkgYiIiPTqFgMcv/vuO2OHQESdRD3pUXp6upEj6TrUfyN5zTrf9evXu8VCYhKhb37OLoCzbBERkSl79tlnsX//fmOH0R77u3zPQhfPdYhMSnp6OsLDw/m5IiItHLNAREREejFZICIiIr2YLBAREZFeTBaIiIhILyYLREREpBeTBSIiItKLyQIRERHpxWSBiIiI9GKyQERERHoxWSAiIiK9mCwQERGRXkwWiIiISC8mC0RERKQXkwUiIiLSi8kCERER6cVkgYiIiPRiskBERER6MVkgIiIivZgsEBERkV5MFoiIiEgvJgtERESkF5MFIiIi0ovJAhEREenFZIGIiIj0YrJAREREejFZICIiIr2YLBAREZFeTBaIiIhILyYLREREpBeTBSIiItKLyQIRERHpxWSBiIiI9GKyQERERHqZGzsAIjKO69ev449//CPq6+s1ZXfv3oWtrS2eeuoprbq+vr7429/+1skREpGpYLJA1EO5u7vjypUrKC4u1tn2n//8R+vnCRMmdFZYRGSCeBuCqAd74YUXYGFh0Wy9iIiIToiGiEwVkwWiHmzhwoWoq6vTW2fYsGHw8/PrpIiIyBQxWSDqwby9vTFixAhIJJJGt1tYWOCPf/xjJ0dFRKaGyQJRD/fCCy+gV69ejW6rq6vDvHnzOjkiIjI1TBaIerj58+ejoaFBp9zMzAzjxo3DgAEDOj8oIjIpTBaIejhXV1c8+eSTMDPT/nNgZmaGF154wUhREZEpYQNm+UoAACAASURBVLJARPjDH/6gUyaEwJw5c4wQDRGZGiYLRIRnn31Wa9xCr1698PTTT8PZ2dmIURGRqWCyQERwcHDA5MmTNQmDEALPP/+8kaMiIlPBZIGIAADPP/+8ZqCjhYUFwsLCjBwREZkKJgtEBACYNWsWrKysAAAzZ85E7969jRwREZkKJgtEBACwsbHR9CbwFgQR/ZZECCGMHYQhpaenIzw83NhhEBFRN9XNv0YBYH+PWXUyLS3N2CEQmbz6+nqkpaVhwYIFAIDvvvsOiYmJ/Py0Unh4OKKjoxEYGGjsUMiA1J+PnqDHJAvPPfecsUMg6hJmz54NqVSq+TkxMZGfn1YKDw9HYGAgr1sP0FOSBY5ZICItv00UiIgAJgtERETUDCYLREREpBeTBSIiItKLyQIRERHpxWSBiAzu8OHDkMvlOHjwoLFD6XG++uorrFu3Dg0NDZg9ezY8PDwglUrh5uaG0NBQ5Ofnt7nthoYGbN++HUFBQS2qX1NTgyFDhmD9+vU621QqFRISEuDj4wNLS0vY29vD398fly9fBgB89tln2Lp1K+rr69scL7UdkwUiMrgeMGmNSdq4cSN27NiBmJgYNDQ04Pjx49i7dy/Ky8uRm5sLpVKJCRMmoKSkpNVtFxYWYsKECVi5ciUUCkWL9omNjcXFixcb3RYeHo6PP/4Ye/bsgUKhwE8//QRvb2/cv38fwMPpyKVSKSZNmoR79+61Ol5qHyYLRGRwM2bMQEVFBWbOnGnsUKBUKlv8n3BXtmXLFqSmpiI9PR22trYAgMDAQAQHB0Mmk2HgwIGIj49HRUUF/vGPf7Sq7fPnz2Pt2rVYunQpAgICWrTPt99+ix9++KHRbampqcjMzMT+/fvxxBNPwNzcHK6ursjKyoK/v7+mXlRUFEaOHInp06ejrq6uVTFT+zBZIKIeJTk5GWVlZcYOw6CKioqwYcMGxMXFaebNMDc317kN5OXlBQAoLi5uVfsjR45ERkYGFi5cqFl8TB+lUonVq1c3OYHRe++9h9GjR2P48OHNtrVp0ybk5eX1mMmQTAWTBSIyqNzcXHh4eEAikWDXrl0AgKSkJNjY2EAmkyErKwvTpk2DnZ0d3N3dsW/fPs2+O3bsgFQqhbOzM5YsWQJXV1dIpVIEBQXh5MmTmnqRkZGwtLREv379NGXLly+HjY0NJBIJbt++DQCIjo7GqlWrUFxcDIlEAh8fHwDAF198ATs7O8THx3fGJTG4HTt2QAiBWbNm6a2nVCoBAHZ2dgaNJzY2FsuXL4eTk5POttraWpw4caLFPRQODg6YOHEiEhMTeXurEzFZICKDCg4OxrfffqtVtmzZMrz66qtQKpWwtbVFWloaiouL4eXlhZdffhkqlQrAwyRg0aJFUCgUiIqKwuXLl3H27FnU1dVh8uTJuHbtGoCHX46PTq28e/duxMXFaZUlJiZi5syZ8Pb2hhACRUVFAKAZNNfQ0GCQa9DZDh06BF9fX8hkMr31Tp06BeDhe2Qo33zzDYqLizXrjTyqpKQEtbW1OHPmDEJCQjQJ4dChQ7F79+5GE4JRo0bhxo0bOH/+vMHiJm1MFojIqIKCgmBnZwcnJydERESguroaV69e1apjbm6OoUOHwsrKCn5+fkhKSkJVVRVSUlI6JIYZM2agsrISGzZs6JD2jKm6uhq//PILvL29m6xTWlqK1NRUREVFITAwsNkeiLZSKpWIjo5GUlJSk3XUAxidnJwQHx+PgoIClJaWIiwsDCtWrMDevXt19hk0aBAA4MKFCwaJm3QxWSAik2FpaQkAmp6FpowZMwYymQz//e9/OyOsLqWsrAxCCL29CoGBgYiKikJYWBiys7NhYWFhkFhiYmLwyiuvwM3Nrck66jEPw4YNQ1BQEBwdHSGXyxEXFwe5XI4PPvhAZx/1uZWWlhokbtLVY1adJKLuxcrKCrdu3TJ2GCanpqYGAPQOPHR2dkZycjKGDRtmsDhyc3Nx4cIFbNu2TW89V1dXANCMK1GztLSEp6dno4Mvra2tAfzvXMnw2LNARF2OSqXCvXv34O7ubuxQTI76i1Tf5EVOTk6wt7c3aBzJyck4cuQIzMzMIJFIIJFINAMc4+PjIZFI8P3336N3794YNGgQfvzxR5026urqIJfLdcpra2sB/O9cyfCYLBBRl5OTkwMhBMaNG6cpMzc3b/b2RU/g7OwMiUSCioqKJuscPHhQ762BjpCSkgIhhNZL3RMUGxsLIQTGjBkD4OGETOfOncOlS5c0+ysUCly5cqXRxynV5+bi4mLQc6D/YbJARCavoaEBd+/eRV1dHfLz8xEdHQ0PDw8sWrRIU8fHxwfl5eXIzMyESqXCrVu3cOXKFZ22HB0dUVJSgsuXL6OqqgoqlQrZ2dnd5tFJmUwGLy8vXL9+vdHtRUVFcHFxQXh4uM62iIgIuLi44OzZs4YOU8vKlSvh6emJRYsW4erVq7hz5w7WrFkDpVKJtWvX6tRXn1tL5mWgjsFkgYgMateuXRg7diwAYM2aNQgNDUVSUhK2b98OABgxYgQuXbqEDz/8EKtWrQIATJ06FYWFhZo2ampqMHz4cFhbW2P8+PEYPHgwvv76a6378suWLUNISAjmz58PX19fvPnmm5pu6sDAQM1jlkuXLoWzszP8/Pwwffp0lJeXd8p16EwzZsxAQUGBZh6F39I3N0FtbS3KysqQlZWlt/0TJ04gODgY/fv3x8mTJ3H+/Hm4urriySefxLFjx1odr4ODA44fPw53d3cEBATAzc0Np06dwqFDhxqdf+H06dNwc3PDiBEjWn0saiPRzaWlpYkecJpEBmEKn5/FixcLR0dHo8bQWgBEWlqa0Y5fWFgozM3Nxb/+9a9W7VdfXy/Gjx8vkpOTDRRZ+92+fVtIpVLxl7/8xdihmMTno5Oks2eBiEweVxpsHR8fH2zevBmbN2/WzGPQnPr6emRmZqKqqgoREREGjrDtNm3ahICAAERGRho7lB6FyUInGjt2LHr16tXiaU1b46WXXoKtrS0kEgny8vJaXc9UlhDOyMiAl5eXZvR0Y68BAwZ0yLH4flB3tm7dOsybNw8RERF6Bzuq5eTkICMjA9nZ2c3O/Ggs27ZtQ15eHg4fPmywuSGocUwWOtHp06cREhJikLY/+ugjfPjhh22uJ0xkjvW5c+fi0qVL8Pb2hlwu14yirqurg0KhQGlpaYf9IeP7YfpiYmKQkpKCiooKDBw4EAcOHDB2SF1KfHw8IiMj8fbbbzdbd9KkSdizZ4/W+hqmJCsrCw8ePEBOTg4cHByMHU6Pw0mZjEAikRg7BB3qJYRNVa9evWBtbQ1ra2sMHjy4Q9vm+2G6EhISkJCQYOwwurQpU6ZgypQpxg6j3UJDQxEaGmrsMHos9iwYgaG6z1r6pdcZX45CCOzfv7/RqVrbKzMzs0Pb4/tBRKQfk4VG1NfX44033oCHhwesra0xYsQIpKWlAXi4ap2NjQ3MzMzw+OOPw8XFBRYWFrCxscHo0aMxfvx4PPbYY5BKpbC3t8frr7+u035RURGGDBkCGxsbzaNgubm5LY4BePjH/91334Wvry+srKwgl8uxevVqnWO1pF57lhBWx5qQkABfX19YW1ujb9++GDhwIBISErRWAjTEMsB8P9r+fhARtZixnsPoLG15tOW1114TVlZW4sCBA+Lu3bsiJiZGmJmZidOnTwshhNi4caMAIE6ePCmqq6vF7du3xdSpUwUAcejQIXHr1i1RXV0tIiMjBQCRl5enaXvSpEnCy8tL/PLLL0KlUokffvhBPPHEE0IqlYqff/65xTHExsYKiUQi/vrXv4q7d+8KhUIhdu/eLQCIc+fOadppab1r164JAGLnzp1a+wIQR44cERUVFaKsrEyMHz9e2NjYiNraWk29+Ph40atXL5GVlSUUCoU4c+aMcHFxEU899ZTWdf3888+Fra2t2Lx5c7Pvgbe3t5DL5VplUVFR4sKFCzp1+X607f1oiR70aFiHgpEfnaTO0YM+H+nd/ixb+2YqlUohk8lERESEpkyhUAgrKyuxbNkyIcT/vpyqqqo0df75z38KAFpfZqdOnRIARGpqqqZs0qRJYuTIkVrHzM/PFwDEa6+91qIYFAqFkMlkYvLkyVrt7Nu3T+tLp6X1hND/5aRUKjVl6i+2oqIiTdnYsWPF//t//0/rGK+88oowMzMTDx48EG3h7e0tAOi89CULfD8e6sj3owf9MexQTBZ6hh70+UjnAMdHXLx4EQqFAv7+/poya2tr9OvXT+9yuOqldevq6jRl6nvhzc1XP3z4cMjlcuTn57cohqKiIigUCkyaNElvuy2t1xqNLSFcU1MDqVSqVa++vh4WFhbo1atXm48ll8tx7949zc/R0dGtjpPvx0PtfT/S09PbHmQP9d133xk7BDKwnvQeM1l4RHV1NQBg/fr1WL9+vdY29VKqhmBhYaH5g99cDOp50dUruDWlpfXaa/r06Xj33XeRlZWFKVOmoKCgAJmZmXjmmWfalSw8KjExscPaag7fD22NrSNA+iUmJnbq7yyRIXGA4yPUf8i3b9+us2KaobLIuro6lJeXw8PDo0UxqP9rfPDggd52W1qvvTZt2oTf/e53WLRoEezs7DBnzhw899xzLZpnwBTx/dD16Hnzpf8FAGlpaUaPgy/Dvn47yLm7Y7LwCPXIeX2z7nW0r7/+Gg0NDRg9enSLYvD394eZmRn+85//6G23pfXaq6CgAMXFxbh16xZUKhWuXr2KpKQkg02c8uuvv+LFF180SNsA3w8iokcxWXiEVCrFiy++iH379iEpKQmVlZWor6/H9evX8euvv3bIMWpra1FRUYG6ujqcPXsWkZGRmuVZWxKDk5MT5s6diwMHDiA5ORmVlZXIz8/XeYa+pfXaa8WKFfDw8Gh2Dvr2LgMshIBSqURGRgbs7Oza1EZjeur7QUTUYqKba8to1QcPHog1a9YIDw8PYW5uLpycnMTcuXNFQUGBSExMFDKZTAAQAwYMEMePHxdbtmwRcrlcABAuLi5iz549IjU1Vbi4uAgAwsHBQezbt08IIURKSooICQkRzs7OwtzcXPTp00fMnz9fXLlypcUxCCFEVVWVeOmll0SfPn1E7969RXBwsHjjjTcEAOHu7i7Onz/f4no7d+4U/fr1EwCETCYTs2bNErt379ac56BBg0RxcbH44IMPhJ2dnQAgPD09NY8WHj16VPTp00frqQULCwsxdOhQkZGRoTmnw4cPC1tbW/HWW281ee0//fTTJp+E+O1r/fr1QgjB96Md70dL9KDR3h0KfBqiR+hBn490iRCiW09Cn56ejvDwcHTz0zSqpKQkFBYWYvv27Zqy2tparF27FklJSbh79y6sra2NGGHP0pHvBz8/bSORSJCWlsZJsLq5HvT52M+nIahdbt68icjISJ37+ZaWlvDw8IBKpYJKpWKy0En4fhCRIXDMArWLtbU1LCwskJycjNLSUqhUKpSUlOCjjz7CG2+8gYiIiA4dX0D68f0gIkNgskDtIpfL8e9//xs//PADBg8eDGtra/j5+SElJQVbtmzBP//5T2OH2KPw/ej6vvrqK6xbtw4NDQ2YPXs2PDw8IJVK4ebmhtDQUM1kYW3R0NCA7du3IygoqEX1a2pqMGTIEJ35RYCHE4ElJCTAx8cHlpaWsLe3h7+/Py5fvmyw+DZv3gw/Pz/Y2dnBysoKPj4+eP311xsdzLt3716MHTsWtra28PT0xIsvvoibN29qtn/22WfYunUr6uvr2xxvj2LUIROdoAcNQCHqcPz8tA3aOMDxjTfeEDNnzhSVlZVCpVKJPn36iOPHj4vq6mpx6dIlMXnyZCGXy8WNGzda3fbPP/8snnzySQFAZ4rzpqxcuVIAELGxsTrbZs+eLXx9fcWJEyeESqUSJSUlYtasWY1Oyd5R8U2cOFHs3r1b3LlzR1RWVoq0tDRhYWEhpk6dqlUvNTVVABBbt24V9+7dE+fOnRNeXl4iICBAqFQqTb3ExEQxceJEcffu3TbF3IM+H+nsWSAik6ZUKlv8n7ApH6M5W7ZsQWpqKtLT02FrawsACAwMRHBwMGQyGQYOHIj4+HhUVFTgH//4R6vaPn/+PNauXYulS5ciICCgRft8++23+OGHHxrdlpqaiszMTOzfvx9PPPEEzM3N4erqiqysLK1p0Ts6vt69e2Px4sVwdHSEra0tnnvuOcyePRtffPEFrl27pqn3t7/9Df3798fq1ashl8sREBCAlStXIi8vDydPntTUi4qKwsiRIzF9+nStqeFJF5MFIjJpycnJKCsr6/LH0KeoqAgbNmxAXFycZqZPc3NzHDx4UKuel5cXAKC4uLhV7Y8cORIZGRlYuHAhrKysmq2vVCqxevXqJqerfu+99zB69GgMHz68VXG0N77PP/9cZ8ryvn37AgAUCoWm7Nq1a3B1dYVEItGUPfbYYwCAK1euaO2/adMm5OXlcWruZjBZIKIOJYTAtm3bMHToUFhZWcHBwQFhYWFaC7FFRkbC0tIS/fr105QtX74cNjY2kEgkuH37NoCHi4etWrUKxcXFkEgk8PHxwY4dOyCVSuHs7IwlS5bA1dUVUqkUQUFBWv81tucYAPDFF1+0axKx1tixYweEEJg1a5beekqlEgAMPkg1NjYWy5cvb3Qdk9raWpw4caLFPRSGduPGDVhbW2PgwIGaMi8vL53kTz1eQZ1wqTk4OGDixIlITEzsCY9AthmTBSLqUJs2bcK6desQGxuLsrIyHDt2DNeuXcP48eNRWloK4OGX46NzEOzevRtxcXFaZYmJiZg5cya8vb0hhEBRUREiIyOxaNEiKBQKREVF4fLlyzh79izq6uowefJkTXd0e44BQDPwraGhoeMuThMOHToEX19fyGQyvfVOnToFAAgODjZYLN988w2Ki4uxYMGCRreXlJSgtrYWZ86cQUhIiCZZGzp0KHbv3t2pX7gKhQJHjx7Fyy+/rFmBFQBiYmJw8+ZN7Ny5E1VVVSgoKEBiYiJ+//vfY9y4cTrtjBo1Cjdu3MD58+c7LfauhskCEXUYpVKJbdu2Yc6cOXj++echl8sxfPhwvP/++7h9+3aHTm1tbm6u6b3w8/NDUlISqqqqkJKS0iHtz5gxA5WVldiwYUOHtNeU6upq/PLLL/D29m6yTmlpKVJTUxEVFYXAwMBmeyDaSqlUIjo6GklJSU3WUT954OTkhPj4eBQUFKC0tBRhYWFYsWIF9u7da5DYGpOQkABXV1e89dZbWuUTJ07EmjVrEBkZCTs7O/j7+6OqqgofffRRo+0MGjQIAHDhwgWDx9xVMVkgog5TUFCA+/fvY8yYMVrlY8eOhaWlpdZtgo42ZswYyGQyrdsdXUFZWRmEEHp7FQIDAxEVFYWwsDBkZ2fDwsLCILHExMTglVdegZubW5N11GMKhg0bhqCgIDg6OkIulyMuLg5yubzD1zppyqeffor09HR8+eWXmgGharGxsfjggw9w5MgR3L9/H5cuXUJQUBACAwO1BkKqqa+9uueLdDFZIKIOc+/ePQAPR60/yt7eHlVVVQY9vpWVFW7dumXQY3S0mpoaANA7sM/Z2RlHjx7Fzp07IZfLDRJHbm4uLly4gJdeeklvPVdXVwDQjPlQs7S0hKenZ6sHX7ZFamoqtmzZgpycHAwYMEBr26+//oqtW7filVdewe9+9zvY2Nhg4MCB+PDDD1FSUoJ3331Xpz31jKbq94J0MVkgog5jb28PAI0mBffu3YO7u7vBjq1SqQx+DENQf1HpmxzIyclJc20NJTk5GUeOHIGZmRkkEgkkEolmgGN8fDwkEgm+//579O7dG4MGDcKPP/6o00ZdXZ3Bkhm1nTt34pNPPsHRo0fRv39/ne2FhYWor6/X2WZnZwdHR0cUFBTo7FNbWwsAnAZdDyYLRNRh/P390bt3b3z//fda5SdPnkRtbS0ef/xxTZm5uTlUKlWHHTsnJwdCCK0BbB19DENwdnaGRCJBRUVFk3UOHjyo99ZAR0hJSYEQQuul7qWJjY2FEEJzeyk8PBznzp3DpUuXNPsrFApcuXKlwx6nfJQQAmvWrMGFCxeQmZnZaO8VAE2y+Ouvv2qVV1VVoby8XPMI5W+pr72Li0sHR919MFkgog4jlUqxatUqfPrpp/jkk09QWVmJCxcuYOnSpXB1dcXixYs1dX18fFBeXo7MzEyoVCrcunVL5xl4AHB0dERJSQkuX76MqqoqzZd/Q0MD7t69i7q6OuTn5yM6OhoeHh5YtGhRhxwjOzu7Ux6dlMlk8PLywvXr1xvdXlRUBBcXF4SHh+tsi4iIgIuLC86ePWvQGB+1cuVKeHp6YtGiRbh69Sru3LmDNWvWQKlUYu3atQaJ78cff8Q777yDDz/8EBYWFpreD/XrL3/5CwBg4MCBCAkJwYcffohjx45BqVTi2rVrmt+9//u//9NpW33tDZXodAdMFoioQ23cuBEJCQnYvHkz+vbti4kTJ2LAgAHIycmBjY2Npt6yZcsQEhKC+fPnw9fXF2+++aamG/i3A9GWLl0KZ2dn+Pn5Yfr06SgvLwfw8P7y8OHDYW1tjfHjx2Pw4MH4+uuvte79t/cYnWXGjBkoKCjQzKPwW/oeRaytrUVZWRmysrL0tn/ixAkEBwejf//+OHnyJM6fPw9XV1c8+eSTOHbsWKvjdXBwwPHjx+Hu7o6AgAC4ubnh1KlTOHTokNb8Cx0ZX0sfyZRIJNi/fz8iIiLwf//3f3BwcICfnx+uXr2KjIwMjB8/Xmef06dPw83NDSNGjGjFVehhOn+K6c7Vg+buJupwpvr5Wbx4sXB0dDR2GE1CK9eGKCwsFObm5uJf//pXq45TX18vxo8fL5KTk1sbYqcw9fiEEOL27dtCKpWKv/zlL63e11Q/HwbAtSGIqGvqTqsF+vj4YPPmzdi8eXOjKyg2pr6+HpmZmaiqqkJERISBI2w9U49PbdOmTQgICEBkZKSxQzFpTBaIiEzAunXrMG/ePEREROgd7KiWk5ODjIwMZGdnNzvzozGYenwAsG3bNuTl5eHw4cMGm7uiu2CyQERdSkxMDFJSUlBRUYGBAwfiwIEDxg6pw8THxyMyMhJvv/12s3UnTZqEPXv2aK19YUpMPb6srCw8ePAAOTk5cHBwMHY4Js/c2AEQEbVGQkICEhISjB2GwUyZMgVTpkwxdhjdXmhoKEJDQ40dRpfBngUiIiLSi8kCERER6cVkgYiIiPRiskBERER69ZgBjvPmzTN2CERdjnoaXH5+Wm/79u3Yv3+/scMgA2pqiu7uSCJEC+fQ7KK+++47bNu2zdhhEHUJN2/exLlz5zBt2jRjh0LUZfSApHB/t08WiKjl0tPTER4e3uJ5+ImoR9jPMQtERESkF5MFIiIi0ovJAhEREenFZIGIiIj0YrJAREREejFZICIiIr2YLBAREZFeTBaIiIhILyYLREREpBeTBSIiItKLyQIRERHpxWSBiIiI9GKyQERERHoxWSAiIiK9mCwQERGRXkwWiIiISC8mC0RERKQXkwUiIiLSi8kCERER6cVkgYiIiPRiskBERER6MVkgIiIivZgsEBERkV5MFoiIiEgvJgtERESkF5MFIiIi0ovJAhEREenFZIGIiIj0YrJAREREejFZICIiIr2YLBAREZFeTBaIiIhIL3NjB0BExqFSqXD//n2tsurqagDA3bt3tcolEgns7e07LTYiMi1MFoh6qPLycri5uaG+vl5nm6Ojo9bPISEhOHr0aGeFRkQmhrchiHooFxcXTJgwAWZm+v8MSCQSzJ8/v5OiIiJTxGSBqAf7wx/+0GydXr16Yc6cOZ0QDRGZKiYLRD3Y3LlzYW7e9N3IXr16YerUqejTp08nRkVEpobJAlEPZmdnh2nTpjWZMAgh8Pzzz3dyVERkapgsEPVwzz//fKODHAHA0tISzzzzTCdHRESmhskCUQ/3zDPPQCaT6ZRbWFhg9uzZsLGxMUJURGRKmCwQ9XBSqRRz5syBhYWFVrlKpcLChQuNFBURmRImC0SEBQsWQKVSaZXZ2dlh8uTJRoqIiEwJkwUiwtNPP601EZOFhQXmz58PS0tLI0ZFRKaCyQIRwdzcHPPnz9fcilCpVFiwYIGRoyIiU8FkgYgAAPPnz9fcinBxcUFwcLCRIyIiU8FkgYgAAEFBQXBzcwMAvPDCC81OA01EPYfOTCzXr1/Ht99+a4xYiMjIxo4dixs3bqBPnz5IT083djhEZATPPfecTplECCF+W5Ceno7w8PBOC4qIiIhMxyNpAQDsb3JS+EYqE1EPcODAATz77LPGDsMg1P8M8e9b60gkEqSlpTX6Hyd1H/o6C3hTkoi0dNdEgYjajskCERER6cVkgYiIiPRiskBERER6MVkgIiIivZgsEBERkV5MFoiIWunw4cOQy+U4ePCgsUMxeV999RXWrVuHhoYGzJ49Gx4eHpBKpXBzc0NoaCjy8/Pb3HZDQwO2b9+OoKCgFtWvqanBkCFDsH79ep1tKpUKCQkJ8PHxgaWlJezt7eHv74/Lly8bLL7NmzfDz88PdnZ2sLKygo+PD15//XXcv39fp+7evXsxduxY2NrawtPTEy+++CJu3ryp2f7ZZ59h69atqK+vb3O8+jBZICJqJc7T0DIbN27Ejh07EBMTg4aGBhw/fhx79+5FeXk5cnNzoVQqMWHCBJSUlLS67cLCQkyYMAErV66EQqFo0T6xsbG4ePFio9vCw8Px8ccfY8+ePVAoFPjpp5/g7e3d6Bd3R8V39OhRrFixApcvX8bt27eRkJCAxMREzJs3T6teWloaFi5ciHnz5uH69evIysrCsWPHMG3aNNTV1QEAZs2aBalUikmTJuHevXttilkv8Yi0tDTRSDERUZfXHf++KRQKERgYaNBjABBpaWmt2uftt98WgwcPFkqlUgghhEqlEs8884xWFnNTigAAIABJREFUnVOnTgkAIj4+vlVt5+XliTlz5ohPPvlEBAQEiJEjRza7zzfffCOmTJkiAIjY2Fitbfv27RMSiUTk5+e3Ko72xjdjxgxRV1enVfbcc88JAOLq1auaspCQENG/f3/R0NCgKdu1a5cAIHJzc7X2j4yMFIGBgUKlUrU6bj2fj3T2LBARdWHJyckoKyszdhhaioqKsGHDBsTFxUEqlQJ4uAz6o7dtvLy8AADFxcWtan/kyJHIyMjAwoULYWVl1Wx9pVKJ1atXIzExsdHt7733HkaPHo3hw4e3Ko72xvf555+jV69eWmV9+/YFAK3eiGvXrsHV1RUSiURT9thjjwEArly5orX/pk2bkJeX1+S5thWTBSKiVsjNzYWHhwckEgl27doFAEhKSoKNjQ1kMhmysrIwbdo02NnZwd3dHfv27dPsu2PHDkilUjg7O2PJkiVwdXWFVCpFUFAQTp48qakXGRkJS0tL9OvXT1O2fPly2NjYQCKR4Pbt2wCA6OhorFq1CsXFxZBIJPDx8QEAfPHFF7Czs0N8fHxnXBIdO3bsgBACs2bN0ltPqVQCAOzs7AwaT2xsLJYvXw4nJyedbbW1tThx4gQCAgIMGkNL3bhxA9bW1hg4cKCmzMvLSychVI9XUCdcag4ODpg4cSISExM79HYZkwUiolYIDg7WWZl32bJlePXVV6FUKmFra4u0tDQUFxfDy8sLL7/8MlQqFYCHScCiRYugUCgQFRWFy5cv4+zZs6irq8PkyZNx7do1AA+/bB9dh2H37t2Ii4vTKktMTMTMmTPh7e0NIQSKiooAQDPIraGhwSDXoDmHDh2Cr68vZDKZ3nqnTp0C8PCaGso333yD4uJiLFiwoNHtJSUlqK2txZkzZxASEqJJ4IYOHYrdu3d36vgUhUKBo0eP4uWXX4alpaWmPCYmBjdv3sTOnTtRVVWFgoICJCYm4ve//z3GjRun086oUaNw48YNnD9/vsNiY7JARNSBgoKCYGdnBycnJ0RERKC6uhpXr17VqmNubo6hQ4fCysoKfn5+SEpKQlVVFVJSUjokhhkzZqCyshIbNmzokPZao7q6Gr/88gu8vb2brFNaWorU1FRERUUhMDCw2R6ItlIqlYiOjkZSUlKTddQDGJ2cnBAfH4+CggKUlpYiLCwMK1aswN69ew0SW2MSEhLg6uqKt956S6t84sSJWLNmDSIjI2FnZwd/f39UVVXho48+arSdQYMGAQAuXLjQYbExWSAiMhD1f4fqnoWmjBkzBjKZDP/97387IyyDKisrgxBCb69CYGAgoqKiEBYWhuzsbFhYWBgklpiYGLzyyitwc3Nrso56TMGwYcMQFBQER0dHyOVyxMXFQS6X44MPPjBIbI/69NNPkZ6eji+//BK2trZa22JjY/HBBx/gyJEjuH//Pi5duoSgoCAEBgZqeqN+S33tS0tLOyw+JgtERCbAysoKt27dMnYY7VZTUwMAegf2OTs74+jRo/+fvXsPi6pc+wf+HeQwDHJMQIRADp5QlExLEDTy1V26FTUVNCt6O3jqB6aXopKFFKjpRram9urmtXeXB0DboKnVVYqn8pQHDMsNGB5CRUUBZZQBnt8fXjPbcWCYgRlmgO/nuuYP13rWs+55GJjbtZ713FizZg0cHR2NEsfhw4dx7tw5vP3221rbeXh4AIBqHoiStbU1fHx89J582RTbtm3DsmXLkJubi65du6rtu3btGpYvX453330XL774Iuzs7ODr64uNGzeipKQEK1as0OjP1tYWwH9+FobAZIGIyMQUCgXu3r0LLy8vU4fSbMovKm2LA7m6usLJycmocaSnp+PHH3+EhYUFJBIJJBKJaoJjcnIyJBIJTp48iY4dO6Jbt244f/68Rh81NTVGS2aU1qxZg6+++gr79u1Dly5dNPYXFBSgtrZWY5+DgwNcXFyQn5+vcUx1dTWA//wsDIHJAhGRieXm5kIIoTZZzdLSstHbF+bIzc0NEokE5eXlDbbZtWuX1lsDhrBp0yYIIdReyis3CQkJEEJgwIABAB4tyHT69GlcvHhRdXxVVRUuXbpksMcpnySEQHx8PM6dO4fs7Gx07Nix3nbKBPLatWtq2ysrK1FWVqZ6hPJxyrF3d3c3WLxMFoiIWlhdXR3u3LmDmpoa5OXlYfbs2fD29kZMTIyqTUBAAMrKypCdnQ2FQoGbN29qPFMPAC4uLigpKUFxcTEqKyuhUCiwd+9ekz06KZPJ4Ofnh6tXr9a7v7CwEO7u7oiKitLYFx0dDXd3d5w6dcrYYaqZM2cOfHx8EBMTg8uXL+P27duIj4+HXC7HggULjBLf+fPn8emnn2Ljxo2wsrJSXf1QvlauXAkA8PX1RUREBDZu3IiDBw9CLpfjypUrmDZtGgDgrbfe0uhbOfaGTHSYLBAR6eGzzz7DwIEDAQDx8fGIjIzEunXrsGrVKgBA3759cfHiRWzcuBFz584FALz00ksoKChQ9fHgwQMEBQXB1tYW4eHh6N69O/bv3692n3/mzJmIiIjA5MmT0aNHD3z88ceqy8qPT2ybMWMG3NzcEBgYiJEjR6KsrKxFxkGbUaNGIT8/X7WOwuO0PYpYXV2N0tJS5OTkaO3/6NGjCAsLQ5cuXXDs2DGcPXsWHh4eGDx4MA4ePKh3vM7Ozjh06BC8vLwQHBwMT09PHD9+HLt371Zbf8GQ8en6SKZEIkFWVhaio6Px1ltvwdnZGYGBgbh8+TJ27NiB8PBwjWNOnDgBT09P9O3bV49RaIQeyz0SEbVq5vD3bdq0acLFxcWkMegLei73XFBQICwtLcWXX36p13lqa2tFeHi4SE9P1zfEFmHu8QkhxK1bt4RUKhUrV67U+1gu90xEZEaMVRnQXAQEBCApKQlJSUk6F2Kqra1FdnY2KisrER0dbeQI9Wfu8SklJiYiODgYsbGxBu23VScL+paJXblypWryzeeff97s87/99tuwt7eHRCLBmTNnmt2fOdO3FKwhxubs2bOIjo6Gr68vbGxs0KlTJ/Tr109jwRJjMsRnbMeOHfDz89O4J2ltbQ03Nze88MILWLFiBe7cuWPMt2I2tH2WOFZtx8KFCzFx4kRER0drneyolJubix07dmDv3r2NrvxoCuYeHwCkpqbizJkz2LNnj+HXrtDjMoTZ+eabb4SDg4PYuXOnzscUFBQIAGL9+vUGiWHr1q0CgDh9+rRB+jNH//73v8XgwYMFAJ2quyk1Z2zy8vKETCYTcXFx4o8//hByuVxcuHBBzJ8/XwwbNkzv/prKkJ8xf39/4ejoKIQQoq6uTty5c0fs379fxMTECIlEIjw8PMSJEycMGr+50fWzZKyxMvXft4ULFwpra2sBQHTt2lVkZWWZLBZ9oAlVJ5W+++47ER8fb+CI6EnZ2dkiJSVFo4qlPrTdhmg1yYKhyrAyWWhYfWPclFKwSs0Zm9dff1106dJFY/vDhw81ytwairE/Y49/AT4pKytLWFhYCDc3N3H37t1mx2Bqzf0sGWuszPXvm7lrTrJArUebmLNgjmVYAaiVDG3t6htjfUvBPq45Y3P79m2Ul5drzOy2trbW+ZaAvkz5GZswYQJiYmJQWlpqkFtkpmboz9Lj2tpYEbUGBkkWDhw4gOeeew4ymQwODg4ICgpCRUWFzuVYAeDQoUMIDAyEo6MjpFIpgoKC8N133wGovwxrfWViG+unuYQQWLFiBXr06AEbGxs4Ojpi3rx5am0+/fRTyGQy2Nvbo7S0FHPnzoWnpycuXLgAIQRSU1NVBWScnZ0xduxYtfXg9RkzXfprbqlbQ44NoHvp3IEDB+L+/ft48cUXceTIkQbbtaXPmPIZ+7179wJov5+lpowVERmZHpch6nXv3j3h4OAgli9fLuRyubh+/boYP368uHnzphDi0WNCdnZ24vz58+LBgwciPz9fDBw4UNjb24vLly+r+snKyhKJiYmirKxM3L59WwwaNEg89dRTqv2vvPKK8Pf3Vzv3lStXBACxZs0anftpzm2IhIQEIZFIxN/+9jdx584dUVVVJdauXatxqT0hIUEAEHFxcWLNmjVi/Pjx4rfffhMffvihsLa2Fl9++aW4e/euyMvLE/379xedOnUS169fVx2v65jp2t+rr74q3N3d1d7LihUrBADVz6mhMX7c888/3+ClY13H5ptvvhH29vYiKSlJ61hXVVWJAQMGCAACgAgMDBTLly8Xt2/f1mjbWj5j2i6tCyFERUWFACCefvpp1bb2+Flq6ljpgrchmga8DdEuGHXOwq+//ioAiG+++abe/dOmTdP4pT9x4oQAIJYsWdJgvykpKQKAKC0tFULo/oe8sX6amixUVVUJmUwmhg8frra9vvvyyj/wcrlc7fiOHTuK6OhoteOPHz8uAKh9eeoyZvr0Z+w/8PqMjT6qq6vF3//+d9GzZ09V0uDm5iZyc3PV2rWWz1hjX4BCCCGRSISTk5Pq3+3ts6TUlLHSBZOFpmGy0D5oSxYsm3tlws/PD25ubpg6dSri4uIQExOjUTXrSbqUY1U+9tHc55EN1U9hYSGqqqowbNiwJh2fn5+Pe/fuqdYiVxo4cCCsra01Lgs/6ckxa25/htTcsWmIlZUVYmNjERsbi2PHjmHZsmXIzs7GxIkTceHCBTg7Ozd4bGv8jN2/fx9CCDg4OGht15Y/S7rSdawaMnHiRANH1PatWrUKWVlZpg6DjKihJboBA8xZsLW1xb59+xAWFobk5GT4+fkhOjq63mU+H/dkOdbdu3fjhRdegKurK2xsbDB//vwmxWOofp6kHERl1TJ93b17FwDqLRbi5OSEysrKRvt4fMwM0Z+hNHdsdPH888/jX//6F2bMmIGbN29i//79jR7T2j5j//73vwEAPXv21NquLX+WdKXrWBGRYTT7ygIA9O7dG7t27cLNmzeRmpqKZcuWoXfv3li8eHG97Z8sx3r58mWMGzcO48ePx//+7/+iS5cuWLNmjd5/hA3VT32kUikA4OHDh006XlmOtb4/vLqUpn1yzJrbnyE1d2zq88orryAjIwOWluof0ddeew3r169HVVWV1uNb42fs22+/BQC8/PLLWtu15c+SrnQdq4bwf8j6kUgkeP/99zFp0iRTh0JGlJmZWW+BL8AAVxZKSkpUdcBdXV2xdOlS9O/fv97a4EpPlmM9d+4cFAoFZs6cCT8/P0il0iY9dmeofurTp08fWFhY4MCBA00+vmPHjjh58qTa9mPHjqG6uhrPPvus1uOfHDN9+jN2qdvmjk19Hj58WO9n6MKFCwDQaIGU1vYZu379OlatWgUvLy/893//t9a2bfmzpAt9xoqIDMMgycL06dPx+++/o7q6GqdPn8alS5fU6rI3Vo7V29sbAPDDDz/gwYMHKCgo0LhPWl8Z1ifp0k9Tubq64pVXXsH27duRnp6OiooK5OXlYcOGDTodL5VKMXfuXHz99df46quvUFFRgXPnzmHGjBnw8PBQlRtVamzM9OmvOaVuDT02+pTOHTduHDIzM3H37l2Ul5cjJycHCxYsQGRkpEay0Fo+Y0II3Lt3D3V1dRBC4ObNm8jIyMDgwYPRoUMHZGdnN3ofvi1/lgw9VkRkIHrMhqxXcXGxCA0NFc7OzqJDhw6iS5cuIiEhQbXk5LRp04SVlZXw9PQUlpaWwsHBQYwdO1YUFRWp9RMfHy9cXFyEk5OTmDhxovjss88EAOHv7y8uX74sTp06JXx8fIStra0ICwsTH3zwgejcubMAIGQymRgzZkyj/cyePVu4u7sLAMLOzk6MHz9e5/cphBCVlZXi7bffFk899ZTo2LGjCAsLEx9++KEAILy8vMTZs2fF8uXLha2treqxrserrtXV1YkVK1aIbt26CSsrK+Hs7CzGjRsnLly4oHYeXcdM1/5u374tIiIihFQqFb6+vuL//b//J+bNmycAiICAANUjdE+O8fXr18XPP/8sBg8eLDw8PFRPJHTu3FmEhoaKAwcO6DU2QgixZ88eYW9vLz755BOtY/3999+LqKgo4e/vL2xsbIS1tbXo0aOHSExMFA8ePGjSeJnqM7Zz507Rt29fIZPJhLW1tbCwsBAAVLP5n3vuOZGUlKTxWGh7/Cw1dax0xachmgZ8GqJdMOlyz62xHKupccz0w/FqGMdGHZOFpmGy0D6YfLnntl6O1Rg4ZvrheDWMY0NEzdVqakMYw++//65RCre+lznXLiciMmc//PADFi5ciLq6OowbNw7e3t6QSqXw9PREZGQk8vLymty3tnLn9Xnw4AF69uyJDz74QGOfQqFASkoKAgICYG1tDScnJ/Tp0wfFxcVGiy8pKQmBgYFwcHCAjY0NAgICMH/+fNy7d0+j7ZYtWzBw4EDY29vDx8cHb775Jq5fv67av3PnTixfvtx4/znQ4zKE3lprOVZT4pjph+PVMI6NJt6GaBo08TbEhx9+KEaPHi0qKiqEQqEQTz31lDh06JC4f/++uHjxohg+fLhwdHQUf/75p95961ru/HFz5swRAERCQoLGvnHjxokePXqIo0ePCoVCIUpKSsSYMWPEuXPn9I5N1/iGDh0q1q5dK27fvi0qKipERkaGsLKyEi+99JJau23btgkAYvny5eLu3bvi9OnTws/PTwQHBwuFQqFql5aWJoYOHSru3LnTpJjbRIlqIqLmMoe/b4Yqhd6S52hKsrB06VLRvXt31VLlCoVCo7y8cknx5ORkvfrWp9y50pEjR8SIESPqTRa2bt0qJBKJyMvL0yuO5sY3atQo1cMASpMmTRIA1Gq3REREiC5duoi6ujrVNuXE6sOHD6sdHxsbK0JCQtSSCF2ZfM4CERE90hKl0E1Zbh14tAT84sWLsWTJEtWibZaWlhrl5f38/AAARUVFevWvb7lzuVyOefPmIS0trd7969evR//+/REUFKRXHM2N75tvvkGHDh3UtnXq1AkA1Baeu3LlCjw8PNTWdHn66acBQOPR5cTERJw5c6bB99pUTBaIiLQQRi7frWsp8eaWCNe1PLwhrF69GkIIjBkzRms7ZVkAY6+XkZCQgFmzZtW7JH11dTWOHj2K4OBgo8agqz///BO2trbw9fVVbfPz89NI/pTzFZQJl5KzszOGDh2KtLQ0CCEMFheTBSIiLRITE7Fw4UIkJCSgtLQUBw8exJUrVxAeHo4bN24AePTl+ORSyGvXrsWSJUvUtqWlpWH06NHw9/eHEAKFhYWIjY1FTEwMqqqqEBcXh+LiYpw6dQo1NTUYPnw4rly50uxzAP95Kqaurs5wg9OA3bt3o0ePHpDJZFrbHT9+HAAQFhZmtFiOHDmCoqIiTJkypd79JSUlqK6uxi+//IKIiAhVstarVy+sXbvWoF+4jamqqsK+ffvwzjvvwNraWrV90aJFuH79OtasWYPKykrk5+cjLS0Nf/nLX9QWQFR65pln8Oeff+Ls2bMGi43JAhFRA+RyOVJTUzF+/HhMnToVjo6OCAoKwueff45bt27pvIKrLiwtLVVXLwIDA7Fu3TpUVlZi06ZNBul/1KhRqKioaLBmj6Hcv38ff/zxB/z9/Rtsc+PGDWzbtg1xcXEICQlp9ApEU8nlcsyePRvr1q1rsI3yyQNXV1ckJycjPz8fN27cwNixY/Hee+9hy5YtRomtPikpKfDw8MAnn3yitn3o0KGIj49HbGwsHBwc0KdPH1RWVuIf//hHvf1069YNwKPl6Q2FyQIRUQNMWb5blzLr5qi0tBRCCK1XFUJCQhAXF4exY8di7969qjLvhrZo0SK8++678PT0bLCNck5B7969ERoaChcXFzg6OmLJkiVwdHQ0aEKozddff43MzEx89913sLe3V9uXkJCADRs24Mcff8S9e/dw8eJFhIaGIiQkRHXl6XHKsVde+TIEJgtERA0wdfnuJ8ustwYPHjwAAK0T+9zc3LBv3z6sWbMGjo6ORonj8OHDOHfuHN5++22t7Tw8PABANedDydraGj4+PnpPvmyKbdu2YdmyZcjNzUXXrl3V9l27dg3Lly/Hu+++ixdffBF2dnbw9fXFxo0bUVJSghUrVmj0Z2trC+A/PwtDYLJARNQAU5bvfrKUeGuh/KLStjiQq6uramyNJT09HT/++CMsLCxUC+wpJzgmJydDIpHg5MmT6NixI7p161ZvlduamhqjJTNKa9aswVdffYV9+/ahS5cuGvsLCgpQW1ursc/BwQEuLi7Iz8/XOKa6uhrAf34WhsBkgYioAaYs3/1kKXFjnMMY3NzcIJFIUF5e3mCbXbt2ab01YAibNm2CEELtpbxKk5CQACGE6vZSVFQUTp8+jYsXL6qOr6qqwqVLlwz2OOWThBCIj4/HuXPnkJ2dXe/VKwCqZPHatWtq2ysrK1FWVqZ6hPJxyrF3d3c3WLxMFoiIGtCS5bsbKyXe3HPoUx6+OWQyGfz8/HD16tV69xcWFsLd3R1RUVEa+6Kjo+Hu7o5Tp04ZNcYnzZkzBz4+PoiJicHly5dx+/ZtxMfHQy6XY8GCBUaJ7/z58/j000+xceNGWFlZaZQZWLlyJQDA19cXERER2LhxIw4ePAi5XI4rV66oPntvvfWWRt/KsTdkosNkgYhIi48++ggpKSlISkpCp06dMHToUHTt2hW5ubmws7NTtZs5cyYiIiIwefJk9OjRAx9//LHqMvDjE9FmzJgBNzc3BAYGYuTIkSgrKwPw6P5yUFAQbG1tER4eju7du2P//v1q9/6be46WMmrUKOTn56vWUXictkcRq6urUVpaipycHK39Hz16FGFhYejSpQuOHTuGs2fPwsPDA4MHD8bBgwf1jtfZ2RmHDh2Cl5cXgoOD4enpiePHj2P37t1q6y8YMj5dH8mUSCTIyspCdHQ03nrrLTg7OyMwMBCXL1/Gjh07EB4ernHMiRMn4Onpib59++oxCo3QY7lHIqJWzVz/vpl7KXHoudxzQUGBsLS0FF9++aVe56mtrRXh4eEiPT1d3xBbhLnHJ4QQt27dElKpVKxcuVLvY7ncMxGRmWtLpcQDAgKQlJSEpKSkeiso1qe2thbZ2dmorKw0y0q/5h6fUmJiIoKDgxEbG2vQfpksEBGRwS1cuBATJ05EdHS01smOSrm5udixYwf27t3b6MqPpmDu8QFAamoqzpw5gz179hh87QomC0REJrRo0SJs2rQJ5eXl8PX1xfbt200dksEkJycjNjYWS5cubbTtsGHDsHnzZrXaF+bE3OPLycnBw4cPkZubC2dnZ4P3b2nwHomISGcpKSlISUkxdRhGM2LECIwYMcLUYbR5kZGRiIyMNFr/vLJAREREWjFZICIiIq2YLBAREZFWTBaIiIhIKyYLREREpFWDT0NIJJKWjIOIqMXw75v+oqKi6q3nQO2DRrIQGhqKjIwMU8RCRCb2888/Iy0tjX8DiEiNRAgdq1kQUZuXmZmJqKgonYvcEFG7kMU5C0RERKQVkwUiIiLSiskCERERacVkgYiIiLRiskBERERaMVkgIiIirZgsEBERkVZMFoiIiEgrJgtERESkFZMFIiIi0orJAhEREWnFZIGIiIi0YrJAREREWjFZICIiIq2YLBAREZFWTBaIiIhIKyYLREREpBWTBSIiItKKyQIRERFpxWSBiIiItGKyQERERFoxWSAiIiKtmCwQERGRVkwWiIiISCsmC0RERKQVkwUiIiLSiskCERERacVkgYiIiLRiskBERERaMVkgIiIirZgsEBERkVZMFoiIiEgrS1MHQESmcfPmTfzrX/9S23by5EkAwIYNG9S229vbY/LkyS0WGxGZF4kQQpg6CCJqeQ8fPoSbmxvu3buHDh06AACUfw4kEomqnUKhwBtvvIEvvvjCFGESkell8TYEUTtlY2ODCRMmwNLSEgqFAgqFAjU1NaipqVH9W6FQAACmTJli4miJyJSYLBC1Y1OmTEF1dbXWNk5OTnjxxRdbKCIiMkdMFojasYiICLi6uja438rKClOnToWlJac3EbVnTBaI2jELCwu8+uqrsLKyqne/QqHgxEYiYrJA1N5NnjxZNTfhSV26dEFISEgLR0RE5obJAlE799xzz8HHx0dju7W1Nd544w21JyOIqH1iskBEeO211zRuRVRXV/MWBBEBYLJARABeffVVjVsRAQEBCAoKMlFERGROmCwQEXr27InAwEDVLQcrKyu8+eabJo6KiMwFkwUiAgC8/vrrqpUca2pqeAuCiFSYLBARgEdPRdTW1gIA+vfvD19fXxNHRETmgskCEQEAvL298fzzzwMA3njjDRNHQ0TmhMuymamff/4Zqamppg6D2pmHDx9CIpHg+++/x8GDB00dDrUzWVlZpg6BGsArC2bqypUr2L59u6nDIAO5evVqq/h5enl5wd3dHVKp1NShAAC2b9+Oq1evmjoMMrLW8vvRnvHKgpljpt02ZGZmIioqqlX8PAsLCxEQEGDqMAA8KpX9/vvvY9KkSaYOhYxI+ftB5otXFohIjbkkCkRkPpgsEBERkVZMFoiIiEgrJgtERESkFZMFIiIi0orJAlErsmfPHjg6OmLXrl2mDsXs/fDDD1i4cCHq6uowbtw4eHt7QyqVwtPTE5GRkcjLy2ty33V1dVi1ahVCQ0N1av/gwQP07NkTH3zwgcY+hUKBlJQUBAQEwNraGk5OTujTpw+Ki4uNFl9SUhICAwPh4OAAGxsbBAQEYP78+bh3755G2y1btmDgwIGwt7eHj48P3nzzTVy/fl21f+fOnVi+fLlq9U9qm5gsELUiQghTh9AqfPTRR1i9ejUWLVqEuro6HDp0CFu2bEFZWRkOHz4MuVyOIUOGoKSkRO++CwoKMGTIEMyZMwdVVVU6HZOQkIALFy7Uuy8qKgr//Oc/sXnzZlRVVeG3336Dv79/vV/chopv3759eO+991BcXIxbt24hJSUFaWlpmDhxolq7jIwMvPrqq5g4cSKuXr2KnJxLf8QeAAAgAElEQVQcHDx4EC+//DJqamoAAGPGjIFUKsWwYcNw9+7dJsVMrYAgs5SRkSH442k72uLPs6qqSoSEhBj1HABERkaGXscsXbpUdO/eXcjlciGEEAqFQvz1r39Va3P8+HEBQCQnJ+vV95kzZ8T48ePFV199JYKDg0W/fv0aPebIkSNixIgRAoBISEhQ27d161YhkUhEXl6eXnE0N75Ro0aJmpoatW2TJk0SAMTly5dV2yIiIkSXLl1EXV2dattnn30mAIjDhw+rHR8bGytCQkKEQqHQO+62+PvRxmTyygIRNUl6ejpKS0tNHYaawsJCLF68GEuWLFGtQmlpaalx28bPzw8AUFRUpFf//fr1w44dO/Dqq6/Cxsam0fZyuRzz5s1DWlpavfvXr1+P/v37IygoSK84mhvfN998o6owqtSpUycAULsaceXKFXh4eKhKlwPA008/DQC4dOmS2vGJiYk4c+ZMg++VWjcmC0StxOHDh+Ht7Q2JRILPPvsMALBu3TrY2dlBJpMhJycHL7/8MhwcHODl5YWtW7eqjl29ejWkUinc3Nwwffp0eHh4QCqVIjQ0FMeOHVO1i42NhbW1NTp37qzaNmvWLNjZ2UEikeDWrVsAgNmzZ2Pu3LkoKiqCRCJRLeT07bffwsHBAcnJyS0xJBpWr14NIQTGjBmjtZ1cLgcAODg4GDWehIQEzJo1C66urhr7qqurcfToUQQHBxs1Bl39+eefsLW1Vas26ufnp5EQKucrKBMuJWdnZwwdOhRpaWm8XdYGMVkgaiXCwsLw008/qW2bOXMm3n//fcjlctjb2yMjIwNFRUXw8/PDO++8A4VCAeBREhATE4OqqirExcWhuLgYp06dQk1NDYYPH44rV64AePRl++TSymvXrsWSJUvUtqWlpWH06NHw9/eHEAKFhYUAoJrkVldXZ5QxaMzu3bvRo0cPyGQyre2OHz8O4NGYGsuRI0dQVFSEKVOm1Lu/pKQE1dXV+OWXXxAREaFK4Hr16oW1a9e26BduVVUV9u3bh3feeQfW1taq7YsWLcL169exZs0aVFZWIj8/H2lpafjLX/6CQYMGafTzzDPP4M8//8TZs2dbLHZqGUwWiNqI0NBQODg4wNXVFdHR0bh//z4uX76s1sbS0hK9evWCjY0NAgMDsW7dOlRWVmLTpk0GiWHUqFGoqKjA4sWLDdKfPu7fv48//vgD/v7+Dba5ceMGtm3bhri4OISEhDR6BaKp5HI5Zs+ejXXr1jXYRjmB0dXVFcnJycjPz8eNGzcwduxYvPfee9iyZYtRYqtPSkoKPDw88Mknn6htHzp0KOLj4xEbGwsHBwf06dMHlZWV+Mc//lFvP926dQMAnDt3zugxU8tiskDUBin/d6i8stCQAQMGQCaT4ffff2+JsIyqtLQUQgitVxVCQkIQFxeHsWPHYu/evbCysjJKLIsWLcK7774LT0/PBtso5xT07t0boaGhcHFxgaOjI5YsWQJHR0ds2LDBKLE96euvv0ZmZia+++472Nvbq+1LSEjAhg0b8OOPP+LevXu4ePEiQkNDERISoroa9Tjl2N+4caNFYqeWw2SBqJ2zsbHBzZs3TR1Gsz148AAAtE7sc3Nzw759+7BmzRo4OjoaJY7Dhw/j3LlzePvtt7W28/DwAADVPBAla2tr+Pj46D35sim2bduGZcuWITc3F127dlXbd+3aNSxfvhzvvvsuXnzxRdjZ2cHX1xcbN25ESUkJVqxYodGfra0tgP/8LKjtYLJA1I4pFArcvXsXXl5epg6l2ZRfVNoWB3J1dYWTk5NR40hPT8ePP/4ICwsLSCQSSCQS1QTH5ORkSCQSnDx5Eh07dkS3bt1w/vx5jT5qamqMlsworVmzBl999RX27duHLl26aOwvKChAbW2txj4HBwe4uLggPz9f45jq6moA//lZUNvBZIGoHcvNzYUQQm2ymqWlZaO3L8yRm5sbJBIJysvLG2yza9curbcGDGHTpk0QQqi9lFduEhISIITAgAEDADxakOn06dO4ePGi6viqqipcunTJYI9TPkkIgfj4eJw7dw7Z2dno2LFjve2UCeS1a9fUtldWVqKsrEz1COXjlGPv7u5u4KjJ1JgsELUjdXV1uHPnDmpqapCXl4fZs2fD29sbMTExqjYBAQEoKytDdnY2FAoFbt68qfFMPQC4uLigpKQExcXFqKyshEKhwN69e0326KRMJoOfnx+uXr1a7/7CwkK4u7sjKipKY190dDTc3d1x6tQpY4epZs6cOfDx8UFMTAwuX76M27dvIz4+HnK5HAsWLDBKfOfPn8enn36KjRs3wsrKSnX1Q/lauXIlAMDX1xcRERHYuHEjDh48CLlcjitXrmDatGkAgLfeekujb+XYGyvRIdNhskDUSnz22WcYOHAgACA+Ph6RkZFYt24dVq1aBQDo27cvLl68iI0bN2Lu3LkAgJdeegkFBQWqPh48eICgoCDY2toiPDwc3bt3x/79+9Xu88+cORMRERGYPHkyevTogY8//lh1WfnxiW0zZsyAm5sbAgMDMXLkSJSVlbXIOGgzatQo5Ofnq9ZReJy2RxGrq6tRWlqKnJwcrf0fPXoUYWFh6NKlC44dO4azZ8/Cw8MDgwcPxsGDB/WO19nZGYcOHYKXlxeCg4Ph6emJ48ePY/fu3WrrLxgyPl0fyZRIJMjKykJ0dDTeeustODs7IzAwEJcvX8aOHTsQHh6uccyJEyfg6emJvn376jEK1CqYYt1IahyXP21bzOHnOW3aNOHi4mLSGPQFPZd7LigoEJaWluLLL7/U6zy1tbUiPDxcpKen6xtiizD3+IQQ4tatW0IqlYqVK1fqfaw5/H6QVlzumag9aeuVAQMCApCUlISkpCSdCzHV1tYiOzsblZWViI6ONnKE+jP3+JQSExMRHByM2NhYU4dCRsBkgYjalIULF2LixImIjo7WOtlRKTc3Fzt27MDevXsbXfnRFMw9PgBITU3FmTNnsGfPHqOtXUGmxWShjVi5cqVqNvjnn39u6nAatGPHDvj5+akmU3Xu3BlTp05t9LizZ88iOjoavr6+sLGxQadOndCvXz+1Feeio6M1Jms19Prmm280Ymls1cHU1FRIJBJYWFigZ8+eTbpHbSqLFi3Cpk2bUF5eDl9fX2zfvt3UIRlVcnIyYmNjsXTp0kbbDhs2DJs3b1arh2FOzD2+nJwcPHz4ELm5uXB2djZ1OGQspr4RQvVryj28goICAUCsX7/eSFEZjr+/v3B0dNSpbV5enpDJZCIuLk788ccfQi6XiwsXLoj58+eLYcOGqdpFRUWJ77//Xty9e1coFApx7do1AUCMGTNGVFdXi/v374vS0lLxzjvviF27dqnFAkB07txZVFdX1xtDTU2N8PHxEQDUzqkr3pNtGjShRDW1Pvz9MHucs9CeyeVyhIaGmjqMRq1cuRJOTk5IS0tD165dIZVK0b17d7VZ+sCj2duDBw+Go6MjLC0t1bZbWVlBJpPB1dUVzz77rMY5nn32WVy/fh3Z2dn1xrBjxw6jP59PRGSumCy0Y+np6RrlZ83R7du3UV5ervFonrW1NXbt2qX699atW3W6pztt2jT89a9/Vds2c+ZMAMD69evrPSY1NVX1OCIRUXvDZKGNO3DgAJ577jnIZDI4ODggKCgIFRUVmD17NubOnYuioiJIJBIEBAQgLS0NdnZ2sLCwwLPPPgt3d3dYWVnBzs4O/fv3R3h4OJ5++mlIpVI4OTlh/vz5auf69ttvjbIgz8CBA3H//n28+OKLOHLkiEH7VnrxxRfRq1cv7N+/HxcuXFDbd+TIEVRVVWHEiBFGOTcRkbljstCG3b9/H2PGjMGECRNQVlaGgoICdO/eHdXV1UhLS8Po0aPh7+8PIQQKCwsxe/ZszJs3D0IIrF+/Hn/88QeuX7+OIUOG4PTp01i4cCFOnz6NsrIyvPHGG1ixYoVa3XrlY3l1dXUGfR/z58/HgAEDcPbsWYSFhaF379749NNPDb4I0PTp0wFAY4Lo3/72N8yZM8eg5yIiak2YLLRhxcXFqKioQO/evSGVSuHu7o4dO3agU6dOjR4bGBgImUyGp556CpMnTwYAeHt7o1OnTpDJZKonGB4vbTxq1ChUVFQ0+lSBvmxtbfHTTz/h73//O3r27Inz588jPj4evXr1woEDBwx2njfeeAN2dnb4v//7P9UKgBcvXsSJEycwZcoUg52HiKi1YbLQhvn5+cHNzQ1Tp05FYmIiiouLm9SPtbU1gEeV8JSUz1K3VMEhKysrxMbG4rfffsPRo0cxduxYlJaWYuLEibhz545BzuHo6IgpU6bgzp072LZtGwBg1apVmDlzpmoMmkvXRzv5evQCHhVbMnUcfBn3VV+9DjIvlo03odbK1tYW+/btw4IFC5CcnIykpCRMmjQJmzZtatUlZJ9//nn861//wsyZM7F+/Xrs378f48ePN0jfM2fOxMaNG/H5559j3LhxyMrKwm+//WaQvgEgIyPDYH21B1FRUZg9ezZCQkJMHQoZ0c8//4y0tDRTh0FaMFlo43r37o1du3bh5s2bSE1NxbJly9C7d2+D3yowpIMHD+KXX37B+++/DwB45ZVXkJGRofY4JAC89tprWL9+Paqqqgx27uDgYAwaNAhHjx7FtGnTMHHiRIMuNDNp0iSD9dUeREVFISQkhOPWDjBZMG+8DdGGlZSU4Pz58wAAV1dXLF26FP3791dtM1e//PIL7OzsVP9++PBhvTErn1owdIU75WOU27dvVyUsRETtGZOFNqykpATTp0/H77//jurqapw+fRqXLl3CoEGDAAAuLi4oKSlBcXExKisrmz3/YO/evc16dFKhUODGjRvIzc1VSxYAYNy4ccjMzMTdu3dRXl6OnJwcLFiwAJGRkQZPFiZNmoROnTph3Lhx8PPzM2jfREStkqnXkKT66bv86d/+9jfh7u4uAAg7Ozsxfvx4UVxcLEJDQ4Wzs7Po0KGD6NKli0hISBA1NTVCCCFOnTolfHx8hK2trQgLCxMLFy4UMplMABBdu3YVhw4dEsuWLROOjo4CgHB3dxebN28W27ZtU53L2dlZbN26VQghxJ49e4S9vb345JNPGozz66+/Vi2vrO319ddfq475/vvvRVRUlPD39xc2NjbC2tpa9OjRQyQmJooHDx5onKOiokIMGTJEuLi4CADCwsJCBAQEiOTk5AZj6dSpk3jvvfdU++bPny9++ukn1b8/+OAD0blzZ1V/gYGB4tChQzr/fLicbdOAyz23C/z9MHuZEiGEaOH8hHSQmZmJqKgo8MfTNvDn2TQSiQQZGRmcs9DG8ffD7GXxNgQRERFpxWSBiKgZfvjhByxcuBB1dXUYN24cvL29IZVK4enpicjISOTl5TWpX4VCgZSUFAQEBMDa2hpOTk7o06eP1vVSHjx4gJ49e+KDDz5Qbdu5cyeWL1+uWmGVqCmYLBARNdFHH32E1atXY9GiRairq8OhQ4ewZcsWlJWV4fDhw5DL5RgyZAhKSkr07jsqKgr//Oc/sXnzZlRVVeG3336Dv78/7t271+AxCQkJGrVNxowZA6lUimHDhuHu3bt6x0EEMFkgajdaoiR5ayl7bgjLli3Dtm3bkJmZCXt7ewBASEgIwsLCIJPJ4Ovri+TkZJSXl+OLL77Qq+9t27YhOzsbWVlZeP7552FpaQkPDw/k5OSgT58+9R7z008/4ddff613X1xcHPr164eRI0eqrcRKpCsmC0TtREuUJG8tZc+bq7CwEIsXL8aSJUsglUoBAJaWlmol0wGoHr0tKirSq//169ejf//+CAoK0qm9XC7HvHnztC5slJiYiDNnznDxI2oSJgtEZkoIgdTUVPTq1Qs2NjZwdnbG2LFj1Yp3xcbGwtraGp07d1ZtmzVrFuzs7CCRSHDr1i0AqLck+erVqyGVSuHm5obp06fDw8MDUqkUoaGhOHbsmEHOARivdLkprV69GkIIjBkzRms7ZUEyBwcHnfuurq7G0aNHERwcrPMxCQkJmDVrFlxdXRts4+zsjKFDhyItLY1PHZDemCwQmanExEQsXLgQCQkJKC0txcGDB3HlyhWEh4fjxo0bAB59aT35WOHatWuxZMkStW31lSSPjY1FTEwMqqqqEBcXh+LiYpw6dQo1NTUYPnw4rly50uxzAMYrXW5Ku3fvRo8ePSCTybS2O378OAAgLCxM575LSkpQXV2NX375BREREaokrlevXli7dq3GF/2RI0dQVFSkU2XUZ555Bn/++adaaXkiXTBZIDJDcrkcqampGD9+PKZOnQpHR0cEBQXh888/x61bt7BhwwaDncvS0lJ19SIwMBDr1q1DZWUlNm3aZJD+jVW63FTu37+PP/74A/7+/g22uXHjBrZt24a4uDiEhIQ0egXiccoJjK6urkhOTkZ+fj5u3LiBsWPH4r333sOWLVtUbeVyOWbPno1169bp1He3bt0AAOfOndM5HiKAyQKRWcrPz8e9e/cwYMAAte0DBw6EtbW12m0CQxswYABkMpna7Q76j9LSUgghtF5VCAkJQVxcHMaOHYu9e/eqSrrrwsbGBsCjInChoaFwcXGBo6MjlixZAkdHR7VEcdGiRXj33Xfh6empU9/KmJVXpoh0xaqTRGZI+Yhbx44dNfY5OTmhsrLSqOe3sbHBzZs3jXqO1urBgwcA/vOlXh83Nzekp6ejd+/eevfv4eEBAKq5IErW1tbw8fFRTZY8fPgwzp07h9TUVJ37VpamV74HIl3xygKRGXJycgKAepOCu3fvwsvLy2jnVigURj9Ha6b8wtW2yJGrq6vqZ6ivjh07olu3bvVWWq2pqYGjoyOAR0+e/Pjjj7CwsIBEIoFEIlFNcExOToZEIsHJkyfVjq+urlZ7D0S6YrJAZIb69OmDjh07avyxP3bsGKqrq/Hss8+qtllaWja7YujjcnNzIYRQVSc1xjlaMzc3N0gkEpSXlzfYZteuXTrfGqhPVFQUTp8+jYsXL6q2VVVV4dKlS6rHKTdt2gQhhNpLeTUoISEBQgiN21jKmN3d3ZscG7VPTBaIzJBUKsXcuXPx9ddf46uvvkJFRQXOnTuHGTNmwMPDA9OmTVO1DQgIQFlZGbKzs6FQKHDz5k1cunRJo8+GSpLX1dXhzp07qKmpQV5eHmbPng1vb2/ExMQY5BzNLV1ubmQyGfz8/HD16tV69xcWFsLd3R1RUVEa+6Kjo+Hu7o5Tp05pPcecOXPg4+ODmJgYXL58Gbdv30Z8fDzkcjkWLFjQ5NiVMeu6fgOREpMFIjP10UcfISUlBUlJSejUqROGDh2Krl27Ijc3F3Z2dqp2M2fOREREBCZPnowePXrg448/Vl1mDgkJUT0COWPGDLi5uSEwMBAjR45EWVkZgEf3r4OCgmBra4vw8HB0794d+/fvV7sn39xztDWjRo1Cfn6+ah2Fx2lbw6C6uhqlpaXIycnR2r+zszMOHToELy8vBAcHw9PTE8ePH8fu3bv1Wn/hSSdOnICnpyf69u3b5D6onWrhmtikI9Z3b1vM9ec5bdo04eLiYuowGgRAZGRkmDoMDQUFBcLS0lJ8+eWXeh1XW1srwsPDRXp6upEia9itW7eEVCoVK1eubPFzN8Zcfz9IJZNXFojaOVYj1F9AQACSkpKQlJSktbDT42pra5GdnY3KykpER0cbOUJNiYmJCA4ORmxsbIufm1o/JgtERE2wcOFCTJw4EdHR0VonOyrl5uZix44d2Lt3b6MrPxpaamoqzpw5gz179ui15gOREpMFonZq0aJF2LRpE8rLy+Hr64vt27ebOqRWJzk5GbGxsVi6dGmjbYcNG4bNmzer1dhoCTk5OXj48CFyc3Ph7OzcouemtoOLMhG1UykpKUhJSTF1GK3eiBEjMGLECFOH0aDIyEhERkaaOgxq5XhlgYiIiLRiskBERERaMVkgIiIirZgsEBERkVac4GjmMjMzTR0CGcDPP/8MgD/PplCOHbVd/BmbP4kQWtYmJZPJzMysd215IqK2il9HZiuLyQIRqSiTVP5ZIKLHZHHOAhEREWnFZIGIiIi0YrJAREREWjFZICIiIq2YLBAREZFWTBaIiIhIKyYLREREpBWTBSIiItKKyQIRERFpxWSBiIiItGKyQERERFoxWSAiIiKtmCwQERGRVkwWiIiISCsmC0RERKQVkwUiIiLSiskCERERacVkgYiIiLRiskBERERaMVkgIiIirZgsEBERkVZMFoiIiEgrJgtERESkFZMFIiIi0orJAhEREWnFZIGIiIi0YrJAREREWjFZICIiIq2YLBAREZFWTBaIiIhIKyYLREREpBWTBSIiItKKyQIRERFpZWnqAIjINK5evYo33ngDtbW1qm137tyBvb09XnjhBbW2PXr0wP/8z/+0cIREZC6YLBC1U15eXrh06RKKioo09h04cEDt30OGDGmpsIjIDPE2BFE79vrrr8PKyqrRdtHR0S0QDRGZKyYLRO3Yq6++ipqaGq1tevfujcDAwBaKiIjMEZMFonbM398fffv2hUQiqXe/lZUV3njjjRaOiojMDZMFonbu9ddfR4cOHerdV1NTg4kTJ7ZwRERkbpgsELVzkydPRl1dncZ2CwsLDBo0CF27dm35oIjIrDBZIGrnPDw8MHjwYFhYqP85sLCwwOuvv26iqIjInDBZICK89tprGtuEEBg/frwJoiEic8NkgYgwYcIEtXkLHTp0wH/913/Bzc3NhFERkblgskBEcHZ2xvDhw1UJgxACU6dONXFURGQumCwQEQBg6tSpqomOVlZWGDt2rIkjIiJzwWSBiAAAY8aMgY2NDQBg9OjR6Nixo4kjIiJzwWSBiAAAdnZ2qqsJvAVBRI+TCCGEqYOglpOZmYmoqChTh0FErRi/NtqdLFadbKcyMjJMHQIZ2apVqwAA77//vs7H1NbWIiMjA1OmTDFWWGbt559/RlpaGn8/GqAcH2p/mCy0U5MmTTJ1CGRkWVlZAPT/WY8bNw5SqdQYIbUKaWlp/P3QgslC+8Q5C0Skpj0nCkRUPyYLREREpBWTBSIiItKKyQIRERFpxWSBiIiItGKyQERa7dmzB46Ojti1a5epQzF7P/zwAxYuXIi6ujqMGzcO3t7ekEql8PT0RGRkJPLy8prUr0KhQEpKCgICAmBtbQ0nJyf06dMHxcXFDR7z4MED9OzZEx988IFq286dO7F8+XLU1tY2KQ5qv5gsEJFWXIBHNx999BFWr16NRYsWoa6uDocOHcKWLVtQVlaGw4cPQy6XY8iQISgpKdG776ioKPzzn//E5s2bUVVVhd9++w3+/v64d+9eg8ckJCTgwoULatvGjBkDqVSKYcOG4e7du3rHQe0XkwUi0mrUqFEoLy/H6NGjTR0K5HI5QkNDTR2GhmXLlmHbtm3IzMyEvb09ACAkJARhYWGQyWTw9fVFcnIyysvL8cUXX+jV97Zt25CdnY2srCw8//zzsLS0hIeHB3JyctCnT596j/npp5/w66+/1rsvLi4O/fr1w8iRI1FTU6NXLNR+MVkgolYjPT0dpaWlpg5DTWFhIRYvXowlS5ao1qiwtLTUuG3j5+cHACgqKtKr//Xr16N///4ICgrSqb1cLse8efO0Lp6UmJiIM2fOcIEl0hmTBSJq0OHDh+Ht7Q2JRILPPvsMALBu3TrY2dlBJpMhJycHL7/8MhwcHODl5YWtW7eqjl29ejWkUinc3Nwwffp0eHh4QCqVIjQ0FMeOHVO1i42NhbW1NTp37qzaNmvWLNjZ2UEikeDWrVsAgNmzZ2Pu3LkoKiqCRCJBQEAAAODbb7+Fg4MDkpOTW2JINKxevRpCCIwZM0ZrO7lcDgBwcHDQue/q6mocPXoUwcHBOh+TkJCAWbNmwdXVtcE2zs7OGDp0KNLS0nibiXTCZIGIGhQWFoaffvpJbdvMmTPx/vvvQy6Xw97eHhkZGSgqKoKfnx/eeecdKBQKAI+SgJiYGFRVVSEuLg7FxcU4deoUampqMHz4cFy5cgXAoy/bJ5dXXrt2LZYsWaK2LS0tDaNHj4a/vz+EECgsLAQA1WS9uro6o4xBY3bv3o0ePXpAJpNpbXf8+HEAj8ZUVyUlJaiursYvv/yCiIgIVcLVq1cvrF27VuOL/siRIygqKtKptsczzzyDP//8E2fPntU5Hmq/mCwQUZOFhobCwcEBrq6uiI6Oxv3793H58mW1NpaWlujVqxdsbGwQGBiIdevWobKyEps2bTJIDKNGjUJFRQUWL15skP70cf/+ffzxxx/w9/dvsM2NGzewbds2xMXFISQkpNErEI9TTmB0dXVFcnIy8vPzcePGDYwdOxbvvfcetmzZomorl8sxe/ZsrFu3Tqe+u3XrBgA4d+6czvFQ+8VkgYgMwtraGgBUVxYaMmDAAMhkMvz+++8tEZZRlZaWQgih9apCSEgI4uLiMHbsWOzduxdWVlY6929jYwMA6N27N0JDQ+Hi4gJHR0csWbIEjo6O2LBhg6rtokWL8O6778LT01OnvpUx37hxQ+d4qP1i1UkianE2Nja4efOmqcNotgcPHgD4z5d6fdzc3JCeno7evXvr3b+HhwcAqOZtKFlbW8PHx0c1WfLw4cM4d+4cUlNTde7b1tYWwH/eA5E2vLJARC1KoVDg7t278PLyMnUozab8wtW2yJGrqyucnJya1H/Hjh3RrVs3nD9/XmNfTU0NHB0dATx6SuTHH3+EhYUFJBIJJBKJaoJjcnIyJBIJTp48qXZ8dXW12nsg0obJAhG1qNzcXAghMGjQINU2S0vLRm9fmCM3NzdIJBKUl5c32GbXrl063xqoT1RUFE6fPo2LFy+qtlVVVeHSpUuqxyk3bdoEIYTaS3nlJiEhAUIIDBgwQK1fZczu7u5Njo3aDyYLRGRUdXV1uHPnDmpqapCXl4fZs2fD29sbMTExqvuUKdgAAA5wSURBVDYBAQEoKytDdnY2FAoFbt68iUuXLmn05eLigpKSEhQXF6OyshIKhQJ79+412aOTMpkMfn5+uHr1ar37CwsL4e7ujqioKI190dHRcHd3x6lTp7SeY86cOfDx8UFMTAwuX76M27dvIz4+HnK5HAsWLGhy7MqYdV2/gdo3JgtE1KDPPvsMAwcOBADEx8cjMjIS69atw6pVqwAAffv2xcWLF7Fx40bMnTsXAPDSSy+hoKBA1ceDBw8QFBQEW1tbhIeHo3v37ti/f7/aff6ZM2ciIiICkydPRo8ePfDxxx+rLo+HhISoHrOcMWMG3NzcEBgYiJEjR6KsrKxFxkGbUaNGIT8/X7WOwuO0rWFQXV2N0tJS5OTkaO3f2dkZhw4dgpeXF4KDg+Hp6Ynjx49j9+7deq2/8KQTJ07A09MTffv2bXIf1I4IalcyMjIEf+ztw4QJE8SECRNMGsO0adOEi4uLSWPQR1N+PwoKCoSlpaX48ssv9TqutrZWhIeHi/T0dL2OM4Rbt24JqVQqVq5cqddx/PvRbmXyygIRGVVbr3AYEBCApKQkJCUlaS3s9Lja2lpkZ2ejsrIS0dHRRo5QU2JiIoKDgxEbG9vi56bWickC6e3tt9+Gvb09JBIJzpw5Y+pw9LZjxw74+fmpZo0rX9bW1nBzc8MLL7yAFStW4M6dO6YOlVqJhQsXYuLEiYiOjtY62VEpNzcXO3bswN69extd+dHQUlNTcebMGezZs0evNR+ofWOyQHr7xz/+gY0bN5o6jCZ75ZVXcPHiRfj7+8PR0RFCCNTV1aG0tBSZmZnw9fVFfHw8evfurfG4Gelu0aJF2LRpE8rLy+Hr64vt27ebOiSjSk5ORmxsLJYuXdpo22HDhmHz5s1q9TBaQk5ODh4+fIjc3Fw4Ozu36LmpdeOiTEQAJBIJnJyc8MILL+CFF17AqFGjEBUVhVGjRuHf//636nl20l1KSgpSUlJMHUaLGjFiBEaMGGHqMBoUGRmJyMhIU4dBrRCvLFCTSCQSU4dgVBMmTEBMTAxKS0vx+eefmzocIiKTYrJAjRJCYMWKFejRowdsbGzg6OiIefPmabSrra3Fhx9+CG9vb9ja2qJv377IyMgAoHtZYwA4cOAAnnvuOchkMjg4OCAoKAgVFRWNngMwbLli5ToAe/fuNav3SETU0pgsUKMWL16M+Ph4TJs2DTdu3MD169frXQxmwYIF+PTTT7Fq1Spcu3YNo0ePxpQpU3Dy5Emdyxrfv38fY8aMwYQJE1BWVoaCggJ0795dtTSttnMAhi1XrHyG/fGV88zhPRIRtThTP7xJLUvf56SrqqqETCYTw4cPV9u+detWAUCcPn1aCCGEXC4XMplMREdHqx1rY2MjZs6cKYQQIiEhQQAQcrlc1Wbt2rUCgCgsLBRCCPHrr78KAOKbb77RiEWXc+jD399fODo6am0jkUiEk5NTq3yP5rDOQmvDdQS04/i0W5mc4EhaFRYWoqqqCsOGDdPa7sKFC6iqqkKfPn1U22xtbdG5c2etpYifLGvs5+cHNzc3TJ06FXFxcYiJiUHXrl2bdY6mun//PoQQcHBwaNb5Tfker169iszMTL2Pa69+/vlnAOCYNUA5PtQOmTpdoZal7/8M9uzZIwBorDL35JWFI0eOCAD1vgYNGiSEqP9/3Rs3bhQAxG+//aba9uuvv4q//vWvwtLSUkgkEhEVFSWqqqp0Ooc+GruycOrUKQFAjBgxolW+xwkTJjTYF198NedF7Q5XcCTtpFIpAODhw4da2ynL4a5atUqj+p2+/xvp3bs3du3ahZKSEsTHxyMjIwMrV6406Dl08e233wIAXn75ZQCt8z1OmDBBox++Gn4pJ5KaOg5zfXGibfvFZIG06tOnDywsLHDgwAGt7Z5++mlIpdJmr+hYUlKC8+fPA3j05bx06VL0798f58+fN9g5dHH9+nWsWrUKXl5e+O///m8Abe89EhHpiskCaeXq6opXXnkF27dvR3p6OioqKpCXl4cNGzaotZNKpXjzzTexdetWrFu3DhUVFaitrcXVq1dx7do1nc9XUlKC6dOn4/fff0d1dTVOnz6NS5cuYdCgQTqdQ99yxUII3Lt3D3V1dRBC4ObNm8jIyMDgwYPRoUMHZGdnq+YsmMt7JCJqcYLalabMZq6srBRvv/22eOqpp0THjh1FWFiY+PDDDwUA4eXlJc6ePSuEEOLhw4ciPj5eeHt7C0tLS+Hq6ipeeeUVkZ+fL9auXStkMpkAILp16yaKiorEhg0bhIODgwAgfHx8xL///W9RXFwsQkNDhbOzs+jQoYPo0qWLSEhIEDU1NY2eQ4hHcyzs7e3FJ5980uD72blzp+jbt6+QyWTC2tpaWFhYCACqJx+ee+45kZSUJG7fvq1xrDm8R13xaQj9cba/dhyfditTIoQQJstUqMVlZmYiKioK/LG3fRMnTgQAZGVlmTiS1oO/H9pxfNqtLN6GICIiIq2YLBAREZFWTBaIiIzohx9+wMKFC1FXV4dx48bB29sbUqkUnp6eiIyMRF5eXpP7rqurw6pVqxAaGqqxb+fOnVi+fLlqCXSi5mCyQERkJB999BFWr16NRYsWoa6uDocOHcKWLVtQVlaGw4cPQy6XY8iQISgpKdG774KCAgwZMgRz5sxBVVWVxv4xY8ZAKpVi2LBhuHv3riHeDrVjTBaIyGjkcnm9/+ttbedoimXLlmHbtm3IzMyEvb09ACAkJARhYWGQyWTw9fVFcnIyysvL8cUXX+jV99mzZ7FgwQLMmDFDVfCsPnFxcejXrx9GjhyJmpqa5rwdaueYLBCR0aSnp6O0tLTVn0NfhYWFWLx4MZYsWaJaBdXS0hK7du1Sa+fn5wcAKCoq0qv/fv36YceOHXj11VdhY2OjtW1iYiLOnDmDtLQ0vc5B9DgmC0SkIoRAamoqevXqBRsbGzg7O2Ps2LFqRaxiY2NhbW2Nzp07q7bNmjULdnZ2kEgkuHXrFgBg9uzZmDt3LoqKiiCRSBAQEIDVq1dDKpXCzc0N06dPh4eHB6RSKUJDQ3Hs2DGDnAN4tFS3PotzGdrq1ashhMCYMWO0tpPL5QCgWvjLGP5/e/cTEtUaxnH8K0ylk1BKzWBFVFqCNVFk0JCDROQiCSHUJmjhTmwxBq0sIptq2sTgpmgjLiqoa4UuymWDm7RCMnGVkGEFjmLpaNSMeu5CnHvnaqe8zp97x99nec573ufxDHoe3/O+7+Tk5FBaWkpTU5OWPMq/pmJBRKIaGxtpaGjg4sWLBINBOjs7GRoawuVyMTw8DMw9CKurq2Ouu3XrFleuXIk51tTUxIkTJ8jPz8cwDAYGBvB4PNTU1PDt2zfq6+sZHBykp6eH6elpjh07xtDQ0LJjANFJfbOzs/G7OUvw9OlTCgsLsVqtpu1evnwJQElJSULz2b9/P58+faK3tzehcSR9qVgQEWDuv1y/38/Jkyc5c+YM69atw+FwcOfOHUZHRxds8b0cFoslOnpRVFTE7du3CYVCtLS0xKX/8vJyJiYmuHTpUlz6W4qpqSnev39Pfn7+T9sMDw/z4MED6uvrcTqdvxyBWK6dO3cC0NfXl9A4kr4sqU5ARP4b+vv7mZycpLi4OOb4wYMHWb16dcxrgngrLi7GarXGvO74vwoGgxiGYTqq4HQ6mZqaorq6mmvXrrFq1aqE5jSfy/zokMhSqVgQEYDo8rrs7OwF59avX08oFEpo/DVr1jAyMpLQGMnw/ft3ANOJhzabjebmZnbv3p2UnLKysmJyE1kqvYYQEWCuIAAWLQq+fv3Kli1bEhY7EokkPEayzD+YzTZD2rhxY/R+J0M4HAb+yk1kqTSyICIA7Nmzh+zsbF6/fh1zvLu7m3A4zIEDB6LHLBYLkUgkbrEDgQCGYXDo0KGExUgWm81GRkYG4+PjP23zzyWUiTafi91uT2pcSR8aWRARADIzMzl//jxPnjzh3r17TExM0NfXR11dHXl5edTW1kbbFhQUMDY2RltbG5FIhJGRET58+LCgz9zcXD5//szg4CChUCj68J+dneXLly9MT0/z9u1bzp07x9atW6mpqYlLjI6OjpQtnbRarezYsYOPHz8uen5gYAC73c6pU6cWnHO73djtdnp6euKa03wuDocjrv3KyqFiQUSiLl++jM/nw+v1smHDBkpLS9m2bRuBQIC1a9dG2509e5YjR45w+vRpCgsLuXr1anSI2+l0RpdA1tXVYbPZKCoq4vjx44yNjQFz784dDgdZWVm4XC527drF8+fPY97zLzdGKpWXl9Pf3x/dR+HvzPY6CIfDBINB2tvbTfvv6uqipKSETZs20d3dTW9vL3l5eRw+fJjOzs4F7V+9esXmzZvZu3fv0n8YEQBDVpSHDx8a+thXhsrKSqOysjLVaSxQW1tr5ObmpjqNRcXr9+Pdu3eGxWIx7t69u6TrZmZmDJfLZTQ3Ny87h3mjo6NGZmamcfPmzWX3pb8fK9YfGlkQkaRL929CLCgowOv14vV6mZyc/K1rZmZmaGtrIxQK4Xa745ZLY2Mj+/btw+PxxK1PWXlULIiIJEBDQwNVVVW43W7TyY7zAoEAjx8/pqOj45c7P/4uv9/PmzdvePbsWcL3cpD0pmJBRJLmwoULtLS0MD4+zvbt23n06FGqU0qo69ev4/F4uHHjxi/bHj16lPv378d8H8ZytLe38+PHDwKBADk5OXHpU1YuLZ0UkaTx+Xz4fL5Up5FUZWVllJWVJT1uRUUFFRUVSY8r6UkjCyIiImJKxYKIiIiYUrEgIiIiplQsiIiIiClNcFyhqqqqUp2CJFhXVxegz3op5rdF1j1b3M+2sJb0l2EYJnuPStp58eIFfr8/1WmIyP9Ya2trqlOQ5GpVsSAiIiJmWjVnQUREREypWBARERFTKhZERETElIoFERERMfUneflxca9xausAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzV5qTeLevEy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f380fc01-2782-4d28-839e-3eae38205ab5"
      },
      "source": [
        "batch_size = 100\n",
        "model.fit(train_X, train_y, epochs=5, batch_size=batch_size, \n",
        "          shuffle=True, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "315/315 [==============================] - 134s 427ms/step - loss: 0.3204 - accuracy: 0.8678 - val_loss: 0.2869 - val_accuracy: 0.8777\n",
            "Epoch 2/5\n",
            "315/315 [==============================] - 132s 419ms/step - loss: 0.1854 - accuracy: 0.9319 - val_loss: 0.3238 - val_accuracy: 0.8723\n",
            "Epoch 3/5\n",
            "315/315 [==============================] - 132s 420ms/step - loss: 0.1221 - accuracy: 0.9564 - val_loss: 0.4521 - val_accuracy: 0.8631\n",
            "Epoch 4/5\n",
            "315/315 [==============================] - 133s 421ms/step - loss: 0.0807 - accuracy: 0.9721 - val_loss: 0.4570 - val_accuracy: 0.8637\n",
            "Epoch 5/5\n",
            "315/315 [==============================] - 131s 416ms/step - loss: 0.0642 - accuracy: 0.9772 - val_loss: 0.4067 - val_accuracy: 0.8703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1903cb2e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l4O5Wlte9Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "8e997776-2a58-4010-d165-571695124f40"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict_classes(test_X)\n",
        "print(classification_report(test_y,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-55-ab74e0d8dd84>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85      7143\n",
            "           1       0.87      0.87      0.87      7857\n",
            "\n",
            "    accuracy                           0.86     15000\n",
            "   macro avg       0.86      0.86      0.86     15000\n",
            "weighted avg       0.86      0.86      0.86     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-sXBOLai_Jy",
        "colab_type": "text"
      },
      "source": [
        "## CNN model with own embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFaOLgUgjpa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make the necessary imports\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
        "from keras.models import Model, Sequential\n",
        "from keras.initializers import Constant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99iMyfq_h32W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14a14acd-156e-4ead-e97f-b16388a1d9e6"
      },
      "source": [
        "EMBEDDING_DIM = 128 # dimension for dense embeddings for each token\n",
        "vocab_size # max vocal in transet 53314 MAX_NUM_WORDS\n",
        "max_len # max sequence length 146 MAX_SEQUENCE_LENGTH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D7pKBwOjHwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "bf2f88a7-0725-4b5a-fdfd-6a88a3eb0acc"
      },
      "source": [
        "print(\"Defining and training a CNN model, training embedding layer on the fly instead of using pre-trained embeddings\")\n",
        "cnnmodel2 = Sequential()\n",
        "cnnmodel2.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_len))\n",
        "cnnmodel2.add(Conv1D(128, 5, activation='relu'))\n",
        "cnnmodel2.add(MaxPooling1D(5))\n",
        "cnnmodel2.add(Conv1D(128, 5, activation='relu'))\n",
        "#cnnmodel2.add(MaxPooling1D(5))\n",
        "#cnnmodel2.add(Conv1D(128, 5, activation='relu'))\n",
        "cnnmodel2.add(GlobalMaxPooling1D())\n",
        "cnnmodel2.add(Dense(128, activation='relu'))\n",
        "cnnmodel2.add(Dense(1, activation='softmax'))\n",
        "\n",
        "cnnmodel2.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "print(cnnmodel2.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defining and training a CNN model, training embedding layer on the fly instead of using pre-trained embeddings\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 146, 128)          6824192   \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 142, 128)          82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 28, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_13 (Conv1D)           (None, 24, 128)           82048     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 7,004,929\n",
            "Trainable params: 7,004,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi2t-dPEkxal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21d2899e-f71b-4589-9d2e-2175c9af07c3"
      },
      "source": [
        "print(train_X.shape,train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 146) (35000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LPIvVXfjeYv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "95d1dde4-94be-467c-9884-91eabb131853"
      },
      "source": [
        "batch_size = 100\n",
        "cnnmodel2.fit(train_X, train_y, epochs=5, batch_size=batch_size,verbose=1,\n",
        "              validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "315/315 [==============================] - 86s 272ms/step - loss: 7.4610 - acc: 0.5107 - val_loss: 8.4481 - val_acc: 0.4460\n",
            "Epoch 2/5\n",
            "315/315 [==============================] - 86s 273ms/step - loss: 7.4610 - acc: 0.5107 - val_loss: 8.4481 - val_acc: 0.4460\n",
            "Epoch 3/5\n",
            "315/315 [==============================] - 86s 274ms/step - loss: 7.4610 - acc: 0.5107 - val_loss: 8.4481 - val_acc: 0.4460\n",
            "Epoch 4/5\n",
            "315/315 [==============================] - 86s 273ms/step - loss: 7.4610 - acc: 0.5107 - val_loss: 8.4481 - val_acc: 0.4460\n",
            "Epoch 5/5\n",
            "315/315 [==============================] - 87s 276ms/step - loss: 7.4610 - acc: 0.5107 - val_loss: 8.4481 - val_acc: 0.4460\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1903b6f208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRjeCJH_jj-o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "91e6c584-e850-49b4-b9c3-d429a4721336"
      },
      "source": [
        "#Evaluate on test set:\n",
        "y_pred = cnnmodel2.predict_classes(test_X)\n",
        "print(classification_report(test_y,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      7143\n",
            "           1       0.52      1.00      0.69      7857\n",
            "\n",
            "    accuracy                           0.52     15000\n",
            "   macro avg       0.26      0.50      0.34     15000\n",
            "weighted avg       0.27      0.52      0.36     15000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1powul9wmsfG",
        "colab_type": "text"
      },
      "source": [
        "# Kaggle CuDNNLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx0jp2Her04y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import bz2\n",
        "import gc\n",
        "import chardet\n",
        "import re\n",
        "import os\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import LSTM,Dense, Embedding, Input, Conv1D, GlobalMaxPool1D, Dropout, concatenate, Layer, InputSpec\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras import activations, initializers, regularizers, constraints\n",
        "from keras.utils.conv_utils import conv_output_length\n",
        "from keras.regularizers import l2\n",
        "from keras.constraints import maxnorm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAyjw6osnsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKw6Ugsemv3-",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/anshulrai/cudnnlstm-implementation-93-7-accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hjKAhEAn-Hw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "12dc5f81-f77a-4ce0-8f25-9649d433240d"
      },
      "source": [
        "norm_train_reviews=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/norm_train_reviews.csv')\n",
        "norm_test_reviews=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/norm_test_reviews.csv')\n",
        "norm_train_reviews=norm_train_reviews['0']\n",
        "norm_test_reviews=norm_test_reviews['0']\n",
        "print(len(norm_train_reviews))\n",
        "print(len(norm_test_reviews))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35000\n",
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzomoHtbqqJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2e2cfd-f9ae-4573-ebc4-72a0fdb6ea39"
      },
      "source": [
        "train_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv')\n",
        "print(train_set.shape)\n",
        "reviews = np.array(train_set['review'])\n",
        "sentiments = np.array(train_set['label'])\n",
        "train_sentiments = sentiments[:35000]\n",
        "test_sentiments = sentiments[35000:50000]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3600000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my4u2NYRr4IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 20000\n",
        "maxlen = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eyE377dr9Xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(norm_train_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t1ZGedur9Sv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_train = tokenizer.texts_to_sequences(norm_train_reviews)\n",
        "X_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVz0Qu8Zr9QK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "43ae5621-6dea-43d1-a4dc-e7213dba685c"
      },
      "source": [
        "print(X_train.shape)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,   107,   316,   109],\n",
              "       [    0,     0,     0, ...,    88,    78,  2396],\n",
              "       [    0,     0,     0, ...,    30,    34,    75],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,   164,     1,   588],\n",
              "       [    0,     0,     0, ..., 18416,  1112,  1056],\n",
              "       [    0,     0,     0, ...,     1,   420,     9]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFqjPnu7r8o2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a578b9ce-6b66-4c8e-cd4d-1a0c8016b05c"
      },
      "source": [
        "tokenized_test = tokenizer.texts_to_sequences(norm_test_reviews)\n",
        "X_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuhvnOCNtOjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = '/content/drive/My Drive/Data/NLP/glove.6B.100d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYOoOMw0t3B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word, *arr): \n",
        "  return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMBARGaPt71M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e13fe0fe-6ee5-4d76-aaab-c077c7d3b593"
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "#change below line if computing normal stats is too slow\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size)) #embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ-2NOtdt_uN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a89f4e6a-267a-45ed-80e4-5e7983d22aff"
      },
      "source": [
        "print(embedding_matrix.shape)\n",
        "embedding_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.73279406e-01, -1.08945996e-01, -3.23282658e-01, ...,\n",
              "        -2.71308239e-01,  2.56275949e-01,  2.68222112e-01],\n",
              "       [-1.91039994e-01,  1.76009998e-01,  3.69199991e-01, ...,\n",
              "        -5.96800029e-01,  8.08430016e-02,  2.78659999e-01],\n",
              "       [-1.97439998e-01,  4.48309988e-01,  1.36889994e-01, ...,\n",
              "        -5.69679976e-01,  1.53739995e-03,  6.66000009e-01],\n",
              "       ...,\n",
              "       [-3.97029996e-01, -4.21180010e-01,  4.91499990e-01, ...,\n",
              "         2.89440006e-01,  5.59660017e-01,  9.49620008e-01],\n",
              "       [-4.53359991e-01,  5.52269995e-01,  2.18989998e-01, ...,\n",
              "        -5.59360027e-01,  1.59140003e+00,  7.47829974e-02],\n",
              "       [-6.30200028e-01,  1.06739998e+00, -5.99319994e-01, ...,\n",
              "         7.62539983e-01, -3.41219991e-01,  1.09800005e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m003kRDuC0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#del tokenized_test, tokenized_train, tokenizer, word_index, embeddings_index, all_embs, nb_words\n",
        "#gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-asvranuMhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 2048\n",
        "epochs = 7\n",
        "embed_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x57Svjs0uR-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "a6b88511-341f-4e36-b023-94bff9d8469e"
      },
      "source": [
        "def cudnnlstm_model(conv_layers = 2, max_dilation_rate = 3):\n",
        "    inp = Input(shape=(maxlen, ))\n",
        "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=True)(inp)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Conv1D(2*embed_size, kernel_size = 3)(x)\n",
        "    prefilt = Conv1D(2*embed_size, kernel_size = 3)(x)\n",
        "    x = prefilt\n",
        "    for strides in [1, 1, 2]:\n",
        "        x = Conv1D(128*2**(strides), strides = strides, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_size=3, kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n",
        "    x_f = LSTM(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)  \n",
        "    x_b = LSTM(512, kernel_regularizer=l2(4e-6), bias_regularizer=l2(4e-6), kernel_constraint=maxnorm(10), bias_constraint=maxnorm(10))(x)\n",
        "    x = concatenate([x_f, x_b])\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['binary_accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "cudnnlstm_model = cudnnlstm_model()\n",
        "cudnnlstm_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 100)     2000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 100, 100)     0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 98, 200)      60200       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 96, 200)      120200      conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 94, 256)      153856      conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 92, 256)      196864      conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 45, 512)      393728      conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 512)          2099200     conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 512)          2099200     conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 1024)         0           lstm[0][0]                       \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 64)           65600       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            65          dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 7,188,913\n",
            "Trainable params: 7,188,913\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tm2wxZmuWi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_path=\"early_weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
        "callbacks = [checkpoint, early_stopping]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge3XkIhhukqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "b58daf01-f230-452b-d40c-a9228206cf3b"
      },
      "source": [
        "cudnnlstm_model.fit(X_train, train_sentiments, batch_size=batch_size, \n",
        "                    epochs=epochs, shuffle = True, validation_split=0.20, \n",
        "                    callbacks=callbacks,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.7399 - binary_accuracy: 0.5462\n",
            "Epoch 00001: val_loss improved from inf to 0.61902, saving model to early_weights.hdf5\n",
            "14/14 [==============================] - 28s 2s/step - loss: 0.7399 - binary_accuracy: 0.5462 - val_loss: 0.6190 - val_binary_accuracy: 0.6850\n",
            "Epoch 2/7\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.6037 - binary_accuracy: 0.6963\n",
            "Epoch 00002: val_loss improved from 0.61902 to 0.56850, saving model to early_weights.hdf5\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.6037 - binary_accuracy: 0.6963 - val_loss: 0.5685 - val_binary_accuracy: 0.8120\n",
            "Epoch 3/7\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.5185 - binary_accuracy: 0.7637\n",
            "Epoch 00003: val_loss improved from 0.56850 to 0.41932, saving model to early_weights.hdf5\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.5185 - binary_accuracy: 0.7637 - val_loss: 0.4193 - val_binary_accuracy: 0.8226\n",
            "Epoch 4/7\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.4361 - binary_accuracy: 0.8131\n",
            "Epoch 00004: val_loss improved from 0.41932 to 0.37817, saving model to early_weights.hdf5\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.4361 - binary_accuracy: 0.8131 - val_loss: 0.3782 - val_binary_accuracy: 0.8439\n",
            "Epoch 5/7\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3904 - binary_accuracy: 0.8354\n",
            "Epoch 00005: val_loss improved from 0.37817 to 0.34417, saving model to early_weights.hdf5\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.3904 - binary_accuracy: 0.8354 - val_loss: 0.3442 - val_binary_accuracy: 0.8586\n",
            "Epoch 6/7\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3594 - binary_accuracy: 0.8505\n",
            "Epoch 00006: val_loss improved from 0.34417 to 0.31961, saving model to early_weights.hdf5\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.3594 - binary_accuracy: 0.8505 - val_loss: 0.3196 - val_binary_accuracy: 0.8721\n",
            "Epoch 7/7\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.3404 - binary_accuracy: 0.8608\n",
            "Epoch 00007: val_loss did not improve from 0.31961\n",
            "14/14 [==============================] - 26s 2s/step - loss: 0.3404 - binary_accuracy: 0.8608 - val_loss: 0.3477 - val_binary_accuracy: 0.8590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0d72842fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbS6oeAJupKF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f74566cd-d53c-4999-b544-1310883a7eff"
      },
      "source": [
        "score, acc = cudnnlstm_model.evaluate(X_test, test_sentiments, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 4s 529ms/step - loss: 0.3603 - binary_accuracy: 0.8494\n",
            "Test score: 0.36029815673828125\n",
            "Test accuracy: 0.849399983882904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x3JWUesvJcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5dbf6c6e-aa8d-49c0-86a1-f9c9b6f2cb1f"
      },
      "source": [
        "#Evaluate on test set:\n",
        "\n",
        "y_pred = cudnnlstm_model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01546661],\n",
              "       [0.0285088 ],\n",
              "       [0.8842947 ],\n",
              "       ...,\n",
              "       [0.13450688],\n",
              "       [0.9937104 ],\n",
              "       [0.96193534]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E5lqEJwyh99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=np.round(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy_FpwQJvWUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4aefdca2-cfc6-4ec7-b313-19179ca4b403"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_sentiments,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.76      0.83      7143\n",
            "           1       0.81      0.93      0.87      7857\n",
            "\n",
            "    accuracy                           0.85     15000\n",
            "   macro avg       0.86      0.85      0.85     15000\n",
            "weighted avg       0.86      0.85      0.85     15000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49IUocgm5HPq",
        "colab_type": "text"
      },
      "source": [
        "# Fast text supervised model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTjq7os_5NVa",
        "colab_type": "text"
      },
      "source": [
        "One of the fastest and most accessible text classifier to anyone, without GPU\n",
        "\n",
        "FastText is well known for its distributed representation, which ultimately gets used as an embedding layer in a typical Deep Learning model such as a CNN or an LSTM. However, many don't know that FastText is also a supervised model. To prove the point, this Amazon dataset has been created to support the FastText format. And yet, 6 months later, no one has even tried to post a kernel for using FastText supervised model. What many also don't know is that, it is in fact a pretty good supervised model. Probably one of the fastest and the best out there without using a GPU. I'll cut straight to the chase and demonstrate how this is done. For a full writeup that's about to come soon, check out my blog post here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5J7Zrk05KUj",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/ejlok1/fasttext-model-91-7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_E884oO6HEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "1a9a4da9-de95-4846-d780-8797877344f6"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\r\u001b[K     |████▊                           | 10kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (49.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3020490 sha256=6019c9cc2d643c67ba9e8c1b0b312c5c59914710478088bb6781ad4f9f7e82eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRpTj98P6FMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import fasttext\n",
        "import bz2\n",
        "import csv\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UddMHAK95U4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b8dc400-0270-46fc-e60e-bc964f73e65c"
      },
      "source": [
        "data = bz2.BZ2File('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train.ft.txt.bz2')\n",
        "data = data.readlines()\n",
        "data = [x.decode('utf-8') for x in data]\n",
        "print(len(data)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3600000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyRr9rz75VGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0b20ff12-1479-468e-d375-338d09ddff2f"
      },
      "source": [
        "# 3.6mil rows! Lets inspect a few records to see the format and get a feel for the data\n",
        "data[1:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
              " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n',\n",
              " \"__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\\n\",\n",
              " \"__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZwqmBky6VU3",
        "colab_type": "text"
      },
      "source": [
        "## Data prep and modelling\n",
        "A slight inconvenience with the FastText model is the need to save the dataset into a text file. And the annoying encoding of the \"__label __#\". Basically, the target and the text is all in the same cell. They are distinguished by the prefix of '__label __#'. Lets say if have 2 labels and one is 'Ham' and the other 'Spam', then your labels would be '__label __Ham' and '__label __Spam'. You can include as many labels as well, not just 2.\n",
        "\n",
        "Thankfully, this dataset has already been formated in that way as you can see from the first 5 records I printed out. We just need to write it out to disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAkL-nJg5VD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "117c3945-0d76-4345-bf3b-c8b88f7a7d6f"
      },
      "source": [
        "# Data Prep\n",
        "data = pd.DataFrame(data)\n",
        "data.to_csv(\"train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
        "\n",
        "# Modelling\n",
        "# This routine takes about 5 to 10 minutes \n",
        "model = fasttext.train_supervised('train.txt',label_prefix='__label__', thread=4, epoch = 10)\n",
        "print(model.labels, 'are the labels or targets the model is predicting')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['__label__1', '__label__2'] are the labels or targets the model is predicting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo8B-PD36tyk",
        "colab_type": "text"
      },
      "source": [
        "## Apply predictions\n",
        "\n",
        "Ok after about 10 minutes or so, the model is finished. Now lets apply the predictions to the test dataset. Thankfully, we don't have to write out a physical text file to do the prediction. You could if you want to, but I'm just going to use the data object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZRnW3g-5VAR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "29d9e842-2863-4ae1-ff88-017ffb2cea86"
      },
      "source": [
        "# Load the test data \n",
        "test = bz2.BZ2File(\"/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test.ft.txt.bz2\")\n",
        "test = test.readlines()\n",
        "test = [x.decode('utf-8') for x in test]\n",
        "print(len(test), 'number of records in the test set') \n",
        "\n",
        "# To run the predict function, we need to remove the __label__1 and __label__2 from the testset.  \n",
        "new = [w.replace('__label__2 ', '') for w in test]\n",
        "new = [w.replace('__label__1 ', '') for w in new]\n",
        "new = [w.replace('\\n', '') for w in new]\n",
        "\n",
        "# Use the predict function \n",
        "pred = model.predict(new)\n",
        "\n",
        "# check the first record outputs\n",
        "print(pred[0][0], 'is the predicted label')\n",
        "print(pred[0][1], 'is the probability score')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000 number of records in the test set\n",
            "['__label__2'] is the predicted label\n",
            "['__label__2'] is the probability score\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "465I_Wdd5U9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets recode the actual targets to 1's and 0's from both the test set and the actual predictions  \n",
        "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test]\n",
        "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmTHqs2k5U1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a6b6603e-af3e-4bcb-a8c6-6768f13ad190"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(labels, pred_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92    200000\n",
            "           1       0.92      0.92      0.92    200000\n",
            "\n",
            "    accuracy                           0.92    400000\n",
            "   macro avg       0.92      0.92      0.92    400000\n",
            "weighted avg       0.92      0.92      0.92    400000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmIaZqQP7wxQ",
        "colab_type": "text"
      },
      "source": [
        "# DistilBert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDLqZquF7yTL",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/alexalex02/sentiment-analysis-distilbert-amazon-reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9wfAUs5AKtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "387852c8-cbca-4b6a-b3aa-7e610d02d28e"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBf4Ar0n5Jch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "#import eli5"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtRisiM08R_R",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxeAIaPl8GI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a3de3b98-43ca-4880-a8a1-dae07cfff482"
      },
      "source": [
        "path='/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv'\n",
        "train_val = pd.read_csv(path, index_col=0)\n",
        "train_val.reset_index(drop=True, inplace=True)\n",
        "print(train_val.info())\n",
        "display(train_val.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3600000 entries, 0 to 3599999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Dtype \n",
            "---  ------  ----- \n",
            " 0   review  object\n",
            " 1   label   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 54.9+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stuning even for the non-gamer: this sound tra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the best soundtrack ever to anything.: i'm rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazing!: this soundtrack is my favorite music...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>excellent soundtrack: i truly like this soundt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>remember, pull your jaw off the floor after he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  stuning even for the non-gamer: this sound tra...      1\n",
              "1  the best soundtrack ever to anything.: i'm rea...      1\n",
              "2  amazing!: this soundtrack is my favorite music...      1\n",
              "3  excellent soundtrack: i truly like this soundt...      1\n",
              "4  remember, pull your jaw off the floor after he...      1"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_1LpBK2Dqat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28381d3d-2d06-4ac7-cda6-f06271e1b7cd"
      },
      "source": [
        "train_val=train_val[:50000]\n",
        "train_val.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUOSE-er8OSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "614f7f6a-b536-4151-a256-54d6eb88b847"
      },
      "source": [
        "sns.countplot(train_val['label']);\n",
        "plt.title('Labels distribution');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW0ElEQVR4nO3dfbRddX3n8ffHBGTwEU1GhRCCSlV8AOUWH6dCRzG6qtgOOmFEUdHUDtR5qrOwroID1drark4VFDNOpKKCFUdNbRQZraIimhsH5anUFNEkahMTEFF8CH7nj7MvPdz8bu4Jyb73cvN+rXVW9v79fnvv78lK7uf+9t5nn1QVkiRNdp/ZLkCSNDcZEJKkJgNCktRkQEiSmgwISVKTASFJajIgdK+X5PNJXjPT207az81JntMt/2GS9+7pPof2fXuSR3bLFyb547247wuS/NHe2p/mFwNCc8bwD9l7s6p6a1VNGzqjhlNV3b+qbtrTupK8MsmXJu37dVV17p7uW/OTASHNUUkWznYN2rcZEJrzkhyU5JNJtia5pVteMmnYo5J8LcltST6R5CFD2z8tyZVJbk3yjSTHTXGcRyf5QpIfJflhkg/voqaXJ/lOkm1J3jSp781JPtAtH5DkA924W5OsS/KwJG8B/g1wXncK6bxufCU5Pcm3gG8NtT166BCLklye5MddvYd145Z1YxcO1fL5JK9J8jjgAuDp3fFu7frvdsoqyWuTbEiyPcmaJAcP9VWS1yX5Vvdezk+Sqf6OdO9nQOje4D7A+4DDgKXAHcB5k8a8Ang18AhgB/AOgCSHAH8H/DHwEOAPgI8mWdw4zrnAZ4CDgCXAO1vFJDkSeDfwcuBg4KHd+JZTgQcBh3bjXgfcUVVvAr4InNGdQjpjaJsXA08Fjpxiny/ral0EXA18cIpxd6mqG7pjf6U73oMb7+s3gT8BXsrg7/E7wCWThv0W8OvAk7pxz5vu2Lr3mncBkWR1ki1Jrh1x/EuTXJ/kuiQf6rs+7b6q2lZVH62qn1bVj4G3AM+eNOyiqrq2qn4C/BHw0iQLgFOAtVW1tqp+VVWXA+PACxqH+iWDEDq4qn5WVV9qjAE4CfhkVV1RVT/vjverKcb+kkEwPLqq7qyq9VV12zRv+U+qantV3TFF/98NHftNDGYFh06zz1G8DFhdVV/v9v3Gbt/Lhsa8rapurarvAn8PHL0Xjqs5at4FBHAhsHyUgUmOYPCf4JlV9XjgP/dYl+6hJAcmeU93Suc24ArgwV0ATNg4tPwdYD8Gv2EfBrykOyVya3dq5VkMfkOe7L8DAb7W/cLw6ilKOnj4eF0obZti7EXAZcAlSb6X5M+S7DfNW944an9V3Q5s72raUwcz+Lsb3vc24JChMT8YWv4pcP+9cFzNUfMuIKrqCgb/Ye6S5FFJPp1kfZIvJnls1/Va4PyquqXbdssMl6vR/DfgMcBTq+qBwG907cPnv4d/g17K4Df3HzL4YXpRVT146HW/qnrb5INU1Q+q6rVVdTDwu8C7Jp37n/D94eMlOZDBLGEnVfXLqvofVXUk8AwGp2heMdE9xfud7hHLw8e+P4NTZ98DftI1Hzg09uG7sd/vMQjUiX3fj8H72jzNdpqn5l1ATGEV8PtVdQyDc9Dv6tp/Dfi1JF9OclWSkWYe6tV+3YXdiddC4AEMrjvc2l18Prux3SlJjux+WJ8DXFpVdwIfAF6Y5HlJFnT7PK5xkZskLxlqv4XBD9TWqaNLgd9K8qwk+3fHa/5fSnJ8kid2s53bGATXxD7/GXjkSH8rd/eCoWOfC1xVVRuraiuDH+andO/11cCjhrb7Z2BJt13LxcCrkhyd5L7AW4GvVtXN96BGzQPzPiC637CeAXwkydXAe/iX0wsLgSOA44CTgf+VZKeLd5pRaxmEwcTrzcD/BP4VgxnBVcCnG9tdxOD04g+AA4DXA1TVRuBE4A+BrQxmFG+g/W//14GvJrkdWAP8p9bnD6rqOuB04EMMZhO3AJumeD8PZxAotwE3AF/oagX4K+CkDO7MescU27d8iEFIbgeOYXCdZcJru/e3DXg8cOVQ3+eA64AfJPlh4339XwbXUz7ava9HASt2oy7NM5mPXxjUXVT7ZFU9IckDgRuraqdzzkkuYPAb0vu69c8CZ1bVupmsV5Lmonk/g+juGPl2kpcAZOCorvvjDGYPJFnE4JTTHn9iVZLmg3kXEEkuBr4CPCbJpiSnMbh977Qk32AwxT6xG34ZsC3J9Qxu2XtDVU11N4ok7VPm5SkmSdKem3czCEnS3jGvHga2aNGiWrZs2WyXIUn3GuvXr/9hVbUePTO/AmLZsmWMj4/PdhmSdK+R5DtT9XmKSZLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1DSvPkm9p455w/tnuwTNQevf/orpB82A757zxNkuQXPQ0rOu6W3fziAkSU29zSCSrGbwBe1bquoJjf43MPiehok6HgcsrqrtSW4GfgzcCeyoqrG+6pQktfU5g7gQWD5VZ1W9vaqOrqqjgTcCX6iq7UNDju/6DQdJmgW9BURVXcHgS9VHcTJwcV+1SJJ236xfg0hyIIOZxkeHmgv4TJL1SVZOs/3KJONJxrdu3dpnqZK0T5n1gABeCHx50umlZ1XVU4DnA6cn+Y2pNq6qVVU1VlVjixc3v/NCknQPzIWAWMGk00tVtbn7cwvwMeDYWahLkvZpsxoQSR4EPBv4xFDb/ZI8YGIZOAG4dnYqlKR9V5+3uV4MHAcsSrIJOBvYD6CqLuiG/Tbwmar6ydCmDwM+lmSivg9V1af7qlOS1NZbQFTVySOMuZDB7bDDbTcBR/VTlSRpVHPhGoQkaQ4yICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ19RYQSVYn2ZLk2in6j0vyoyRXd6+zhvqWJ7kxyYYkZ/ZVoyRpan3OIC4Elk8z5otVdXT3OgcgyQLgfOD5wJHAyUmO7LFOSVJDbwFRVVcA2+/BpscCG6rqpqr6BXAJcOJeLU6SNK3Zvgbx9CTfSPKpJI/v2g4BNg6N2dS1NSVZmWQ8yfjWrVv7rFWS9imzGRBfBw6rqqOAdwIfvyc7qapVVTVWVWOLFy/eqwVK0r5s1gKiqm6rqtu75bXAfkkWAZuBQ4eGLunaJEkzaNYCIsnDk6RbPrarZRuwDjgiyeFJ9gdWAGtmq05J2lct7GvHSS4GjgMWJdkEnA3sB1BVFwAnAb+XZAdwB7CiqgrYkeQM4DJgAbC6qq7rq05JUltvAVFVJ0/Tfx5w3hR9a4G1fdQlSRrNbN/FJEmaowwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU29BUSS1Um2JLl2iv6XJflmkmuSXJnkqKG+m7v2q5OM91WjJGlqfc4gLgSW76L/28Czq+qJwLnAqkn9x1fV0VU11lN9kqRdWNjXjqvqiiTLdtF/5dDqVcCSvmqRJO2+uXIN4jTgU0PrBXwmyfokK3e1YZKVScaTjG/durXXIiVpX9LbDGJUSY5nEBDPGmp+VlVtTvKvgcuT/ENVXdHavqpW0Z2eGhsbq94LlqR9xKzOIJI8CXgvcGJVbZtor6rN3Z9bgI8Bx85OhZK075q1gEiyFPg/wMur6h+H2u+X5AETy8AJQPNOKElSf3o7xZTkYuA4YFGSTcDZwH4AVXUBcBbwUOBdSQB2dHcsPQz4WNe2EPhQVX26rzolSW193sV08jT9rwFe02i/CThq5y0kSTNprtzFJEmaYwwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUtNIAZHks6O0SZLmj11+J3WSA4ADgUVJDgLSdT0QOKTn2iRJs2i6GcTvAuuBx3Z/Trw+AZw33c6TrE6yJcm1U/QnyTuSbEjyzSRPGeo7Ncm3utepo74hSdLescuAqKq/qqrDgT+oqkdW1eHd66iqmjYggAuB5bvofz5wRPdaCbwbIMlDgLOBpwLHAmd3MxhJ0gzZ5SmmCVX1ziTPAJYNb1NV759muyuSLNvFkBOB91dVAVcleXCSRwDHAZdX1XaAJJczCJqLR6lXkrTnRgqIJBcBjwKuBu7smgvYZUCM4BBg49D6pq5tqvZWbSsZzD5YunTpHpYjSZowUkAAY8CR3W/6c0pVrQJWAYyNjc25+iTp3mrUz0FcCzy8h+NvBg4dWl/StU3VLkmaIaMGxCLg+iSXJVkz8doLx18DvKK7m+lpwI+q6vvAZcAJSQ7qLk6f0LVJkmbIqKeY3nxPdp7kYgYXnBcl2cTgzqT9AKrqAmAt8AJgA/BT4FVd3/Yk5wLrul2dM3HBWpI0M0a9i+kL92TnVXXyNP0FnD5F32pg9T05riRpz416F9OPGdy1BLA/g1nAT6rqgX0VJkmaXaPOIB4wsZwkDD6/8LS+ipIkzb7dfpprDXwceF4P9UiS5ohRTzH9ztDqfRh8LuJnvVQkSZoTRr2L6YVDyzuAmxmcZpIkzVOjXoN4Vd+FSJLmllG/MGhJko91j+7ekuSjSZb0XZwkafaMepH6fQw+9Xxw9/rbrk2SNE+NGhCLq+p9VbWje10ILO6xLknSLBs1ILYlOSXJgu51CrCtz8IkSbNr1IB4NfBS4AfA94GTgFf2VJMkaQ4Y9TbXc4BTq+oWuOsrQf+cQXBIkuahUWcQT5oIBxg8bRV4cj8lSZLmglED4j7d9zIAd80gRp19SJLuhUb9If8XwFeSfKRbfwnwln5KkiTNBaN+kvr9ScaB3+yafqeqru+vLEnSbBv5NFEXCIaCJO0jdvtx35KkfYMBIUlq6jUgkixPcmOSDUnObPT/ZZKru9c/Jrl1qO/Oob41fdYpSdpZb7eqJlkAnA88F9gErEuyZvjidlX9l6Hxv8/dP1txR1Ud3Vd9kqRd63MGcSywoapuqqpfAJew6y8ZOhm4uMd6JEm7oc+AOATYOLS+qWvbSZLDgMOBzw01H5BkPMlVSV7cX5mSpJa58mnoFcClVXXnUNthVbU5ySOBzyW5pqr+afKGSVYCKwGWLl06M9VK0j6gzxnEZuDQofUlXVvLCiadXqqqzd2fNwGfZ4pnP1XVqqoaq6qxxYv9igpJ2lv6DIh1wBFJDk+yP4MQ2OlupCSPBQ4CvjLUdlCS+3bLi4Bn4of0JGlG9XaKqap2JDkDuAxYAKyuquuSnAOMV9VEWKwALqmqGtr8ccB7kvyKQYi9zUd7SNLM6vUaRFWtBdZOajtr0vqbG9tdCTyxz9okSbvmJ6klSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqSmXgMiyfIkNybZkOTMRv8rk2xNcnX3es1Q36lJvtW9Tu2zTknSzhb2teMkC4DzgecCm4B1SdZU1fWThn64qs6YtO1DgLOBMaCA9d22t/RVryTp7vqcQRwLbKiqm6rqF8AlwIkjbvs84PKq2t6FwuXA8p7qlCQ19BkQhwAbh9Y3dW2T/bsk30xyaZJDd3NbkqxMMp5kfOvWrXujbkkSs3+R+m+BZVX1JAazhL/e3R1U1aqqGquqscWLF+/1AiVpX9VnQGwGDh1aX9K13aWqtlXVz7vV9wLHjLqtJKlffQbEOuCIJIcn2R9YAawZHpDkEUOrLwJu6JYvA05IclCSg4ATujZJ0gzp7S6mqtqR5AwGP9gXAKur6rok5wDjVbUGeH2SFwE7gO3AK7tttyc5l0HIAJxTVdv7qlWStLPeAgKgqtYCaye1nTW0/EbgjVNsuxpY3Wd9kqSpzfZFaknSHGVASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWrqNSCSLE9yY5INSc5s9P/XJNcn+WaSzyY5bKjvziRXd681fdYpSdrZwr52nGQBcD7wXGATsC7Jmqq6fmjY/wPGquqnSX4P+DPg33d9d1TV0X3VJ0natT5nEMcCG6rqpqr6BXAJcOLwgKr6+6r6abd6FbCkx3okSbuhz4A4BNg4tL6pa5vKacCnhtYPSDKe5KokL55qoyQru3HjW7du3bOKJUl36e0U0+5IcgowBjx7qPmwqtqc5JHA55JcU1X/NHnbqloFrAIYGxurGSlYkvYBfc4gNgOHDq0v6druJslzgDcBL6qqn0+0V9Xm7s+bgM8DT+6xVknSJH0GxDrgiCSHJ9kfWAHc7W6kJE8G3sMgHLYMtR+U5L7d8iLgmcDwxW1JUs96O8VUVTuSnAFcBiwAVlfVdUnOAcarag3wduD+wEeSAHy3ql4EPA54T5JfMQixt026+0mS1LNer0FU1Vpg7aS2s4aWnzPFdlcCT+yzNknSrvlJaklSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqanXgEiyPMmNSTYkObPRf98kH+76v5pk2VDfG7v2G5M8r886JUk76y0gkiwAzgeeDxwJnJzkyEnDTgNuqapHA38J/Gm37ZHACuDxwHLgXd3+JEkzpM8ZxLHAhqq6qap+AVwCnDhpzInAX3fLlwL/Nkm69kuq6udV9W1gQ7c/SdIMWdjjvg8BNg6tbwKeOtWYqtqR5EfAQ7v2qyZte0jrIElWAiu71duT3LjnpQtYBPxwtouYC/Lnp852CdqZ/z4nnJ093cNhU3X0GRAzoqpWAatmu475Jsl4VY3Ndh1Si/8+Z0afp5g2A4cOrS/p2ppjkiwEHgRsG3FbSVKP+gyIdcARSQ5Psj+Di85rJo1ZA0zM308CPldV1bWv6O5yOhw4Avhaj7VKkibp7RRTd03hDOAyYAGwuqquS3IOMF5Va4D/DVyUZAOwnUGI0I37G+B6YAdwelXd2VetavK0neYy/33OgAx+YZck6e78JLUkqcmAkCQ1GRDayXSPSJFmS5LVSbYkuXa2a9kXGBC6mxEfkSLNlgsZPH5HM8CA0GSjPCJFmhVVdQWDOx41AwwITdZ6RErzMSeS5jcDQpLUZEBoMh9zIgkwILSzUR6RImkfYEDobqpqBzDxiJQbgL+pqutmtyppIMnFwFeAxyTZlOS02a5pPvNRG5KkJmcQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiCkeyjJ7dP0L9vdp44muTDJSXtWmbR3GBCSpCYDQtpDSe6f5LNJvp7kmiTDT79dmOSDSW5IcmmSA7ttjknyhSTrk1yW5BGzVL40JQNC2nM/A367qp4CHA/8RZJ0fY8B3lVVjwNuA/5jkv2AdwInVdUxwGrgLbNQt7RLC2e7AGkeCPDWJL8B/IrB49Ef1vVtrKovd8sfAF4PfBp4AnB5lyMLgO/PaMXSCAwIac+9DFgMHFNVv0xyM3BA1zf5WTbFIFCuq6qnz1yJ0u7zFJO05x4EbOnC4XjgsKG+pUkmguA/AF8CbgQWT7Qn2S/J42e0YmkEBoS05z4IjCW5BngF8A9DfTcCpye5ATgIeHf3Va4nAX+a5BvA1cAzZrhmaVo+zVWS1OQMQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNf1/OjOTyUyTDLYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0knsx438OQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "0a89761b-0b56-45a2-ef54-21bd48239fce"
      },
      "source": [
        "train_val['len'] = train_val['review'].apply(lambda x: len(x.split()))\n",
        "sns.distplot(train_val['len']);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEiH2Ans8ONs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "fcf9f52a-9777-4539-ac4a-1d3baae019df"
      },
      "source": [
        "neg_mean_len = train_val.groupby('label')['len'].mean().values[0]\n",
        "pos_mean_len = train_val.groupby('label')['len'].mean().values[1]\n",
        "\n",
        "print(f\"Negative mean length: {neg_mean_len:.2f}\")\n",
        "print(f\"Positive mean length: {pos_mean_len:.2f}\")\n",
        "print(f\"Mean Difference: {neg_mean_len-pos_mean_len:.2f}\")\n",
        "ax = sns.catplot(x='label', y='len', data=train_val, kind='box')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative mean length: 81.50\n",
            "Positive mean length: 75.46\n",
            "Mean Difference: 6.04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4qph_-AAb7q",
        "colab_type": "text"
      },
      "source": [
        "We can see that negative sentences are longer on average. To say how significant this difference, we use permutation testing and calculate p-value.\n",
        "\n",
        "First, we define a function to generate a permutation sample from two arrays. Then, we generate permutation replicates, which are a single statistic computed from permutation sample. Last, we compute the probability of getting at least 5.91 difference in mean under the hypothesis that the distributions of words are identical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JItyl0Kg8OLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_array = train_val[train_val['label']==0]['len'].values\n",
        "pos_array = train_val[train_val['label']==1]['len'].values\n",
        "mean_diff = neg_mean_len - pos_mean_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak641N6U8OIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def permutation_sample(data1, data2):\n",
        "    # Permute the concatenated array: permuted_data\n",
        "    data = np.concatenate((data1,data2))\n",
        "    permuted_data = np.random.permutation(data)\n",
        "\n",
        "    # Split the permuted array into two: perm_sample_1, perm_sample_2\n",
        "    perm_sample_1 = permuted_data[:len(data1)]\n",
        "    perm_sample_2 = permuted_data[len(data1):]\n",
        "\n",
        "    return perm_sample_1, perm_sample_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6bLBErPAxVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_perm_reps(data_1, data_2, size=1):\n",
        "\n",
        "    perm_replicates = np.empty(size)\n",
        "\n",
        "    for i in range(size):\n",
        "        # Generate permutation sample\n",
        "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
        "\n",
        "        # Compute the test statistic\n",
        "        perm_replicates[i] = np.mean(perm_sample_1) - np.mean(perm_sample_2)\n",
        "\n",
        "    return perm_replicates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpB2tvOYA01k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "perm_replicates = draw_perm_reps(neg_array, pos_array,\n",
        "                                 size=10000)\n",
        "\n",
        "# Compute p-value: p\n",
        "p = np.sum(perm_replicates >= mean_diff) / len(perm_replicates)\n",
        "\n",
        "print(f'p-value = {p}')\n",
        "# p-value = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EcDkSV2A4_6",
        "colab_type": "text"
      },
      "source": [
        "The p-value tells us that the null hypothesis is false."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lmCJt4jA-nH",
        "colab_type": "text"
      },
      "source": [
        "## Baseline - LogReg (Tf-Idf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9nf3fKFA3Om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def prediction(model, X_train, y_train, X_valid, y_valid):\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_valid)\n",
        "    acc = accuracy_score(y_valid, pred)\n",
        "    print(classification_report(y_valid, pred))\n",
        "    f1 = f1_score(y_valid, pred)\n",
        "    conf = confusion_matrix(y_valid, pred)\n",
        "    joblib.dump(model, f\"model_acc_{acc:.5f}.pkl\")\n",
        "    return model, acc, f1, conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajV8DJr7BBRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer = TfidfVectorizer(stop_words='english', ngram_range=(1, 3), \n",
        "                              lowercase=True, max_features=100000)\n",
        "X = transformer.fit_transform(train_val['review'])\n",
        "y = train_val.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUdnJUNWBDN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5c753f15-0f1b-49ce-8f5e-5e45f192f1d4"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, \n",
        "                                                      random_state=42, stratify=y)\n",
        "print(X_train.shape, y_train.shape)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 100000) (40000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<40000x100000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1709950 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXDQa3EKCAch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "fa65a66d-35ef-4f57-ec1f-37a6cf7eaad8"
      },
      "source": [
        "model = LogisticRegression(C=1, random_state=42, n_jobs=-1)\n",
        "fit_model, acc, f1, conf = prediction(model, X_train, y_train, X_valid, y_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88      4899\n",
            "           1       0.88      0.89      0.89      5101\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82dlTB7IBEoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5fecf435-e8c6-45bf-95f5-85d738386444"
      },
      "source": [
        "print(f\"Accuracy: {acc:.5f}\")\n",
        "print(f\"F1_Score: {f1:.5f}\")\n",
        "print(f\"Confusion Matrix: {conf}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.88420\n",
            "F1_Score: 0.88729\n",
            "Confusion Matrix: [[4284  615]\n",
            " [ 543 4558]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r3N7J6vBIbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804
        },
        "outputId": "ab899a1c-fd33-41f2-ae42-8616751e640d"
      },
      "source": [
        "eli5.show_weights(estimator=fit_model, \n",
        "                  feature_names= list(transformer.get_feature_names()),\n",
        "                    top=(20,20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "        \n",
              "            \n",
              "                \n",
              "                \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=1\n",
              "    \n",
              "</b>\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
              "                    Weight<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +12.115\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        great\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.53%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +9.180\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        excellent\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 84.49%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +8.426\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        best\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 85.67%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +7.523\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        love\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.19%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +7.140\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        perfect\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 86.65%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +6.802\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        awesome\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.73%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +6.031\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        amazing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 87.91%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.904\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        wonderful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.22%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.689\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        favorite\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 88.75%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.327\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        easy\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.07%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.111\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        good\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.21%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +5.020\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        loved\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.57%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.778\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        enjoyed\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.79%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.634\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        highly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.83%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.609\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        fantastic\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 89.96%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.527\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        loves\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 90.07%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +4.455\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        fun\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 90.98%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.886\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        works\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.05%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.840\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        beautiful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.10%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +3.812\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        classic\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 91.10%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 49954 more positive &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.98%); border: none;\">\n",
              "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
              "                    <i>&hellip; 49570 more negative &hellip;</i>\n",
              "                </td>\n",
              "            </tr>\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.98%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -3.885\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        dull\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.96%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -3.895\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        ok\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.77%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -4.016\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        didn\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.35%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -4.274\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        worse\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 90.32%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -4.297\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        return\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 89.77%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -4.650\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        instead\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 89.73%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -4.678\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        poorly\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.89%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -5.234\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        unfortunately\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.81%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -5.286\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        awful\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 88.42%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -5.550\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        money\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.23%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -6.386\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointment\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 87.03%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -6.523\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        terrible\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.60%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -6.837\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        bad\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 86.22%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -7.116\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        horrible\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.75%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -7.463\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointing\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.43%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -7.702\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        waste\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.04%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -8.003\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        poor\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.25%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -8.609\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        disappointed\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 84.01%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -8.800\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        worst\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 82.56%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -9.961\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        boring\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "            \n",
              "        \n",
              "\n",
              "        \n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7AGvubFCTz4",
        "colab_type": "text"
      },
      "source": [
        "## DistilBert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG4GDemHCWCG",
        "colab_type": "text"
      },
      "source": [
        "Here we'll use DistilBert from transformers. And catalyst for running experiment.\n",
        "\n",
        "First, we install torch nightly for Mixed-precision training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWGXDDo9CPfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --pre torch==1.7.0.dev20200701+cu101 torchvision==0.8.0.dev20200701+cu101 -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3TWYMGuFWiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFLt4nFoFfby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install catalyst"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7howCmGGrzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDdkaqcnCgvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['WANDB_SILENT'] = 'True'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
        "\n",
        "from typing import Mapping, List\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModel\n",
        "\n",
        "from catalyst.dl import SupervisedRunner\n",
        "from catalyst.dl.callbacks import AccuracyCallback, OptimizerCallback, CheckpointCallback,WandbLogger\n",
        "from catalyst.utils import set_global_seed, prepare_cudnn\n",
        "from catalyst.contrib.nn import RAdam, Lookahead, OneCycleLRWithWarmup\n",
        "#import wandb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIgpkjqZIFnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install pytorch_lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpgQXrXQHT5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pytorch_lightning as pl\n",
        "#from pytorch_lightning.loggers import WandbLogger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdL7T_3pCgsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Config setup\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "LOG_DIR = \"./amazon\" \n",
        "NUM_EPOCHS = 2 \n",
        "LEARNING_RATE = 5e-5\n",
        "MAX_SEQ_LENGTH = 512\n",
        "BATCH_SIZE = 32\n",
        "WEIGHT_DECAY = 1e-3\n",
        "ACCUMULATION_STEPS = 3\n",
        "SEED = 42\n",
        "FP_16 = dict(opt_level=\"O1\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TYWW9bYCgpk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For reproducibility\n",
        "set_global_seed(SEED)\n",
        "prepare_cudnn(deterministic=True, benchmark=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1iMyVoaCr9q",
        "colab_type": "text"
      },
      "source": [
        "We'll create dataset. Instantiate tokenizer. Then, we convert tokens to integers, add special tokens, use padding to max_length. Return 'input_ids', 'attention_mask', 'targets'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5km0_9NcCgnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReviewDataset(Dataset):\n",
        "\n",
        "    \n",
        "    def __init__(self,\n",
        "                 sentences: List[str],\n",
        "                 labels: List[str] = None,\n",
        "                 max_seq_length: int = MAX_SEQ_LENGTH,\n",
        "                 model_name: str = 'distilbert-base-uncased'):\n",
        "\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        \n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.sentences)\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index) -> Mapping[str, torch.Tensor]:\n",
        "\n",
        "        sentence = self.sentences[index]\n",
        "        encoded = self.tokenizer.encode_plus(sentence, add_special_tokens=True, \n",
        "                                        pad_to_max_length=True, max_length=self.max_seq_length, \n",
        "                                        return_tensors=\"pt\",)\n",
        "        \n",
        "        output = {\n",
        "            'input_ids': encoded['input_ids'],\n",
        "            'attention_mask': encoded['attention_mask']\n",
        "        }\n",
        "        \n",
        "        output['targets'] = torch.tensor(self.labels[index], dtype=torch.long)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWEAxXKRCxZ_",
        "colab_type": "text"
      },
      "source": [
        "Making train_test_split, defining datasets and loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM9rhnmSCwCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2682c502-23fd-4b40-fa73-c014b1bb2bcd"
      },
      "source": [
        "df_train, df_valid = train_test_split(\n",
        "            train_val,\n",
        "            test_size=0.2,\n",
        "            random_state=42,\n",
        "            stratify = train_val.label.values\n",
        "        )\n",
        "print(df_train.shape, df_valid.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000, 2) (10000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXj9zNuECwAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = ReviewDataset(\n",
        "    sentences=df_train['review'].values.tolist(),\n",
        "    labels=df_train['label'].values,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    model_name=MODEL_NAME\n",
        ")\n",
        "\n",
        "valid_dataset = ReviewDataset(\n",
        "    sentences=df_valid['review'].values.tolist(),\n",
        "    labels=df_valid['label'].values,\n",
        "    max_seq_length=MAX_SEQ_LENGTH,\n",
        "    model_name=MODEL_NAME\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2ZWnw0kC5za",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_val_loaders = {\n",
        "    \"train\": DataLoader(dataset=train_dataset,\n",
        "                        batch_size=BATCH_SIZE, \n",
        "                        shuffle=True, num_workers=2, pin_memory=True),\n",
        "    \"valid\": DataLoader(dataset=valid_dataset,\n",
        "                        batch_size=BATCH_SIZE, \n",
        "                        shuffle=False, num_workers=2, pin_memory=True)    \n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5ji214vC5wJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "499f233b-2fc8-4e44-b48d-f31f2f849ae8"
      },
      "source": [
        "print(df_valid.review.values[50])\n",
        "valid_dataset[50]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "incredible: this cd is undoubtedly the most impressive cd i have heard in years. aiken truly delivers on his debut album. a great mixture of ballads and pop/rock songs make this cd a must-have. aiken's voice is crisp and clear, flawless and fresh. he certainly has proven he can sing anything given to him.it's great to finally have someone in this era who can have a positive impact on the young and old. he is truly an american idol. i don't know who said you have to promote \"sex, violence, and more sex\" to be a successful recording artist, but aiken has shown you can make it as a respectful person. cudos to aiken for staying a role model for all!!! i look forward to his other projects.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " 'input_ids': tensor([[  101,  9788,  1024,  2023,  3729,  2003, 17319,  1996,  2087,  8052,\n",
              "           3729,  1045,  2031,  2657,  1999,  2086,  1012,  9932,  7520,  5621,\n",
              "          18058,  2006,  2010,  2834,  2201,  1012,  1037,  2307,  8150,  1997,\n",
              "          18456,  1998,  3769,  1013,  2600,  2774,  2191,  2023,  3729,  1037,\n",
              "           2442,  1011,  2031,  1012,  9932,  7520,  1005,  1055,  2376,  2003,\n",
              "          15594,  1998,  3154,  1010, 27503,  1998,  4840,  1012,  2002,  5121,\n",
              "           2038, 10003,  2002,  2064,  6170,  2505,  2445,  2000,  2032,  1012,\n",
              "           2009,  1005,  1055,  2307,  2000,  2633,  2031,  2619,  1999,  2023,\n",
              "           3690,  2040,  2064,  2031,  1037,  3893,  4254,  2006,  1996,  2402,\n",
              "           1998,  2214,  1012,  2002,  2003,  5621,  2019,  2137, 10282,  1012,\n",
              "           1045,  2123,  1005,  1056,  2113,  2040,  2056,  2017,  2031,  2000,\n",
              "           5326,  1000,  3348,  1010,  4808,  1010,  1998,  2062,  3348,  1000,\n",
              "           2000,  2022,  1037,  3144,  3405,  3063,  1010,  2021,  9932,  7520,\n",
              "           2038,  3491,  2017,  2064,  2191,  2009,  2004,  1037, 26438,  2711,\n",
              "           1012, 12731, 12269,  2000,  9932,  7520,  2005,  6595,  1037,  2535,\n",
              "           2944,  2005,  2035,   999,   999,   999,  1045,  2298,  2830,  2000,\n",
              "           2010,  2060,  3934,  1012,   102,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0]]),\n",
              " 'targets': tensor(1)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toe92z_kC5s9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DistilBert(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_model_name: str = MODEL_NAME, num_classes: int = 2):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        config = AutoConfig.from_pretrained(\n",
        "             pretrained_model_name)\n",
        "\n",
        "        self.distilbert = AutoModel.from_pretrained(pretrained_model_name,\n",
        "                                                    config=config)\n",
        "        self.pre_classifier = nn.Linear(config.dim, config.dim)\n",
        "        self.classifier = nn.Linear(config.dim, num_classes)\n",
        "        self.dropout = nn.Dropout(config.seq_classif_dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, head_mask=None):\n",
        "\n",
        "        assert attention_mask is not None, \"attention mask is none\"\n",
        "        distilbert_output = self.distilbert(input_ids=input_ids,\n",
        "                                            attention_mask=attention_mask,\n",
        "                                            head_mask=head_mask)\n",
        "        hidden_state = distilbert_output[0]  # [BATCH_SIZE=32, MAX_SEQ_LENGTH = 512, DIM = 768]\n",
        "        pooled_output = hidden_state[:, 0]  # [32, 768]\n",
        "        pooled_output = self.pre_classifier(pooled_output)  # [32, 768]\n",
        "        pooled_output = F.relu(pooled_output)  # [32, 768]\n",
        "        pooled_output = self.dropout(pooled_output)  # [32, 768]\n",
        "        logits = self.classifier(pooled_output)  # [32, 2]\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZsnHgFTC5p0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DistilBert()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLDGbr6ADD1O",
        "colab_type": "text"
      },
      "source": [
        "Training setup:\n",
        "\n",
        "We'll apply weight decay for all parameters except 'bias' and 'LayerNorm'\n",
        "Lookahead optimizer(improves the learning stability and lowers the variance of its inner optimizer)\n",
        "OneCycleLRWithWarmup with 0 warmup steps, cosine annealing from 5e-5 to 1e-8.\n",
        "Gradient accumulation for large batch training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uk474IrDDZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_optim = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o5PogjTCv8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "base_optimizer = RAdam([\n",
        "    {'params': [p for n,p in param_optim if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': WEIGHT_DECAY}, \n",
        "    {'params': [p for n,p in param_optim if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': 0.0}\n",
        "])\n",
        "optimizer = Lookahead(base_optimizer)\n",
        "scheduler = OneCycleLRWithWarmup(\n",
        "    optimizer, \n",
        "    num_steps=NUM_EPOCHS, \n",
        "    lr_range=(LEARNING_RATE, 1e-8),\n",
        "    init_lr=LEARNING_RATE,\n",
        "    warmup_steps=0,\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdVgk0u1Cv6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e24ee63c-4883-4a4b-e029-089ef17cff48"
      },
      "source": [
        "runner = SupervisedRunner(\n",
        "    input_key=(\n",
        "        \"input_ids\",\n",
        "        \"attention_mask\"\n",
        "    )\n",
        ")\n",
        "# model training\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    loaders=train_val_loaders,\n",
        "    callbacks=[\n",
        "        AccuracyCallback(num_classes=2),\n",
        "        OptimizerCallback(accumulation_steps=ACCUMULATION_STEPS),\n",
        "        WandbLogger(name=\"Name\", project=\"sentiment-analysis\"),\n",
        "    ],\n",
        "    fp16=FP_16,\n",
        "    logdir=LOG_DIR,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    verbose=True\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fb9a7e486652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOG_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/dl/runner/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, stage_kwargs, checkpoint_data, fp16, distributed, check, overfit, timeit, load_best_on_end, initial_seed, state_kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     def infer(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     ):\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_exception_handler_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \"\"\"\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     def _batch2device(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/callbacks/exception.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_exception_reraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mcatalyst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExceptionCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_stage_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             utils.set_global_seed(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \"\"\"\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     def _batch2device(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/catalyst/contrib/dl/callbacks/wandb_logger.py\u001b[0m in \u001b[0;36mon_stage_start\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         wandb.watch(\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         )\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/__init__.py\u001b[0m in \u001b[0;36mwatch\u001b[0;34m(models, criterion, log, log_freq, idx)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         raise ValueError(\n\u001b[0;32m--> 156\u001b[0;31m             \"You must call `wandb.init` before calling watch\")\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0min_jupyter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You must call `wandb.init` before calling watch"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DEk4C6mDO3X",
        "colab_type": "text"
      },
      "source": [
        "After two epochs, we’ll able to reach 96.22% accuracy, which is on 6% higher than logistic regression.\n",
        "\n",
        "To improve our result even more, we can continue fine-tuning with frozen encoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYXpLfM6DQty",
        "colab_type": "text"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tSFg5DADNAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "def prediction(model, sentence: str, max_len: int = 512, device = 'cpu'):\n",
        "    x_encoded = tokenizer.encode_plus(sentence, add_special_tokens=True, pad_to_max_length=True, max_length=max_len, return_tensors=\"pt\",).to(device)\n",
        "    logits = model(x_encoded['input_ids'], x_encoded['attention_mask'])\n",
        "    probabilities = F.softmax(logits.detach(), dim=1)\n",
        "    output = probabilities.max(axis=1)\n",
        "    print(sentence)\n",
        "    print(f\"Class: {['Negative' if output.indices[0] == 0 else 'Positive'][0]}, Probability: {output.values[0]:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxiLKNiSDM96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction(plain_model, df_valid['sentences'].values[20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohU9GkU2DM7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUtZ94MqDM4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}