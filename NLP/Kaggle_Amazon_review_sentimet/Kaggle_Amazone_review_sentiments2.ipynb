{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kaggle_Amazone_review_sentiments.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAJddn9lp0Tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import bz2\n",
        "import gc\n",
        "import chardet\n",
        "import re\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVC4bZHGrTnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = bz2.BZ2File('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train.ft.txt.bz2')\n",
        "test_file = bz2.BZ2File('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test.ft.txt.bz2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkELqPpYz5EV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d768abc-4346-46ae-a7cf-7a52ff513e88"
      },
      "source": [
        "train_file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bz2.BZ2File at 0x7fb4b8afbc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXbztI3WyMHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_lines = train_file.readlines()\n",
        "test_file_lines = test_file.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMkf0ynOrj6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
        "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6G7l3p_0DVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "86b49516-6b50-4e4e-c679-34287e420761"
      },
      "source": [
        "train_file_lines[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__label__2 Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n',\n",
              " \"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
              " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n',\n",
              " \"__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\\n\",\n",
              " \"__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROw81W0BrkDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file_lines]\n",
        "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file_lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXyJYGoVrkGR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "029cbff0-2ec0-4e77-f53d-1d9b511131d4"
      },
      "source": [
        "train_labels[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9VCj3ze0K3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a27d647b-dde0-43ac-e8f0-e4c448cd192a"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuning even for the non-gamer: this sound track was beautiful! it paints the senery in your mind so well i would recomend it even to people who hate vid. game music! i have played the game chrono cross but out of all of the games i have ever played it has the best music! it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. it would impress anyone who cares to listen! ^_^',\n",
              " \"the best soundtrack ever to anything.: i'm reading a lot of reviews saying that this is the best 'game soundtrack' and i figured that i'd write a review to disagree a bit. this in my opinino is yasunori mitsuda's ultimate masterpiece. the music is timeless and i'm been listening to it for years now and its beauty simply refuses to fade.the price tag on this is pretty staggering i must say, but if you are going to buy any cd for this much money, this is the only one that i feel would be worth every penny.\",\n",
              " 'amazing!: this soundtrack is my favorite music of all time, hands down. the intense sadness of \"prisoners of fate\" (which means all the more if you\\'ve played the game) and the hope in \"a distant promise\" and \"girl who stole the star\" have been an important inspiration to me personally throughout my teen years. the higher energy tracks like \"chrono cross ~ time\\'s scar~\", \"time of the dreamwatch\", and \"chronomantique\" (indefinably remeniscent of chrono trigger) are all absolutely superb as well.this soundtrack is amazing music, probably the best of this composer\\'s work (i haven\\'t heard the xenogears soundtrack, so i can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.i wish i could give it 6 stars.',\n",
              " \"excellent soundtrack: i truly like this soundtrack and i enjoy video game music. i have played this game and most of the music on here i enjoy and it's truly relaxing and peaceful.on disk one. my favorites are scars of time, between life and death, forest of illusion, fortress of ancient dragons, lost fragment, and drowned valley.disk two: the draggons, galdorb - home, chronomantique, prisoners of fate, gale, and my girlfriend likes zelbessdisk three: the best of the three. garden of god, chronopolis, fates, jellyfish sea, burning orphange, dragon's prayer, tower of stars, dragon god, and radical dreamers - unstealable jewel.overall, this is a excellent soundtrack and should be brought by those that like video game music.xander cross\",\n",
              " \"remember, pull your jaw off the floor after hearing it: if you've played the game, you know how divine the music is! every single song tells a story of the game, it's that good! the greatest songs are without a doubt, chrono cross: time's scar, magical dreamers: the wind, the stars, and the sea and radical dreamers: unstolen jewel. (translation varies) this music is perfect if you ask me, the best it can be. yasunori mitsuda just poured his heart on and wrote it down on paper.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op-m_QDL0OHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_sentences)):\n",
        "    train_sentences[i] = re.sub('\\d','0',train_sentences[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCrNx4I0XRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "93c27f2f-6a64-42ca-c675-68caeb5b0534"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stuning even for the non-gamer: this sound track was beautiful! it paints the senery in your mind so well i would recomend it even to people who hate vid. game music! i have played the game chrono cross but out of all of the games i have ever played it has the best music! it backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. it would impress anyone who cares to listen! ^_^',\n",
              " \"the best soundtrack ever to anything.: i'm reading a lot of reviews saying that this is the best 'game soundtrack' and i figured that i'd write a review to disagree a bit. this in my opinino is yasunori mitsuda's ultimate masterpiece. the music is timeless and i'm been listening to it for years now and its beauty simply refuses to fade.the price tag on this is pretty staggering i must say, but if you are going to buy any cd for this much money, this is the only one that i feel would be worth every penny.\",\n",
              " 'amazing!: this soundtrack is my favorite music of all time, hands down. the intense sadness of \"prisoners of fate\" (which means all the more if you\\'ve played the game) and the hope in \"a distant promise\" and \"girl who stole the star\" have been an important inspiration to me personally throughout my teen years. the higher energy tracks like \"chrono cross ~ time\\'s scar~\", \"time of the dreamwatch\", and \"chronomantique\" (indefinably remeniscent of chrono trigger) are all absolutely superb as well.this soundtrack is amazing music, probably the best of this composer\\'s work (i haven\\'t heard the xenogears soundtrack, so i can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.i wish i could give it 0 stars.',\n",
              " \"excellent soundtrack: i truly like this soundtrack and i enjoy video game music. i have played this game and most of the music on here i enjoy and it's truly relaxing and peaceful.on disk one. my favorites are scars of time, between life and death, forest of illusion, fortress of ancient dragons, lost fragment, and drowned valley.disk two: the draggons, galdorb - home, chronomantique, prisoners of fate, gale, and my girlfriend likes zelbessdisk three: the best of the three. garden of god, chronopolis, fates, jellyfish sea, burning orphange, dragon's prayer, tower of stars, dragon god, and radical dreamers - unstealable jewel.overall, this is a excellent soundtrack and should be brought by those that like video game music.xander cross\",\n",
              " \"remember, pull your jaw off the floor after hearing it: if you've played the game, you know how divine the music is! every single song tells a story of the game, it's that good! the greatest songs are without a doubt, chrono cross: time's scar, magical dreamers: the wind, the stars, and the sea and radical dreamers: unstolen jewel. (translation varies) this music is perfect if you ask me, the best it can be. yasunori mitsuda just poured his heart on and wrote it down on paper.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa9nxicQ0kKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1482e490-34aa-4f55-b16f-eaed38489953"
      },
      "source": [
        "print(len(train_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3600000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9oE82Ih0gZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file_lines]\n",
        "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file_lines]\n",
        "\n",
        "for i in range(len(test_sentences)):\n",
        "    test_sentences[i] = re.sub('\\d','0',test_sentences[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62-5qitp0rHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44c33299-7715-4d31-8a23-3fdafa7c6247"
      },
      "source": [
        "print(len(test_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPf8LC5x0svY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(train_sentences)):\n",
        "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
        "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n",
        "        \n",
        "for i in range(len(test_sentences)):\n",
        "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
        "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLtxAAwq0z_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del train_file_lines, test_file_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVAsL5oT05ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b16dfc74-48e9-44fa-84b6-33c91c14944c"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "397"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIYScaNu1Sfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences\n",
        "train_labels\n",
        "test_sentences\n",
        "test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU9Is0Kh4xBW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1212d493-94dd-4295-b98b-ac00782157ba"
      },
      "source": [
        "train_set=pd.concat([pd.DataFrame(train_sentences),pd.DataFrame(train_labels)],axis=1)\n",
        "train_set.columns=['review','label']\n",
        "train_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>stuning even for the non-gamer: this sound tra...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the best soundtrack ever to anything.: i'm rea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>amazing!: this soundtrack is my favorite music...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>excellent soundtrack: i truly like this soundt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>remember, pull your jaw off the floor after he...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  stuning even for the non-gamer: this sound tra...      1\n",
              "1  the best soundtrack ever to anything.: i'm rea...      1\n",
              "2  amazing!: this soundtrack is my favorite music...      1\n",
              "3  excellent soundtrack: i truly like this soundt...      1\n",
              "4  remember, pull your jaw off the floor after he...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "facG0nYb5gir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5118316e-3f35-42c8-fa38-32e86c726923"
      },
      "source": [
        "test_set=pd.concat([pd.DataFrame(test_sentences),pd.DataFrame(test_labels)],axis=1)\n",
        "test_set.columns=['review','label']\n",
        "test_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>great cd: my lovely pat has one of the great v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>one of the best game music soundtracks - for a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>batteries died within a year ...: i bought thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>works fine, but maha energy is better: check o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great for the non-audiophile: reviewed quite a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  great cd: my lovely pat has one of the great v...      1\n",
              "1  one of the best game music soundtracks - for a...      1\n",
              "2  batteries died within a year ...: i bought thi...      0\n",
              "3  works fine, but maha energy is better: check o...      1\n",
              "4  great for the non-audiophile: reviewed quite a...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmhAij4D5myT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set.to_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv')\n",
        "test_set.to_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test_set.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny_ZASKb6PWP",
        "colab_type": "text"
      },
      "source": [
        "# Code for re-process text data from Text_analytic Apress"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-tCZjzJ6VFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Aug 01 01:11:02 2016\n",
        "@author: DIP\n",
        "\"\"\"\n",
        "\n",
        "CONTRACTION_MAP = {\n",
        "\"ain't\": \"is not\",\n",
        "\"aren't\": \"are not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he will\",\n",
        "\"he'll've\": \"he he will have\",\n",
        "\"he's\": \"he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how is\",\n",
        "\"I'd\": \"I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I will\",\n",
        "\"I'll've\": \"I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"i'd\": \"i would\",\n",
        "\"i'd've\": \"i would have\",\n",
        "\"i'll\": \"i will\",\n",
        "\"i'll've\": \"i will have\",\n",
        "\"i'm\": \"i am\",\n",
        "\"i've\": \"i have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it will\",\n",
        "\"it'll've\": \"it will have\",\n",
        "\"it's\": \"it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she will\",\n",
        "\"she'll've\": \"she will have\",\n",
        "\"she's\": \"she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as\",\n",
        "\"that'd\": \"that would\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that is\",\n",
        "\"there'd\": \"there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there is\",\n",
        "\"they'd\": \"they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they will\",\n",
        "\"they'll've\": \"they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what will\",\n",
        "\"what'll've\": \"what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who will\",\n",
        "\"who'll've\": \"who will have\",\n",
        "\"who's\": \"who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you will\",\n",
        "\"you'll've\": \"you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODHmdls06WNo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9702a9c1-6407-4285-9f97-b2406f5fe4fa"
      },
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import unicodedata\n",
        "#from contractions import CONTRACTION_MAP\n",
        "import re\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('stopwords')\n",
        "import collections\n",
        "#from textblob import Word\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "nlp = spacy.load('en', parse=True, tag=True, entity=True)\n",
        "# nlp_vec = spacy.load('en_vectors_web_lg', parse=True, tag=True, entity=True)\n",
        "\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    if bool(soup.find()):\n",
        "        [s.extract() for s in soup(['iframe', 'script'])]\n",
        "        stripped_text = soup.get_text()\n",
        "        stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "    else:\n",
        "        stripped_text = text\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "#def correct_spellings_textblob(tokens):\n",
        "#\treturn [Word(token).correct() for token in tokens]  \n",
        "\n",
        "\n",
        "def simple_porter_stemming(text):\n",
        "    ps = nltk.porter.PorterStemmer()\n",
        "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_repeated_characters(tokens):\n",
        "    repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
        "    match_substitution = r'\\1\\2\\3'\n",
        "    def replace(old_word):\n",
        "        if wordnet.synsets(old_word):\n",
        "            return old_word\n",
        "        new_word = repeat_pattern.sub(match_substitution, old_word)\n",
        "        return replace(new_word) if new_word != old_word else new_word\n",
        "            \n",
        "    correct_tokens = [replace(word) for word in tokens]\n",
        "    return correct_tokens\n",
        "\n",
        "\n",
        "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
        "    \n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
        "                                      flags=re.IGNORECASE|re.DOTALL)\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match)\\\n",
        "                                if contraction_mapping.get(match)\\\n",
        "                                else contraction_mapping.get(match.lower())                       \n",
        "        expanded_contraction = first_char+expanded_contraction[1:]\n",
        "        return expanded_contraction\n",
        "        \n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text\n",
        "\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^a-zA-Z0-9\\s]|\\[|\\]' if not remove_digits else r'[^a-zA-Z\\s]|\\[|\\]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_stopwords(text, is_lower_case=False, stopwords=stopword_list):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "\n",
        "\n",
        "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
        "                     accented_char_removal=True, text_lower_case=True, \n",
        "                     text_stemming=False, text_lemmatization=True, \n",
        "                     special_char_removal=True, remove_digits=True,\n",
        "                     stopword_removal=True, stopwords=stopword_list):\n",
        "    \n",
        "    normalized_corpus = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "\n",
        "        # strip HTML\n",
        "        if html_stripping:\n",
        "            doc = strip_html_tags(doc)\n",
        "\n",
        "        # remove extra newlines\n",
        "        doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "\n",
        "        # remove accented characters\n",
        "        if accented_char_removal:\n",
        "            doc = remove_accented_chars(doc)\n",
        "\n",
        "        # expand contractions    \n",
        "        if contraction_expansion:\n",
        "            doc = expand_contractions(doc)\n",
        "\n",
        "        # lemmatize text\n",
        "        if text_lemmatization:\n",
        "            doc = lemmatize_text(doc)\n",
        "\n",
        "        # stem text\n",
        "        if text_stemming and not text_lemmatization:\n",
        "        \tdoc = simple_porter_stemming(doc)\n",
        "\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
        "\n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "\n",
        "         # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "\n",
        "        # remove stopwords\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc, is_lower_case=text_lower_case, stopwords=stopwords)\n",
        "\n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        doc = doc.strip()\n",
        "            \n",
        "        normalized_corpus.append(doc)\n",
        "        \n",
        "    return normalized_corpus"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4itx8LE1OC7",
        "colab_type": "text"
      },
      "source": [
        "# Ch09a - Sentiment Analysis - Unsupervised Lexical.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF3Q4cAxtRod",
        "colab_type": "text"
      },
      "source": [
        "No need to re-process data before training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCH_xUOS6GMY",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis with textblob"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMwRJ05y6Clx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import text_normalizer as tn # specific ebook library\n",
        "#import model_evaluation_utils as meu # specific ebook library\n",
        "import nltk\n",
        "import textblob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfk5j-aI07TF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv')\n",
        "test_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test_set.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsuRJU6E59Nm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7d686988-63ce-4283-d12e-746aae9dbbc4"
      },
      "source": [
        "print(train_set.shape)\n",
        "print(test_set.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3600000, 3)\n",
            "(400000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9s4SsF-6ubT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5c08c9c0-7182-476a-8de8-938b025d3a1f"
      },
      "source": [
        "test_set.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>great cd: my lovely pat has one of the great v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>one of the best game music soundtracks - for a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>batteries died within a year ...: i bought thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>works fine, but maha energy is better: check o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>great for the non-audiophile: reviewed quite a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             review  label\n",
              "0           0  great cd: my lovely pat has one of the great v...      1\n",
              "1           1  one of the best game music soundtracks - for a...      1\n",
              "2           2  batteries died within a year ...: i bought thi...      0\n",
              "3           3  works fine, but maha energy is better: check o...      1\n",
              "4           4  great for the non-audiophile: reviewed quite a...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUt_F1q96qeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = np.array(test_set['review'])\n",
        "sentiments = np.array(test_set['label'])\n",
        "split_ratio=0.7\n",
        "split=int(test_set.shape[0]*0.7)\n",
        "test_reviews = reviews[split:]\n",
        "test_sentiments = sentiments[split:]\n",
        "sample_review_ids = [0, 200, 500]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bexjv1pK60tQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "b46bff1d-05a5-4624-e83d-2f0074e97c1c"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    print('Predicted Sentiment polarity:', textblob.TextBlob(review).sentiment.polarity)\n",
        "    print('-'*60)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: amazing compositions, performances and recording quality!: having purchased and enjoyed the other 0 star disc of this group i had to see what \"closer\" was like.this disc is even better in many respects.the compositions are so clever, the arrangements perfect and the recording/mixing are stunning.would love to see a live concert here in new zealand!\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment polarity: 0.40984848484848485\n",
            "------------------------------------------------------------\n",
            "REVIEW: i liked it: great story, no violence, nudity, profanity, a movie everyone can watch and enjoy. i would recommend this movie to anyone\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment polarity: 0.6\n",
            "------------------------------------------------------------\n",
            "REVIEW: poor bob, victim of himself!: awful. i mean, really awful...and i liked \"self portrait\" because you knew dylan was just trying to have some fun with his image. this album is just a disaster. the lyrics are ok on most songs (i've seen worse by dylan), but the music is unexciting, not very creative, and downright embarrassing on some tracks. why, oh, why did you have to make an album like this, bob? such talented people at your disposal for these sessions, and you threw it away on garbage arrangements. shameful. really sad.\n",
            "Actual Sentiment: 0\n",
            "Predicted Sentiment polarity: -0.007039835164835172\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTiG2btK7NcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f51f1c76-45d9-489c-ae23-82e04c50113c"
      },
      "source": [
        "sentiment_polarity = [textblob.TextBlob(review).sentiment.polarity for review in test_reviews]\n",
        "predicted_sentiments = [1 if score >= 0.1 else 0 for score in sentiment_polarity]\n",
        "print(classification_report(test_sentiments,predicted_sentiments))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.65      0.73     60301\n",
            "           1       0.71      0.87      0.78     59699\n",
            "\n",
            "    accuracy                           0.76    120000\n",
            "   macro avg       0.77      0.76      0.76    120000\n",
            "weighted avg       0.77      0.76      0.76    120000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhvBk9kC7eh8",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis with AFINN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZvs_jTW7Xyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "16e1b948-245d-4f32-9fea-800e5ee8106a"
      },
      "source": [
        "!pip install afinn\n",
        "from afinn import Afinn\n",
        "afn = Afinn(emoticons=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting afinn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
            "\r\u001b[K     |                         | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |                   | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |             | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |       | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     || 51kB 2.0MB/s eta 0:00:01\r\u001b[K     || 61kB 1.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-cp36-none-any.whl size=53452 sha256=001d03417353dd2aadb3386448da728e155d6b6bf9a505f507cd1799791be206\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8WVtTAz7hsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "97110629-b292-4ade-a856-687b83a8e02b"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    print('Predicted Sentiment polarity:', afn.score(review))\n",
        "    print('-'*60)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: amazing compositions, performances and recording quality!: having purchased and enjoyed the other 0 star disc of this group i had to see what \"closer\" was like.this disc is even better in many respects.the compositions are so clever, the arrangements perfect and the recording/mixing are stunning.would love to see a live concert here in new zealand!\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment polarity: 26.0\n",
            "------------------------------------------------------------\n",
            "REVIEW: i liked it: great story, no violence, nudity, profanity, a movie everyone can watch and enjoy. i would recommend this movie to anyone\n",
            "Actual Sentiment: 1\n",
            "Predicted Sentiment polarity: 5.0\n",
            "------------------------------------------------------------\n",
            "REVIEW: poor bob, victim of himself!: awful. i mean, really awful...and i liked \"self portrait\" because you knew dylan was just trying to have some fun with his image. this album is just a disaster. the lyrics are ok on most songs (i've seen worse by dylan), but the music is unexciting, not very creative, and downright embarrassing on some tracks. why, oh, why did you have to make an album like this, bob? such talented people at your disposal for these sessions, and you threw it away on garbage arrangements. shameful. really sad.\n",
            "Actual Sentiment: 0\n",
            "Predicted Sentiment polarity: -13.0\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBLIgknu7hxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cbfdad77-0674-419f-967e-304941015c58"
      },
      "source": [
        "sentiment_polarity = [afn.score(review) for review in test_reviews]\n",
        "predicted_sentiments = [1 if score >= 1.0 else 0 for score in sentiment_polarity]\n",
        "print(classification_report(test_sentiments,predicted_sentiments))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.50      0.63     60301\n",
            "           1       0.64      0.92      0.76     59699\n",
            "\n",
            "    accuracy                           0.71    120000\n",
            "   macro avg       0.75      0.71      0.69    120000\n",
            "weighted avg       0.75      0.71      0.69    120000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgT_8STq7yxE",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis with SentiWordNet (VERY LONG, not stable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoCe0OTT7h01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "975de5fe-e7ae-4a90-9462-91628bec9392"
      },
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "import nltk\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "awesome = list(swn.senti_synsets('awesome', 'a'))[0]\n",
        "print('Positive Polarity Score:', awesome.pos_score())\n",
        "print('Negative Polarity Score:', awesome.neg_score())\n",
        "print('Objective Score:', awesome.obj_score())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Positive Polarity Score: 0.875\n",
            "Negative Polarity Score: 0.125\n",
            "Objective Score: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsJeGIF071P_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_sentiment_sentiwordnet_lexicon(review,\n",
        "                                           verbose=False):\n",
        "\n",
        "    # tokenize and POS tag text tokens\n",
        "    tagged_text = [(token.text, token.tag_) for token in nlp(review)] # from text_normalizer.py\n",
        "    pos_score = neg_score = token_count = obj_score = 0\n",
        "    # get wordnet synsets based on POS tags\n",
        "    # get sentiment scores if synsets are found\n",
        "    for word, tag in tagged_text:\n",
        "        ss_set = None\n",
        "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
        "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
        "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
        "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
        "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
        "        # if senti-synset is found        \n",
        "        if ss_set:\n",
        "            # add scores for all found synsets\n",
        "            pos_score += ss_set.pos_score()\n",
        "            neg_score += ss_set.neg_score()\n",
        "            obj_score += ss_set.obj_score()\n",
        "            token_count += 1\n",
        "    \n",
        "    # aggregate final scores\n",
        "    final_score = pos_score - neg_score\n",
        "    norm_final_score = round(float(final_score) / token_count, 2)\n",
        "    final_sentiment = 1 if norm_final_score >= 0 else 0\n",
        "    if verbose:\n",
        "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
        "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
        "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
        "        # to display results in a nice table\n",
        "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
        "                                         norm_neg_score, norm_final_score]],\n",
        "                                       columns = ['Predicted Sentiment', 'Objectivity',\n",
        "                                                     'Positive', 'Negative', 'Overall']\n",
        "                                       #columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
        "                                       #                      ['Predicted Sentiment', 'Objectivity',\n",
        "                                        #                      'Positive', 'Negative', 'Overall']], \n",
        "                                       #                      labels=[[0,0,0,0,0],[0,1,2,3,4]])\n",
        "                                       )\n",
        "        print(sentiment_frame)\n",
        "        \n",
        "    return final_sentiment"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ-hndov74hd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "a143c89c-a232-4ef4-ed2f-cf3ff568bc3b"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    pred = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)    \n",
        "    print('-'*60)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: amazing compositions, performances and recording quality!: having purchased and enjoyed the other 0 star disc of this group i had to see what \"closer\" was like.this disc is even better in many respects.the compositions are so clever, the arrangements perfect and the recording/mixing are stunning.would love to see a live concert here in new zealand!\n",
            "Actual Sentiment: 1\n",
            "   Predicted Sentiment  Objectivity  Positive  Negative  Overall\n",
            "0                    1         0.81      0.15      0.04     0.11\n",
            "------------------------------------------------------------\n",
            "REVIEW: i liked it: great story, no violence, nudity, profanity, a movie everyone can watch and enjoy. i would recommend this movie to anyone\n",
            "Actual Sentiment: 1\n",
            "   Predicted Sentiment  Objectivity  Positive  Negative  Overall\n",
            "0                    1         0.88      0.07      0.06     0.01\n",
            "------------------------------------------------------------\n",
            "REVIEW: poor bob, victim of himself!: awful. i mean, really awful...and i liked \"self portrait\" because you knew dylan was just trying to have some fun with his image. this album is just a disaster. the lyrics are ok on most songs (i've seen worse by dylan), but the music is unexciting, not very creative, and downright embarrassing on some tracks. why, oh, why did you have to make an album like this, bob? such talented people at your disposal for these sessions, and you threw it away on garbage arrangements. shameful. really sad.\n",
            "Actual Sentiment: 0\n",
            "   Predicted Sentiment  Objectivity  Positive  Negative  Overall\n",
            "0                    0         0.77       0.1      0.13    -0.03\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aDN5YCL7hvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "3bd3c163-69a7-497d-8c49-2e90df8556ae"
      },
      "source": [
        "#norm_test_reviews = normalize_corpus(test_reviews)\n",
        "#predicted_sentiments = [analyze_sentiment_sentiwordnet_lexicon(review, verbose=False) for review in norm_test_reviews]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-17a9bd005996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnorm_test_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_sentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyze_sentiment_sentiwordnet_lexicon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnorm_test_reviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-17a9bd005996>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnorm_test_reviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_reviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_sentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyze_sentiment_sentiwordnet_lexicon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnorm_test_reviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-abc0c0544880>\u001b[0m in \u001b[0;36manalyze_sentiment_sentiwordnet_lexicon\u001b[0;34m(review, verbose)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# aggregate final scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mfinal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mnorm_final_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_score\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtoken_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mfinal_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnorm_final_score\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4nnNfTV8CSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(test_sentiments,predicted_sentiments))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj-V4Ayk8Xi3",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis with VADER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcAloXxG8WPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6b1d9b4e-3dba-4abd-d75f-acdfc816aad9"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1vUtH5h8ZN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze_sentiment_vader_lexicon(review, \n",
        "                                    threshold=0.1,\n",
        "                                    verbose=False):\n",
        "    # pre-process text\n",
        "    review = strip_html_tags(review)\n",
        "    review = remove_accented_chars(review)\n",
        "    review = expand_contractions(review)\n",
        "    \n",
        "    # analyze the sentiment for review\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(review)\n",
        "    # get aggregate scores and final sentiment\n",
        "    agg_score = scores['compound']\n",
        "    final_sentiment = 1 if agg_score >= threshold else 0\n",
        "    #1: positive, o: negative\n",
        "    if verbose:\n",
        "        # display detailed sentiment statistics\n",
        "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
        "        final = round(agg_score, 2)\n",
        "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
        "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
        "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
        "                                        negative, neutral]],\n",
        "                                       columns = ['Predicted Sentiment', 'Polarity Score',\n",
        "                                                     'Positive', 'Negative', 'Overall']\n",
        "                                        #columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
        "                                        #                              ['Predicted Sentiment', 'Polarity Score',\n",
        "                                         #                              'Positive', 'Negative', 'Neutral']], \n",
        "                                          #                    labels=[[0,0,0,0,0],[0,1,2,3,4]])\n",
        "                                        )\n",
        "        print(sentiment_frame)\n",
        "    \n",
        "    return final_sentiment"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxUL2W0t8aNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "286631c7-8f24-417e-c4fd-eff280b85b08"
      },
      "source": [
        "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
        "    print('REVIEW:', review)\n",
        "    print('Actual Sentiment:', sentiment)\n",
        "    pred = analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=True)    \n",
        "    print('-'*60)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REVIEW: amazing compositions, performances and recording quality!: having purchased and enjoyed the other 0 star disc of this group i had to see what \"closer\" was like.this disc is even better in many respects.the compositions are so clever, the arrangements perfect and the recording/mixing are stunning.would love to see a live concert here in new zealand!\n",
            "Actual Sentiment: 1\n",
            "   Predicted Sentiment  Polarity Score Positive Negative Overall\n",
            "0                    1            0.97    33.0%     0.0%   67.0%\n",
            "------------------------------------------------------------\n",
            "REVIEW: i liked it: great story, no violence, nudity, profanity, a movie everyone can watch and enjoy. i would recommend this movie to anyone\n",
            "Actual Sentiment: 1\n",
            "   Predicted Sentiment  Polarity Score Positive Negative Overall\n",
            "0                    1            0.74    38.0%    19.0%   43.0%\n",
            "------------------------------------------------------------\n",
            "REVIEW: poor bob, victim of himself!: awful. i mean, really awful...and i liked \"self portrait\" because you knew dylan was just trying to have some fun with his image. this album is just a disaster. the lyrics are ok on most songs (i've seen worse by dylan), but the music is unexciting, not very creative, and downright embarrassing on some tracks. why, oh, why did you have to make an album like this, bob? such talented people at your disposal for these sessions, and you threw it away on garbage arrangements. shameful. really sad.\n",
            "Actual Sentiment: 0\n",
            "   Predicted Sentiment  Polarity Score Positive Negative Overall\n",
            "0                    0           -0.91    12.0%    23.0%   66.0%\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6E40Pso8epc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "391c4451-fd4d-4d16-e15e-367015ff1716"
      },
      "source": [
        "predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=False) for review in test_reviews]\n",
        "print(classification_report(test_sentiments,predicted_sentiments))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.63      0.72     60301\n",
            "           1       0.70      0.88      0.78     59699\n",
            "\n",
            "    accuracy                           0.76    120000\n",
            "   macro avg       0.77      0.76      0.75    120000\n",
            "weighted avg       0.77      0.76      0.75    120000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJd2_hz7slBm",
        "colab_type": "text"
      },
      "source": [
        "# Ch09b - Sentiment Analysis - Supervised.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjGfdzWl8ij7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import text_normalizer as tn\n",
        "#import model_evaluation_utils as meu\n",
        "import nltk\n",
        "\n",
        "np.set_printoptions(precision=2, linewidth=80)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tkwil7HHsqFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1714ef0c-cb28-4cf8-f9c6-e2de4dfd3a13"
      },
      "source": [
        "train_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/train_set.csv')\n",
        "test_set=pd.read_csv('/content/drive/My Drive/Data/NLP/Kaggle_Amazone_review_sentiment/test_set.csv')\n",
        "print(train_set.shape)\n",
        "print(test_set.shape)\n",
        "test_set.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3600000, 3)\n",
            "(400000, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>great cd: my lovely pat has one of the great v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>one of the best game music soundtracks - for a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>batteries died within a year ...: i bought thi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>works fine, but maha energy is better: check o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>great for the non-audiophile: reviewed quite a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             review  label\n",
              "0           0  great cd: my lovely pat has one of the great v...      1\n",
              "1           1  one of the best game music soundtracks - for a...      1\n",
              "2           2  batteries died within a year ...: i bought thi...      0\n",
              "3           3  works fine, but maha energy is better: check o...      1\n",
              "4           4  great for the non-audiophile: reviewed quite a...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgKr8Pn4tY-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews = np.array(train_set['review'])\n",
        "sentiments = np.array(train_set['label'])\n",
        "# build train and test datasets\n",
        "train_reviews = reviews[:35000]\n",
        "train_sentiments = sentiments[:35000]\n",
        "test_reviews = reviews[35000:50000]\n",
        "test_sentiments = sentiments[35000:50000]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjUuDbHF96cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize datasets\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "stop_words.remove('no')\n",
        "stop_words.remove('but')\n",
        "stop_words.remove('not')\n",
        "\n",
        "norm_train_reviews = normalize_corpus(train_reviews, stopwords=stop_words)\n",
        "norm_test_reviews = normalize_corpus(test_reviews, stopwords=stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J6mNwaY-Dtp",
        "colab_type": "text"
      },
      "source": [
        "## Traditional Supervised Machine Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4QpRLxS-JS0",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSIo_cDv9_Ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# build BOW features on train reviews\n",
        "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
        "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
        "# build TFIDF features on train reviews\n",
        "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
        "                     sublinear_tf=True)\n",
        "tv_train_features = tv.fit_transform(norm_train_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHmiDfU8-Tdq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform test reviews into features\n",
        "cv_test_features = cv.transform(norm_test_reviews)\n",
        "tv_test_features = tv.transform(norm_test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBPaGSEm-WC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
        "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90q4bJOj-WM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LgkCzZ8-WKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJO_QN_S-WIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJujB9PH-WGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}