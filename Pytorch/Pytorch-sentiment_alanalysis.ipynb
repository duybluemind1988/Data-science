{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Pytorch-sentiment_alanalysis.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "gXLGy-ILd_eD"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "#print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88eDSLuAd_eH"
      },
      "source": [
        "# 1. LOAD THE TRAINING TEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pRc56_Swd_eH"
      },
      "source": [
        "#test_data_sub=pd.read_csv('../input/test.csv')\n",
        "#train_data=pd.read_csv('../input/train.csv')\n",
        "#reviews=train_data['review'].get_values()\n",
        "#labels=train_data['sentiment'].get_values()\n",
        "#input_test=test_data_sub['review'].get_values()\n",
        "#y_test=list()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqzm9FJKeMLh",
        "outputId": "79d2607a-56fc-4bb5-9909-761ad989247f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "#download data\n",
        "!mkdir data\n",
        "!wget -c https://github.com/agungsantoso/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/labels.txt\n",
        "!wget -c https://github.com/agungsantoso/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/reviews.txt\n",
        "!mv *.txt data/\n",
        "import numpy as np\n",
        "# read data from text files\n",
        "with open('data/reviews.txt', 'r') as f:\n",
        "     reviews = f.readlines()\n",
        "with open('data/labels.txt', 'r') as f:\n",
        "     labels = f.readlines()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-04 07:45:47--  https://github.com/agungsantoso/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/labels.txt\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/agungsantoso/deep-learning-v2-pytorch/master/sentiment-rnn/data/labels.txt [following]\n",
            "--2020-10-04 07:45:47--  https://raw.githubusercontent.com/agungsantoso/deep-learning-v2-pytorch/master/sentiment-rnn/data/labels.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 225000 (220K) [text/plain]\n",
            "Saving to: ‘labels.txt’\n",
            "\n",
            "labels.txt          100%[===================>] 219.73K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-10-04 07:45:47 (8.21 MB/s) - ‘labels.txt’ saved [225000/225000]\n",
            "\n",
            "--2020-10-04 07:45:47--  https://github.com/agungsantoso/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/reviews.txt\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/agungsantoso/deep-learning-v2-pytorch/master/sentiment-rnn/data/reviews.txt [following]\n",
            "--2020-10-04 07:45:47--  https://raw.githubusercontent.com/agungsantoso/deep-learning-v2-pytorch/master/sentiment-rnn/data/reviews.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33678267 (32M) [text/plain]\n",
            "Saving to: ‘reviews.txt’\n",
            "\n",
            "reviews.txt         100%[===================>]  32.12M  80.0MB/s    in 0.4s    \n",
            "\n",
            "2020-10-04 07:45:48 (80.0 MB/s) - ‘reviews.txt’ saved [33678267/33678267]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgWq2Bpid_eK"
      },
      "source": [
        "#  2. TEXT PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iXfOIB7gd_eL",
        "outputId": "b66e9a34-093e-492c-802e-c1d36f791455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Cfr1-a-hd_eO"
      },
      "source": [
        "appos = {\n",
        "\"aren't\" : \"are not\",\n",
        "\"can't\" : \"cannot\",\n",
        "\"couldn't\" : \"could not\",\n",
        "\"didn't\" : \"did not\",\n",
        "\"doesn't\" : \"does not\",\n",
        "\"don't\" : \"do not\",\n",
        "\"hadn't\" : \"had not\",\n",
        "\"hasn't\" : \"has not\",\n",
        "\"haven't\" : \"have not\",\n",
        "\"he'd\" : \"he would\",\n",
        "\"he'll\" : \"he will\",\n",
        "\"he's\" : \"he is\",\n",
        "\"i'd\" : \"I would\",\n",
        "\"i'd\" : \"I had\",\n",
        "\"i'll\" : \"I will\",\n",
        "\"i'm\" : \"I am\",\n",
        "\"isn't\" : \"is not\",\n",
        "\"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\",\n",
        "\"i've\" : \"I have\",\n",
        "\"let's\" : \"let us\",\n",
        "\"mightn't\" : \"might not\",\n",
        "\"mustn't\" : \"must not\",\n",
        "\"shan't\" : \"shall not\",\n",
        "\"she'd\" : \"she would\",\n",
        "\"she'll\" : \"she will\",\n",
        "\"she's\" : \"she is\",\n",
        "\"shouldn't\" : \"should not\",\n",
        "\"that's\" : \"that is\",\n",
        "\"there's\" : \"there is\",\n",
        "\"they'd\" : \"they would\",\n",
        "\"they'll\" : \"they will\",\n",
        "\"they're\" : \"they are\",\n",
        "\"they've\" : \"they have\",\n",
        "\"we'd\" : \"we would\",\n",
        "\"we're\" : \"we are\",\n",
        "\"weren't\" : \"were not\",\n",
        "\"we've\" : \"we have\",\n",
        "\"what'll\" : \"what will\",\n",
        "\"what're\" : \"what are\",\n",
        "\"what's\" : \"what is\",\n",
        "\"what've\" : \"what have\",\n",
        "\"where's\" : \"where is\",\n",
        "\"who'd\" : \"who would\",\n",
        "\"who'll\" : \"who will\",\n",
        "\"who're\" : \"who are\",\n",
        "\"who's\" : \"who is\",\n",
        "\"who've\" : \"who have\",\n",
        "\"won't\" : \"will not\",\n",
        "\"wouldn't\" : \"would not\",\n",
        "\"you'd\" : \"you would\",\n",
        "\"you'll\" : \"you will\",\n",
        "\"you're\" : \"you are\",\n",
        "\"you've\" : \"you have\",\n",
        "\"'re\": \" are\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'll\":\" will\",\n",
        "\"didn't\": \"did not\"\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lNQkI_axd_eR"
      },
      "source": [
        "from string import punctuation\n",
        "def review_formatting(reviews):\n",
        "    all_reviews=list()\n",
        "    for text in reviews:\n",
        "        lower_case = text.lower()\n",
        "        words = lower_case.split()\n",
        "        reformed = [appos[word] if word in appos else word for word in words]\n",
        "        reformed_test=list()\n",
        "        for word in reformed:\n",
        "            if word not in stop_words:\n",
        "                reformed_test.append(word)\n",
        "        reformed = \" \".join(reformed_test) \n",
        "        punct_text = \"\".join([ch for ch in reformed if ch not in punctuation])\n",
        "        all_reviews.append(punct_text)\n",
        "    all_text = \" \".join(all_reviews)\n",
        "    all_words = all_text.split()\n",
        "    return all_reviews, all_words"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pjex7IROd_eU"
      },
      "source": [
        "from collections import Counter \n",
        "# Count all the words using Counter Method\n",
        "all_reviews, all_words=review_formatting(reviews)\n",
        "count_words = Counter(all_words)\n",
        "total_words=len(all_words)\n",
        "sorted_words=count_words.most_common(total_words)\n",
        "vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CQD66llUd_eX"
      },
      "source": [
        "def encode_reviews(reviews):\n",
        "    \"\"\"\n",
        "    encode_reviews function will encodes review in to array of numbers\n",
        "    \"\"\"\n",
        "    all_reviews=list()\n",
        "    for text in reviews:\n",
        "        text = text.lower()\n",
        "        text = \"\".join([ch for ch in text if ch not in punctuation])\n",
        "        all_reviews.append(text)\n",
        "    encoded_reviews=list()\n",
        "    for review in all_reviews:\n",
        "        encoded_review=list()\n",
        "        for word in review.split():\n",
        "            if word not in vocab_to_int.keys():\n",
        "                encoded_review.append(0)\n",
        "            else:\n",
        "                encoded_review.append(vocab_to_int[word])\n",
        "        encoded_reviews.append(encoded_review)\n",
        "    return encoded_reviews"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hLHDcbL4d_ea"
      },
      "source": [
        "def pad_sequences(encoded_reviews, sequence_length=250):\n",
        "    ''' \n",
        "    Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
        "    '''\n",
        "    features=np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
        "    \n",
        "    for i, review in enumerate(encoded_reviews):\n",
        "        review_len=len(review)\n",
        "        if (review_len<=sequence_length):\n",
        "            zeros=list(np.zeros(sequence_length-review_len))\n",
        "            new=zeros+review\n",
        "        else:\n",
        "            new=review[:sequence_length]\n",
        "        features[i,:]=np.array(new)\n",
        "    return features"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GWogBWvVd_ed"
      },
      "source": [
        "def preprocess(reviews):\n",
        "    \"\"\"\n",
        "    This Function will tranform reviews in to model readable form\n",
        "    \"\"\"\n",
        "    formated_reviews, all_words = review_formatting(reviews)\n",
        "    encoded_reviews=encode_reviews(formated_reviews)\n",
        "    features=pad_sequences(encoded_reviews, 250)\n",
        "    return features"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUhJ8gz6d_ef"
      },
      "source": [
        "# Analyze The Review Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xw4CXIhhd_ef"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#encoded_reviews=encode_reviews(reviews)\n",
        "#review_len=[len(encoded_review) for encoded_review in encoded_reviews]\n",
        "#pd.Series(review_len).hist()\n",
        "#plt.show()\n",
        "#pd.Series(review_len).describe()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG2CP3BXe-xu"
      },
      "source": [
        "labels=[1 if label.strip()=='positive' else 0 for label in labels]\n",
        "labels=np.array(labels)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q2_a7sOXd_ei",
        "outputId": "813c47b5-191a-401f-81b8-c6c00246ab95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#split_dataset into 80% training , 10% test and 10% Validation Dataset\n",
        "features=preprocess(reviews)\n",
        "train_x=features[:int(0.90*len(features))]\n",
        "train_y=labels[:int(0.90*len(features))]\n",
        "valid_x=features[int(0.90*len(features)):]\n",
        "valid_y=labels[int(0.90*len(features)):]\n",
        "print(len(train_y), len(valid_y))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22500 2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERmCBNzoek9Z",
        "outputId": "5e7d23f9-fedd-430b-a631-3dc2fcb58d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "train_x"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  120, 4004, 2071],\n",
              "       [   0,    0,    0, ..., 7801,   32, 3182],\n",
              "       [   0,    0,    0, ..., 5710,  220,  281],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 6843,   14,   45],\n",
              "       [   0,    0,    0, ..., 7104,  864,  158],\n",
              "       [   0,    0,    0, ...,    2,   37, 2278]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24roVdQSjJKV",
        "outputId": "51625bcd-9bde-4061-a789-5515a486bfa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_y"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wp5xHaR6d_el"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "#create Tensor Dataset\n",
        "train_data=TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data=TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
        "\n",
        "#dataloader\n",
        "batch_size=50\n",
        "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "valid_loader=DataLoader(valid_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "anJgeJ0qd_eo",
        "outputId": "f9184fbb-d0f6-426f-8b2d-19e4a6f78ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 250])\n",
            "Sample input: \n",
            " tensor([[    0,     0,     0,  ...,  3760, 14714,    70],\n",
            "        [    0,     0,     0,  ...,   376,    69,   713],\n",
            "        [    0,     0,     0,  ...,   201,    26,    14],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ..., 10379,  1566, 20154],\n",
            "        [    0,     0,     0,  ..., 12874,   400,  1675],\n",
            "        [63651,  2520,   328,  ...,   472,   683,    41]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
            "        0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lyzamvgcd_eq"
      },
      "source": [
        "import torch.nn as nn\n",
        " \n",
        "class SentimentalLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):    \n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.output_size=output_size\n",
        "        self.n_layers=n_layers\n",
        "        self.hidden_dim=hidden_dim\n",
        "        \n",
        "        #Embedding and LSTM layers\n",
        "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        #dropout layer\n",
        "        self.dropout=nn.Dropout(0.3)\n",
        "        \n",
        "        #Linear and sigmoid layer\n",
        "        self.fc1=nn.Linear(hidden_dim, 64)\n",
        "        self.fc2=nn.Linear(64, 16)\n",
        "        self.fc3=nn.Linear(16,output_size)\n",
        "        self.sigmoid=nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size=x.size()\n",
        "        \n",
        "        #Embadding and LSTM output\n",
        "        embedd=self.embedding(x)\n",
        "        lstm_out, hidden=self.lstm(embedd, hidden)\n",
        "        \n",
        "        #stack up the lstm output\n",
        "        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        #dropout and fully connected layers\n",
        "        out=self.dropout(lstm_out)\n",
        "        out=self.fc1(out)\n",
        "        out=self.dropout(out)\n",
        "        out=self.fc2(out)\n",
        "        out=self.dropout(out)\n",
        "        out=self.fc3(out)\n",
        "        sig_out=self.sigmoid(out)\n",
        "        \n",
        "        sig_out=sig_out.view(batch_size, -1)\n",
        "        sig_out=sig_out[:, -1]\n",
        "        \n",
        "        return sig_out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"Initialize Hidden STATE\"\"\"\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "g5YymHOXd_es",
        "outputId": "767dc4d2-df95-4acc-dbb3-362b4a37cbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentalLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "print(net)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentalLSTM(\n",
            "  (embedding): Embedding(73920, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
            "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z2614DMqd_ex",
        "outputId": "d6cbb196-1708-48b5-e3f7-72bd3083757f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "# training params\n",
        "\n",
        "epochs = 3 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs=inputs.cuda()\n",
        "            labels=labels.cuda()\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()  \n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3... Step: 100... Loss: 0.620769... Val Loss: 0.589968\n",
            "Epoch: 1/3... Step: 200... Loss: 0.584067... Val Loss: 0.509869\n",
            "Epoch: 1/3... Step: 300... Loss: 0.519849... Val Loss: 0.500912\n",
            "Epoch: 1/3... Step: 400... Loss: 0.433492... Val Loss: 0.510812\n",
            "Epoch: 2/3... Step: 500... Loss: 0.290394... Val Loss: 0.424918\n",
            "Epoch: 2/3... Step: 600... Loss: 0.422250... Val Loss: 0.558912\n",
            "Epoch: 2/3... Step: 700... Loss: 0.224285... Val Loss: 0.385605\n",
            "Epoch: 2/3... Step: 800... Loss: 0.167243... Val Loss: 0.415238\n",
            "Epoch: 2/3... Step: 900... Loss: 0.333522... Val Loss: 0.421626\n",
            "Epoch: 3/3... Step: 1000... Loss: 0.179388... Val Loss: 0.470326\n",
            "Epoch: 3/3... Step: 1100... Loss: 0.391976... Val Loss: 0.442390\n",
            "Epoch: 3/3... Step: 1200... Loss: 0.237543... Val Loss: 0.462957\n",
            "Epoch: 3/3... Step: 1300... Loss: 0.315555... Val Loss: 0.440386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fr8VpUMnd_ez",
        "outputId": "c698536e-afeb-41f2-a4e6-ffc67010f9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "def test_model(input_test):\n",
        "    output_list=list()\n",
        "    batch_size=50   \n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        test_review=preprocess(input_test)\n",
        "        for review in test_review:\n",
        "            # convert to tensor to pass into your model\n",
        "            feature_tensor = torch.from_numpy(review).view(1,-1)\n",
        "            if(train_on_gpu):\n",
        "                feature_tensor= feature_tensor.cuda()\n",
        "            batch_size = feature_tensor.size(0)\n",
        "            # initialize hidden state\n",
        "            h = net.init_hidden(batch_size)\n",
        "            # get the output from the model\n",
        "            output, h = net(feature_tensor, h)\n",
        "            pred = torch.round(output.squeeze()) \n",
        "            output_list.append(pred)\n",
        "        labels=[int(i.data.cpu().numpy()) for i in output_list]\n",
        "        return labels\n",
        "labels=test_model(input_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3490a4f29aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'input_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YRMRF8aZd_e1"
      },
      "source": [
        "output = pd.DataFrame()\n",
        "output['Id'] = test_data_sub['Id']\n",
        "output['sentiment'] = labels\n",
        "output.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2RjUVgefd_e3"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}